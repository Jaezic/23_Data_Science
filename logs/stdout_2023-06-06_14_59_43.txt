OrderedDict([('data_path', './dataset/FireDataset.csv'),
             ('param_path', './models/config'),
             ('seed', 64),
             ('redirector', True),
             ('visual', False),
             ('model', 'ab'),
             ('param_load', False),
             ('voting_list', ['dt', 'knn', 'rf', 'ab', 'gb']),
             ('tune', 'grid'),
             ('n_iter', 10),
             ('cv', 5),
             ('pca', False),
             ('n_components', 0.95),
             ('smote', True),
             ('standard', False),
             ('eval', 'kfold'),
             ('n_split', 10),
             ('num_class', 3)])
------------------------------------------------------------
Model: voting, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.4307, Precision: 0.4425, F1 Score: 0.4236
Confusion Matrix: 
 [[0.46060606 0.05454545 0.48484848]
 [0.32666667 0.08       0.59333333]
 [0.20186916 0.04672897 0.75140187]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.46      0.48       330
         1.0       0.22      0.08      0.12       150
         2.0       0.62      0.75      0.68       535

    accuracy                           0.56      1015
   macro avg       0.44      0.43      0.42      1015
weighted avg       0.52      0.56      0.53      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5764, Recall: 0.4331, Precision: 0.4413, F1 Score: 0.4267
Confusion Matrix: 
 [[0.46708464 0.04702194 0.48589342]
 [0.24285714 0.06428571 0.69285714]
 [0.17805755 0.05395683 0.76798561]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.47      0.50       319
         1.0       0.17      0.06      0.09       140
         2.0       0.63      0.77      0.69       556

    accuracy                           0.58      1015
   macro avg       0.44      0.43      0.43      1015
weighted avg       0.53      0.58      0.55      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.4314, Precision: 0.4508, F1 Score: 0.4305
Confusion Matrix: 
 [[0.45086705 0.06358382 0.48554913]
 [0.3037037  0.11111111 0.58518519]
 [0.22284644 0.04494382 0.73220974]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.45      0.47       346
         1.0       0.25      0.11      0.15       135
         2.0       0.61      0.73      0.67       534

    accuracy                           0.55      1015
   macro avg       0.45      0.43      0.43      1015
weighted avg       0.52      0.55      0.53      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5517, Recall: 0.4334, Precision: 0.4557, F1 Score: 0.4309
Confusion Matrix: 
 [[0.44692737 0.04748603 0.50558659]
 [0.28169014 0.1056338  0.61267606]
 [0.1961165  0.05631068 0.74757282]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.45      0.49       358
         1.0       0.25      0.11      0.15       142
         2.0       0.59      0.75      0.66       515

    accuracy                           0.55      1015
   macro avg       0.46      0.43      0.43      1015
weighted avg       0.52      0.55      0.53      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5360, Recall: 0.4178, Precision: 0.4288, F1 Score: 0.4083
Confusion Matrix: 
 [[0.43098592 0.07042254 0.49859155]
 [0.24025974 0.07142857 0.68831169]
 [0.20948617 0.03952569 0.75098814]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.43      0.47       355
         1.0       0.20      0.07      0.10       154
         2.0       0.57      0.75      0.65       506

    accuracy                           0.54      1015
   macro avg       0.43      0.42      0.41      1015
weighted avg       0.50      0.54      0.50      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5872, Recall: 0.4577, Precision: 0.4814, F1 Score: 0.4493
Confusion Matrix: 
 [[0.51111111 0.025      0.46388889]
 [0.35862069 0.07586207 0.56551724]
 [0.16862745 0.04509804 0.78627451]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.51      0.54       360
         1.0       0.26      0.08      0.12       145
         2.0       0.62      0.79      0.69       510

    accuracy                           0.59      1015
   macro avg       0.48      0.46      0.45      1015
weighted avg       0.55      0.59      0.56      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.4170, Precision: 0.4301, F1 Score: 0.4077
Confusion Matrix: 
 [[0.4186747  0.06325301 0.51807229]
 [0.28472222 0.0625     0.65277778]
 [0.20222635 0.02782931 0.76994434]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.42      0.45       332
         1.0       0.20      0.06      0.10       144
         2.0       0.61      0.77      0.68       539

    accuracy                           0.55      1015
   macro avg       0.43      0.42      0.41      1015
weighted avg       0.51      0.55      0.52      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5635, Recall: 0.4291, Precision: 0.4271, F1 Score: 0.4149
Confusion Matrix: 
 [[0.47839506 0.0462963  0.47530864]
 [0.30519481 0.04545455 0.64935065]
 [0.19553073 0.04096834 0.76350093]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.48      0.49       324
         1.0       0.16      0.05      0.07       154
         2.0       0.62      0.76      0.68       537

    accuracy                           0.56      1015
   macro avg       0.43      0.43      0.41      1015
weighted avg       0.51      0.56      0.53      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5764, Recall: 0.4334, Precision: 0.4408, F1 Score: 0.4323
Confusion Matrix: 
 [[0.48044693 0.05865922 0.46089385]
 [0.32110092 0.08256881 0.59633028]
 [0.20620438 0.05656934 0.73722628]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.48      0.51       358
         1.0       0.15      0.08      0.11       109
         2.0       0.64      0.74      0.68       548

    accuracy                           0.58      1015
   macro avg       0.44      0.43      0.43      1015
weighted avg       0.55      0.58      0.56      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5961, Recall: 0.4428, Precision: 0.4626, F1 Score: 0.4442
Confusion Matrix: 
 [[0.44771242 0.06535948 0.4869281 ]
 [0.28333333 0.10833333 0.60833333]
 [0.18675722 0.04074703 0.77249576]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.45      0.47       306
         1.0       0.23      0.11      0.15       120
         2.0       0.67      0.77      0.72       589

    accuracy                           0.60      1015
   macro avg       0.46      0.44      0.44      1015
weighted avg       0.56      0.60      0.58      1015

Average metrics:
 Accuracy: 0.5653, Precision: 0.4461, Recall: 0.4327, F1: 0.4268
    model    pca standard tune  accuracy  precision    recall        f1
0  voting  False    False  NaN   0.56532   0.446113  0.432653  0.426843
Model: voting, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5389, Recall: 0.4230, Precision: 0.4495, F1 Score: 0.4213
Confusion Matrix: 
 [[0.43030303 0.05757576 0.51212121]
 [0.27333333 0.11333333 0.61333333]
 [0.2317757  0.04299065 0.72523364]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.43      0.45       330
         1.0       0.29      0.11      0.16       150
         2.0       0.60      0.73      0.66       535

    accuracy                           0.54      1015
   macro avg       0.45      0.42      0.42      1015
weighted avg       0.51      0.54      0.51      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.4260, Precision: 0.4325, F1 Score: 0.4243
Confusion Matrix: 
 [[0.45141066 0.08777429 0.46081505]
 [0.27142857 0.10714286 0.62142857]
 [0.21582734 0.0647482  0.71942446]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.45      0.46       319
         1.0       0.19      0.11      0.14       140
         2.0       0.63      0.72      0.67       556

    accuracy                           0.55      1015
   macro avg       0.43      0.43      0.42      1015
weighted avg       0.52      0.55      0.53      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5182, Recall: 0.4007, Precision: 0.4041, F1 Score: 0.3981
Confusion Matrix: 
 [[0.42774566 0.06069364 0.51156069]
 [0.31111111 0.08888889 0.6       ]
 [0.22659176 0.08801498 0.68539326]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.43      0.45       346
         1.0       0.15      0.09      0.11       135
         2.0       0.59      0.69      0.63       534

    accuracy                           0.52      1015
   macro avg       0.40      0.40      0.40      1015
weighted avg       0.49      0.52      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.4169, Precision: 0.4242, F1 Score: 0.4106
Confusion Matrix: 
 [[0.44134078 0.06424581 0.49441341]
 [0.3028169  0.07746479 0.61971831]
 [0.21359223 0.05436893 0.73203883]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.44      0.47       358
         1.0       0.18      0.08      0.11       142
         2.0       0.59      0.73      0.65       515

    accuracy                           0.54      1015
   macro avg       0.42      0.42      0.41      1015
weighted avg       0.50      0.54      0.51      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5399, Recall: 0.4365, Precision: 0.4616, F1 Score: 0.4355
Confusion Matrix: 
 [[0.45633803 0.06478873 0.47887324]
 [0.27272727 0.12987013 0.5974026 ]
 [0.22727273 0.04940711 0.72332016]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.46      0.48       355
         1.0       0.29      0.13      0.18       154
         2.0       0.58      0.72      0.65       506

    accuracy                           0.54      1015
   macro avg       0.46      0.44      0.44      1015
weighted avg       0.51      0.54      0.52      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5655, Recall: 0.4530, Precision: 0.4640, F1 Score: 0.4504
Confusion Matrix: 
 [[0.525      0.06666667 0.40833333]
 [0.26896552 0.11034483 0.62068966]
 [0.21372549 0.0627451  0.72352941]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.53      0.54       360
         1.0       0.22      0.11      0.15       145
         2.0       0.61      0.72      0.66       510

    accuracy                           0.57      1015
   macro avg       0.46      0.45      0.45      1015
weighted avg       0.54      0.57      0.55      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.4240, Precision: 0.4481, F1 Score: 0.4232
Confusion Matrix: 
 [[0.4246988  0.06024096 0.51506024]
 [0.31944444 0.11805556 0.5625    ]
 [0.22634508 0.0445269  0.72912801]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.42      0.44       332
         1.0       0.28      0.12      0.17       144
         2.0       0.61      0.73      0.66       539

    accuracy                           0.54      1015
   macro avg       0.45      0.42      0.42      1015
weighted avg       0.51      0.54      0.52      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5143, Recall: 0.3980, Precision: 0.3995, F1 Score: 0.3912
Confusion Matrix: 
 [[0.41975309 0.07716049 0.50308642]
 [0.31168831 0.07792208 0.61038961]
 [0.24394786 0.05959032 0.69646182]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.42      0.43       324
         1.0       0.17      0.08      0.11       154
         2.0       0.59      0.70      0.64       537

    accuracy                           0.51      1015
   macro avg       0.40      0.40      0.39      1015
weighted avg       0.48      0.51      0.49      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5724, Recall: 0.4256, Precision: 0.4267, F1 Score: 0.4213
Confusion Matrix: 
 [[0.4972067  0.05027933 0.45251397]
 [0.29357798 0.05504587 0.65137615]
 [0.22445255 0.05109489 0.72445255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.50      0.52       358
         1.0       0.12      0.06      0.07       109
         2.0       0.63      0.72      0.67       548

    accuracy                           0.57      1015
   macro avg       0.43      0.43      0.42      1015
weighted avg       0.54      0.57      0.55      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.4121, Precision: 0.4184, F1 Score: 0.4113
Confusion Matrix: 
 [[0.42156863 0.07843137 0.5       ]
 [0.33333333 0.1        0.56666667]
 [0.23089983 0.05432937 0.7147708 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.42      0.42       306
         1.0       0.18      0.10      0.13       120
         2.0       0.66      0.71      0.68       589

    accuracy                           0.55      1015
   macro avg       0.42      0.41      0.41      1015
weighted avg       0.53      0.55      0.54      1015

Average metrics:
 Accuracy: 0.5434, Precision: 0.4329, Recall: 0.4216, F1: 0.4187
    model    pca standard tune  accuracy  precision    recall        f1
0  voting  False    False  NaN  0.565320   0.446113  0.432653  0.426843
0  voting  False     True  NaN  0.543448   0.432863  0.421573  0.418720
Model: voting, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4562, Recall: 0.4117, Precision: 0.4100, F1 Score: 0.4057
Confusion Matrix: 
 [[0.45151515 0.22424242 0.32424242]
 [0.33333333 0.27333333 0.39333333]
 [0.27850467 0.21121495 0.51028037]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.45      0.44       330
         1.0       0.18      0.27      0.22       150
         2.0       0.62      0.51      0.56       535

    accuracy                           0.46      1015
   macro avg       0.41      0.41      0.41      1015
weighted avg       0.49      0.46      0.47      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4305, Recall: 0.4050, Precision: 0.4000, F1 Score: 0.3899
Confusion Matrix: 
 [[0.47962382 0.21943574 0.30094044]
 [0.3        0.3        0.4       ]
 [0.29676259 0.26798561 0.4352518 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.48      0.45       319
         1.0       0.16      0.30      0.21       140
         2.0       0.61      0.44      0.51       556

    accuracy                           0.43      1015
   macro avg       0.40      0.40      0.39      1015
weighted avg       0.49      0.43      0.45      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4335, Recall: 0.3901, Precision: 0.3992, F1 Score: 0.3847
Confusion Matrix: 
 [[0.46531792 0.23699422 0.29768786]
 [0.37037037 0.24444444 0.38518519]
 [0.26217228 0.27715356 0.46067416]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.47      0.46       346
         1.0       0.13      0.24      0.17       135
         2.0       0.61      0.46      0.53       534

    accuracy                           0.43      1015
   macro avg       0.40      0.39      0.38      1015
weighted avg       0.50      0.43      0.46      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4305, Recall: 0.4000, Precision: 0.4058, F1 Score: 0.3914
Confusion Matrix: 
 [[0.46648045 0.25139665 0.28212291]
 [0.34507042 0.28873239 0.36619718]
 [0.26990291 0.28543689 0.44466019]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.47      0.47       358
         1.0       0.15      0.29      0.20       142
         2.0       0.60      0.44      0.51       515

    accuracy                           0.43      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.49      0.43      0.45      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4502, Recall: 0.4108, Precision: 0.4095, F1 Score: 0.4060
Confusion Matrix: 
 [[0.46760563 0.21126761 0.32112676]
 [0.30519481 0.27272727 0.42207792]
 [0.28853755 0.21936759 0.49209486]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.47      0.46       355
         1.0       0.18      0.27      0.22       154
         2.0       0.58      0.49      0.53       506

    accuracy                           0.45      1015
   macro avg       0.41      0.41      0.41      1015
weighted avg       0.48      0.45      0.46      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4394, Recall: 0.3943, Precision: 0.4054, F1 Score: 0.3923
Confusion Matrix: 
 [[0.47777778 0.23888889 0.28333333]
 [0.36551724 0.23448276 0.4       ]
 [0.25294118 0.27647059 0.47058824]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.48      0.48       360
         1.0       0.13      0.23      0.17       145
         2.0       0.60      0.47      0.53       510

    accuracy                           0.44      1015
   macro avg       0.41      0.39      0.39      1015
weighted avg       0.49      0.44      0.46      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4493, Recall: 0.4168, Precision: 0.4180, F1 Score: 0.4062
Confusion Matrix: 
 [[0.46987952 0.2439759  0.28614458]
 [0.34027778 0.30555556 0.35416667]
 [0.25788497 0.26716141 0.47495362]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.47      0.46       332
         1.0       0.16      0.31      0.21       144
         2.0       0.64      0.47      0.54       539

    accuracy                           0.45      1015
   macro avg       0.42      0.42      0.41      1015
weighted avg       0.51      0.45      0.47      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4345, Recall: 0.3979, Precision: 0.3949, F1 Score: 0.3903
Confusion Matrix: 
 [[0.47222222 0.18518519 0.34259259]
 [0.35064935 0.25974026 0.38961039]
 [0.29236499 0.24581006 0.46182495]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.47      0.44       324
         1.0       0.17      0.26      0.21       154
         2.0       0.59      0.46      0.52       537

    accuracy                           0.43      1015
   macro avg       0.39      0.40      0.39      1015
weighted avg       0.47      0.43      0.45      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4453, Recall: 0.3862, Precision: 0.3995, F1 Score: 0.3815
Confusion Matrix: 
 [[0.47486034 0.23184358 0.29329609]
 [0.35779817 0.21100917 0.43119266]
 [0.27189781 0.25547445 0.47262774]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.47      0.47       358
         1.0       0.09      0.21      0.13       109
         2.0       0.63      0.47      0.54       548

    accuracy                           0.45      1015
   macro avg       0.40      0.39      0.38      1015
weighted avg       0.52      0.45      0.47      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4384, Recall: 0.3955, Precision: 0.3947, F1 Score: 0.3805
Confusion Matrix: 
 [[0.44117647 0.24509804 0.31372549]
 [0.375      0.275      0.35      ]
 [0.29202037 0.237691   0.47028862]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.38      0.44      0.41       306
         1.0       0.13      0.28      0.18       120
         2.0       0.67      0.47      0.55       589

    accuracy                           0.44      1015
   macro avg       0.39      0.40      0.38      1015
weighted avg       0.52      0.44      0.47      1015

Average metrics:
 Accuracy: 0.4408, Precision: 0.4037, Recall: 0.4008, F1: 0.3928
    model    pca standard tune  accuracy  precision    recall        f1
0  voting  False    False  NaN  0.565320   0.446113  0.432653  0.426843
0  voting  False     True  NaN  0.543448   0.432863  0.421573  0.418720
0  voting   True     True  NaN  0.440788   0.403687  0.400824  0.392846
