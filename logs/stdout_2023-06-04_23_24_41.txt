OrderedDict([('data_path', './dataset/FireDataset.csv'),
             ('param_path', './models/config'),
             ('seed', 64),
             ('redirector', True),
             ('visual', False),
             ('model', 'voting'),
             ('param_load', False),
             ('voting_list', ['dt', 'knn', 'rf', 'ab', 'gb']),
             ('tune', None),
             ('n_iter', 10),
             ('cv', 5),
             ('pca', False),
             ('n_components', 0.95),
             ('smote', False),
             ('eval', 'kfold'),
             ('n_split', 10),
             ('num_class', 3)])
------------------------------------------------------------
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_5km', 'within_10km', 'within_30km', 'within_5km_fact', 'within_10km_fact', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5724, Recall: 0.4047, Precision: 0.5083, F1 Score: 0.3743
Confusion Matrix: 
 [[102   2 226]
 [ 28   2 120]
 [ 57   1 477]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.31      0.39       330
         1.0       0.40      0.01      0.03       150
         2.0       0.58      0.89      0.70       535

    accuracy                           0.57      1015
   macro avg       0.51      0.40      0.37      1015
weighted avg       0.54      0.57      0.50      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5921, Recall: 0.4124, Precision: 0.5222, F1 Score: 0.3891
Confusion Matrix: 
 [[109   1 209]
 [ 19   2 119]
 [ 64   2 490]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.34      0.43       319
         1.0       0.40      0.01      0.03       140
         2.0       0.60      0.88      0.71       556

    accuracy                           0.59      1015
   macro avg       0.52      0.41      0.39      1015
weighted avg       0.56      0.59      0.53      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5665, Recall: 0.3964, Precision: 0.4187, F1 Score: 0.3661
Confusion Matrix: 
 [[105   2 239]
 [ 30   1 104]
 [ 61   4 469]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.30      0.39       346
         1.0       0.14      0.01      0.01       135
         2.0       0.58      0.88      0.70       534

    accuracy                           0.57      1015
   macro avg       0.42      0.40      0.37      1015
weighted avg       0.51      0.57      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3988, Precision: 0.4310, F1 Score: 0.3635
Confusion Matrix: 
 [[106   4 248]
 [ 27   1 114]
 [ 54   1 460]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.30      0.39       358
         1.0       0.17      0.01      0.01       142
         2.0       0.56      0.89      0.69       515

    accuracy                           0.56      1015
   macro avg       0.43      0.40      0.36      1015
weighted avg       0.51      0.56      0.49      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.4059, Precision: 0.5105, F1 Score: 0.3739
Confusion Matrix: 
 [[109   2 244]
 [ 17   3 134]
 [ 52   3 451]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.31      0.41       355
         1.0       0.38      0.02      0.04       154
         2.0       0.54      0.89      0.68       506

    accuracy                           0.55      1015
   macro avg       0.51      0.41      0.37      1015
weighted avg       0.54      0.55      0.49      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.6020, Recall: 0.4402, Precision: 0.5308, F1 Score: 0.4106
Confusion Matrix: 
 [[138   1 221]
 [ 31   2 112]
 [ 36   3 471]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.67      0.38      0.49       360
         1.0       0.33      0.01      0.03       145
         2.0       0.59      0.92      0.72       510

    accuracy                           0.60      1015
   macro avg       0.53      0.44      0.41      1015
weighted avg       0.58      0.60      0.54      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3955, Precision: 0.6209, F1 Score: 0.3720
Confusion Matrix: 
 [[102   0 230]
 [ 27   4 113]
 [ 79   1 459]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.31      0.38       332
         1.0       0.80      0.03      0.05       144
         2.0       0.57      0.85      0.68       539

    accuracy                           0.56      1015
   macro avg       0.62      0.40      0.37      1015
weighted avg       0.58      0.56      0.49      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5695, Recall: 0.4012, Precision: 0.3716, F1 Score: 0.3669
Confusion Matrix: 
 [[104   2 218]
 [ 27   0 127]
 [ 63   0 474]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.32      0.40       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.88      0.70       537

    accuracy                           0.57      1015
   macro avg       0.37      0.40      0.37      1015
weighted avg       0.48      0.57      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5970, Recall: 0.4095, Precision: 0.4430, F1 Score: 0.3872
Confusion Matrix: 
 [[119   3 236]
 [ 20   1  88]
 [ 58   4 486]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.60      0.33      0.43       358
         1.0       0.12      0.01      0.02       109
         2.0       0.60      0.89      0.72       548

    accuracy                           0.60      1015
   macro avg       0.44      0.41      0.39      1015
weighted avg       0.55      0.60      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6177, Recall: 0.4147, Precision: 0.6119, F1 Score: 0.3975
Confusion Matrix: 
 [[106   1 199]
 [ 24   2  94]
 [ 70   0 519]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.35      0.42       306
         1.0       0.67      0.02      0.03       120
         2.0       0.64      0.88      0.74       589

    accuracy                           0.62      1015
   macro avg       0.61      0.41      0.40      1015
weighted avg       0.61      0.62      0.56      1015

Average metrics:
 Accuracy: 0.5787, Precision: 0.4969, Recall: 0.4079, F1: 0.3801
