OrderedDict([('data_path', './dataset/FireDataset.csv'),
             ('param_path', './models/config'),
             ('seed', 64),
             ('redirector', True),
             ('visual', False),
             ('model', 'voting'),
             ('param_load', False),
             ('voting_list', ['dt', 'knn', 'rf', 'ab', 'gb']),
             ('tune', None),
             ('n_iter', 10),
             ('cv', 5),
             ('pca', False),
             ('n_components', 0.95),
             ('smote', False),
             ('standard', True),
             ('eval', 'kfold'),
             ('n_split', 10),
             ('num_class', 3)])
------------------------------------------------------------
Model: dt, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
 Best Score : 0.5705418719211823
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
DecisionTreeClassifier(max_depth=3, min_samples_leaf=9, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3916, Precision: 0.3635, F1 Score: 0.3564
Confusion Matrix: 
 [[0.3        0.         0.7       ]
 [0.15333333 0.         0.84666667]
 [0.12523364 0.         0.87476636]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.30      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.87      0.69       535

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5921, Recall: 0.4084, Precision: 0.3872, F1 Score: 0.3792
Confusion Matrix: 
 [[0.33855799 0.         0.66144201]
 [0.15       0.         0.85      ]
 [0.11330935 0.         0.88669065]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.34      0.42       319
         1.0       0.00      0.00      0.00       140
         2.0       0.60      0.89      0.72       556

    accuracy                           0.59      1015
   macro avg       0.39      0.41      0.38      1015
weighted avg       0.50      0.59      0.52      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3881, Precision: 0.3646, F1 Score: 0.3533
Confusion Matrix: 
 [[0.28612717 0.         0.71387283]
 [0.17777778 0.         0.82222222]
 [0.12172285 0.         0.87827715]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.29      0.37       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.88      0.69       534

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.48      0.56      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5488, Recall: 0.3906, Precision: 0.3625, F1 Score: 0.3528
Confusion Matrix: 
 [[0.29608939 0.         0.70391061]
 [0.1971831  0.         0.8028169 ]
 [0.12427184 0.         0.87572816]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.30      0.38       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.88      0.68       515

    accuracy                           0.55      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.3874, Precision: 0.3557, F1 Score: 0.3451
Confusion Matrix: 
 [[0.27887324 0.         0.72112676]
 [0.19480519 0.         0.80519481]
 [0.11660079 0.         0.88339921]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.28      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.88      0.67       506

    accuracy                           0.54      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.45      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.4125, Precision: 0.3830, F1 Score: 0.3760
Confusion Matrix: 
 [[0.34722222 0.         0.65277778]
 [0.23448276 0.         0.76551724]
 [0.10980392 0.         0.89019608]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.35      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.89      0.69       510

    accuracy                           0.57      1015
   macro avg       0.38      0.41      0.38      1015
weighted avg       0.49      0.57      0.50      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3813, Precision: 0.3537, F1 Score: 0.3470
Confusion Matrix: 
 [[0.28313253 0.         0.71686747]
 [0.13194444 0.         0.86805556]
 [0.13914657 0.         0.86085343]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.28      0.36       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.86      0.68       539

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.46      0.55      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5734, Recall: 0.4029, Precision: 0.3751, F1 Score: 0.3675
Confusion Matrix: 
 [[0.31481481 0.         0.68518519]
 [0.18181818 0.         0.81818182]
 [0.10614525 0.         0.89385475]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.31      0.40       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.89      0.70       537

    accuracy                           0.57      1015
   macro avg       0.38      0.40      0.37      1015
weighted avg       0.48      0.57      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5980, Recall: 0.4112, Precision: 0.3945, F1 Score: 0.3864
Confusion Matrix: 
 [[0.36312849 0.         0.63687151]
 [0.21100917 0.         0.78899083]
 [0.12956204 0.         0.87043796]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.36      0.45       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.87      0.71       548

    accuracy                           0.60      1015
   macro avg       0.39      0.41      0.39      1015
weighted avg       0.53      0.60      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6099, Recall: 0.4000, Precision: 0.3823, F1 Score: 0.3753
Confusion Matrix: 
 [[0.31045752 0.         0.68954248]
 [0.2        0.         0.8       ]
 [0.11035654 0.         0.88964346]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.31      0.39       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.89      0.74       589

    accuracy                           0.61      1015
   macro avg       0.38      0.40      0.38      1015
weighted avg       0.52      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5699, Precision: 0.3722, Recall: 0.3974, F1: 0.3639
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
Model: dt, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
 Best Score : 0.5705418719211823
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
DecisionTreeClassifier(max_depth=3, min_samples_leaf=9, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3916, Precision: 0.3635, F1 Score: 0.3564
Confusion Matrix: 
 [[0.3        0.         0.7       ]
 [0.15333333 0.         0.84666667]
 [0.12523364 0.         0.87476636]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.30      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.87      0.69       535

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5921, Recall: 0.4084, Precision: 0.3872, F1 Score: 0.3792
Confusion Matrix: 
 [[0.33855799 0.         0.66144201]
 [0.15       0.         0.85      ]
 [0.11330935 0.         0.88669065]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.34      0.42       319
         1.0       0.00      0.00      0.00       140
         2.0       0.60      0.89      0.72       556

    accuracy                           0.59      1015
   macro avg       0.39      0.41      0.38      1015
weighted avg       0.50      0.59      0.52      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3881, Precision: 0.3646, F1 Score: 0.3533
Confusion Matrix: 
 [[0.28612717 0.         0.71387283]
 [0.17777778 0.         0.82222222]
 [0.12172285 0.         0.87827715]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.29      0.37       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.88      0.69       534

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.48      0.56      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5488, Recall: 0.3906, Precision: 0.3625, F1 Score: 0.3528
Confusion Matrix: 
 [[0.29608939 0.         0.70391061]
 [0.1971831  0.         0.8028169 ]
 [0.12427184 0.         0.87572816]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.30      0.38       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.88      0.68       515

    accuracy                           0.55      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.3874, Precision: 0.3557, F1 Score: 0.3451
Confusion Matrix: 
 [[0.27887324 0.         0.72112676]
 [0.19480519 0.         0.80519481]
 [0.11660079 0.         0.88339921]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.28      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.88      0.67       506

    accuracy                           0.54      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.45      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.4125, Precision: 0.3830, F1 Score: 0.3760
Confusion Matrix: 
 [[0.34722222 0.         0.65277778]
 [0.23448276 0.         0.76551724]
 [0.10980392 0.         0.89019608]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.35      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.89      0.69       510

    accuracy                           0.57      1015
   macro avg       0.38      0.41      0.38      1015
weighted avg       0.49      0.57      0.50      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3813, Precision: 0.3537, F1 Score: 0.3470
Confusion Matrix: 
 [[0.28313253 0.         0.71686747]
 [0.13194444 0.         0.86805556]
 [0.13914657 0.         0.86085343]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.28      0.36       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.86      0.68       539

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.46      0.55      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5734, Recall: 0.4029, Precision: 0.3751, F1 Score: 0.3675
Confusion Matrix: 
 [[0.31481481 0.         0.68518519]
 [0.18181818 0.         0.81818182]
 [0.10614525 0.         0.89385475]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.31      0.40       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.89      0.70       537

    accuracy                           0.57      1015
   macro avg       0.38      0.40      0.37      1015
weighted avg       0.48      0.57      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5980, Recall: 0.4112, Precision: 0.3945, F1 Score: 0.3864
Confusion Matrix: 
 [[0.36312849 0.         0.63687151]
 [0.21100917 0.         0.78899083]
 [0.12956204 0.         0.87043796]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.36      0.45       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.87      0.71       548

    accuracy                           0.60      1015
   macro avg       0.39      0.41      0.39      1015
weighted avg       0.53      0.60      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6099, Recall: 0.4000, Precision: 0.3823, F1 Score: 0.3753
Confusion Matrix: 
 [[0.31045752 0.         0.68954248]
 [0.2        0.         0.8       ]
 [0.11035654 0.         0.88964346]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.31      0.39       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.89      0.74       589

    accuracy                           0.61      1015
   macro avg       0.38      0.40      0.38      1015
weighted avg       0.52      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5699, Precision: 0.3722, Recall: 0.3974, F1: 0.3639
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
Model: dt, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
 Best Score : 0.5632512315270937
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5468, Recall: 0.3756, Precision: 0.6847, F1 Score: 0.3352
Confusion Matrix: 
 [[0.22121212 0.         0.77878788]
 [0.12666667 0.00666667 0.86666667]
 [0.10093458 0.         0.89906542]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.22      0.31       330
         1.0       1.00      0.01      0.01       150
         2.0       0.55      0.90      0.69       535

    accuracy                           0.55      1015
   macro avg       0.68      0.38      0.34      1015
weighted avg       0.60      0.55      0.46      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5823, Recall: 0.3948, Precision: 0.3765, F1 Score: 0.3621
Confusion Matrix: 
 [[0.28526646 0.         0.71473354]
 [0.15714286 0.         0.84285714]
 [0.10071942 0.         0.89928058]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.29      0.37       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.90      0.71       556

    accuracy                           0.58      1015
   macro avg       0.38      0.39      0.36      1015
weighted avg       0.49      0.58      0.51      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3751, Precision: 0.3538, F1 Score: 0.3341
Confusion Matrix: 
 [[0.2283237  0.         0.7716763 ]
 [0.17037037 0.         0.82962963]
 [0.10299625 0.         0.89700375]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.23      0.31       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.90      0.69       534

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.33      1015
weighted avg       0.47      0.55      0.47      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3969, Precision: 0.4724, F1 Score: 0.3618
Confusion Matrix: 
 [[0.27374302 0.01396648 0.7122905 ]
 [0.15492958 0.01408451 0.83098592]
 [0.09708738 0.         0.90291262]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.27      0.37       358
         1.0       0.29      0.01      0.03       142
         2.0       0.55      0.90      0.69       515

    accuracy                           0.56      1015
   macro avg       0.47      0.40      0.36      1015
weighted avg       0.52      0.56      0.48      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5517, Recall: 0.3944, Precision: 0.3877, F1 Score: 0.3485
Confusion Matrix: 
 [[0.25633803 0.         0.74366197]
 [0.11688312 0.         0.88311688]
 [0.07312253 0.         0.92687747]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.26      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.93      0.68       506

    accuracy                           0.55      1015
   macro avg       0.39      0.39      0.35      1015
weighted avg       0.49      0.55      0.47      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3975, Precision: 0.3702, F1 Score: 0.3591
Confusion Matrix: 
 [[0.30833333 0.         0.69166667]
 [0.2        0.         0.8       ]
 [0.11568627 0.         0.88431373]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.31      0.40       360
         1.0       0.00      0.00      0.00       145
         2.0       0.55      0.88      0.68       510

    accuracy                           0.55      1015
   macro avg       0.37      0.40      0.36      1015
weighted avg       0.48      0.55      0.48      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.3841, Precision: 0.3734, F1 Score: 0.3427
Confusion Matrix: 
 [[0.23192771 0.         0.76807229]
 [0.13194444 0.         0.86805556]
 [0.07977737 0.         0.92022263]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.23      0.33       332
         1.0       0.00      0.00      0.00       144
         2.0       0.57      0.92      0.70       539

    accuracy                           0.56      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.48      0.56      0.48      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3877, Precision: 0.3673, F1 Score: 0.3495
Confusion Matrix: 
 [[0.2654321  0.         0.7345679 ]
 [0.12987013 0.         0.87012987]
 [0.10055866 0.0018622  0.89757914]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.27      0.36       324
         1.0       0.00      0.00      0.00       154
         2.0       0.56      0.90      0.69       537

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.47      0.56      0.48      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5882, Recall: 0.3996, Precision: 0.3943, F1 Score: 0.3728
Confusion Matrix: 
 [[0.31564246 0.         0.68435754]
 [0.13761468 0.         0.86238532]
 [0.11313869 0.00364964 0.88321168]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.32      0.41       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.88      0.71       548

    accuracy                           0.59      1015
   macro avg       0.39      0.40      0.37      1015
weighted avg       0.53      0.59      0.53      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6148, Recall: 0.3993, Precision: 0.4633, F1 Score: 0.3762
Confusion Matrix: 
 [[0.2745098  0.00980392 0.71568627]
 [0.13333333 0.00833333 0.85833333]
 [0.08319185 0.00169779 0.91511036]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.27      0.37       306
         1.0       0.20      0.01      0.02       120
         2.0       0.63      0.92      0.74       589

    accuracy                           0.61      1015
   macro avg       0.46      0.40      0.38      1015
weighted avg       0.56      0.61      0.54      1015

Average metrics:
 Accuracy: 0.5668, Precision: 0.4243, Recall: 0.3905, F1: 0.3542
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
Model: knn, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'n_neighbors': 30}
 Best Score : 0.5465024630541871
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5458, Recall: 0.3800, Precision: 0.3460, F1 Score: 0.3429
Confusion Matrix: 
 [[0.27272727 0.         0.72727273]
 [0.18666667 0.         0.81333333]
 [0.13271028 0.         0.86728972]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.27      0.35       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.87      0.68       535

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.34      1015
weighted avg       0.45      0.55      0.47      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5665, Recall: 0.3857, Precision: 0.3591, F1 Score: 0.3539
Confusion Matrix: 
 [[0.28840125 0.         0.71159875]
 [0.15       0.         0.85      ]
 [0.13129496 0.         0.86870504]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.29      0.36       319
         1.0       0.00      0.00      0.00       140
         2.0       0.58      0.87      0.70       556

    accuracy                           0.57      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.57      0.50      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3759, Precision: 0.3435, F1 Score: 0.3414
Confusion Matrix: 
 [[0.27745665 0.         0.72254335]
 [0.20740741 0.         0.79259259]
 [0.14981273 0.         0.85018727]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.28      0.35       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.85      0.68       534

    accuracy                           0.54      1015
   macro avg       0.34      0.38      0.34      1015
weighted avg       0.45      0.54      0.47      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5488, Recall: 0.3903, Precision: 0.3649, F1 Score: 0.3526
Confusion Matrix: 
 [[0.29329609 0.         0.70670391]
 [0.18309859 0.         0.81690141]
 [0.12038835 0.00194175 0.8776699 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.29      0.38       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.88      0.68       515

    accuracy                           0.55      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5291, Recall: 0.3812, Precision: 0.3502, F1 Score: 0.3400
Confusion Matrix: 
 [[0.27605634 0.         0.72394366]
 [0.16233766 0.         0.83766234]
 [0.13043478 0.00197628 0.86758893]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.28      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.87      0.66       506

    accuracy                           0.53      1015
   macro avg       0.35      0.38      0.34      1015
weighted avg       0.45      0.53      0.45      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.3993, Precision: 0.3662, F1 Score: 0.3614
Confusion Matrix: 
 [[0.31944444 0.         0.68055556]
 [0.24827586 0.         0.75172414]
 [0.12156863 0.         0.87843137]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.32      0.40       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.88      0.68       510

    accuracy                           0.55      1015
   macro avg       0.37      0.40      0.36      1015
weighted avg       0.47      0.55      0.49      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.3723, Precision: 0.3440, F1 Score: 0.3359
Confusion Matrix: 
 [[0.2560241  0.         0.7439759 ]
 [0.125      0.         0.875     ]
 [0.13914657 0.         0.86085343]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.26      0.33       332
         1.0       0.00      0.00      0.00       144
         2.0       0.55      0.86      0.67       539

    accuracy                           0.54      1015
   macro avg       0.34      0.37      0.34      1015
weighted avg       0.45      0.54      0.47      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5291, Recall: 0.3660, Precision: 0.3260, F1 Score: 0.3275
Confusion Matrix: 
 [[0.24691358 0.         0.75308642]
 [0.18181818 0.         0.81818182]
 [0.14897579 0.         0.85102421]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.25      0.31       324
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.85      0.67       537

    accuracy                           0.53      1015
   macro avg       0.33      0.37      0.33      1015
weighted avg       0.43      0.53      0.45      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5931, Recall: 0.4030, Precision: 0.3932, F1 Score: 0.3752
Confusion Matrix: 
 [[0.31843575 0.         0.68156425]
 [0.19266055 0.         0.80733945]
 [0.10948905 0.         0.89051095]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.32      0.41       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.89      0.71       548

    accuracy                           0.59      1015
   macro avg       0.39      0.40      0.38      1015
weighted avg       0.53      0.59      0.53      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5842, Recall: 0.3822, Precision: 0.3560, F1 Score: 0.3568
Confusion Matrix: 
 [[0.29084967 0.         0.70915033]
 [0.19166667 0.         0.80833333]
 [0.14431239 0.         0.85568761]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.29      0.35       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.86      0.72       589

    accuracy                           0.58      1015
   macro avg       0.36      0.38      0.36      1015
weighted avg       0.49      0.58      0.52      1015

Average metrics:
 Accuracy: 0.5534, Precision: 0.3549, Recall: 0.3836, F1: 0.3488
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
Model: knn, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'n_neighbors': 29}
 Best Score : 0.5532019704433498
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 29}
KNeighborsClassifier(n_neighbors=29)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3927, Precision: 0.3598, F1 Score: 0.3580
Confusion Matrix: 
 [[0.30909091 0.0030303  0.68787879]
 [0.19333333 0.         0.80666667]
 [0.13084112 0.         0.86915888]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.31      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.87      0.69       535

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5882, Recall: 0.4136, Precision: 0.7127, F1 Score: 0.3884
Confusion Matrix: 
 [[0.37931034 0.         0.62068966]
 [0.17142857 0.00714286 0.82142857]
 [0.14568345 0.         0.85431655]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.38      0.44       319
         1.0       1.00      0.01      0.01       140
         2.0       0.60      0.85      0.71       556

    accuracy                           0.59      1015
   macro avg       0.71      0.41      0.39      1015
weighted avg       0.64      0.59      0.53      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3951, Precision: 0.3610, F1 Score: 0.3633
Confusion Matrix: 
 [[0.32947977 0.00289017 0.66763006]
 [0.26666667 0.         0.73333333]
 [0.14419476 0.         0.85580524]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.33      0.40       346
         1.0       0.00      0.00      0.00       135
         2.0       0.58      0.86      0.69       534

    accuracy                           0.56      1015
   macro avg       0.36      0.40      0.36      1015
weighted avg       0.48      0.56      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5557, Recall: 0.4028, Precision: 0.5301, F1 Score: 0.3718
Confusion Matrix: 
 [[0.3547486  0.0027933  0.6424581 ]
 [0.25352113 0.00704225 0.73943662]
 [0.15339806 0.         0.84660194]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.35      0.42       358
         1.0       0.50      0.01      0.01       142
         2.0       0.57      0.85      0.68       515

    accuracy                           0.56      1015
   macro avg       0.53      0.40      0.37      1015
weighted avg       0.54      0.56      0.50      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5340, Recall: 0.3879, Precision: 0.3513, F1 Score: 0.3494
Confusion Matrix: 
 [[0.30985915 0.0028169  0.68732394]
 [0.19480519 0.         0.80519481]
 [0.14624506 0.         0.85375494]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.31      0.39       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.85      0.66       506

    accuracy                           0.53      1015
   macro avg       0.35      0.39      0.35      1015
weighted avg       0.45      0.53      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.4086, Precision: 0.3803, F1 Score: 0.3732
Confusion Matrix: 
 [[0.34722222 0.         0.65277778]
 [0.2137931  0.         0.7862069 ]
 [0.11764706 0.00392157 0.87843137]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.35      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.88      0.69       510

    accuracy                           0.56      1015
   macro avg       0.38      0.41      0.37      1015
weighted avg       0.49      0.56      0.50      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5389, Recall: 0.3734, Precision: 0.3389, F1 Score: 0.3388
Confusion Matrix: 
 [[0.27409639 0.         0.72590361]
 [0.18055556 0.         0.81944444]
 [0.15213358 0.00185529 0.84601113]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.27      0.34       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.85      0.67       539

    accuracy                           0.54      1015
   macro avg       0.34      0.37      0.34      1015
weighted avg       0.45      0.54      0.47      1015

Fold 7
