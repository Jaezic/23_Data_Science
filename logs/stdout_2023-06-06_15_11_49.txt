OrderedDict([('data_path', './dataset/FireDataset.csv'),
             ('param_path', './models/config'),
             ('seed', 64),
             ('redirector', True),
             ('visual', False),
             ('model', 'ab'),
             ('param_load', False),
             ('voting_list', ['dt', 'knn', 'rf', 'ab', 'gb']),
             ('tune', 'grid'),
             ('n_iter', 10),
             ('cv', 5),
             ('pca', False),
             ('n_components', 0.95),
             ('smote', False),
             ('standard', False),
             ('eval', 'kfold'),
             ('n_split', 10),
             ('num_class', 3)])
------------------------------------------------------------
Model: voting, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.4066, Precision: 0.6167, F1 Score: 0.3787
Confusion Matrix: 
 [[0.32121212 0.0030303  0.67575758]
 [0.22666667 0.02       0.75333333]
 [0.12149533 0.         0.87850467]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.32      0.40       330
         1.0       0.75      0.02      0.04       150
         2.0       0.58      0.88      0.70       535

    accuracy                           0.57      1015
   macro avg       0.62      0.41      0.38      1015
weighted avg       0.59      0.57      0.50      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.6020, Recall: 0.4251, Precision: 0.5958, F1 Score: 0.4053
Confusion Matrix: 
 [[0.37617555 0.0031348  0.62068966]
 [0.14285714 0.02142857 0.83571429]
 [0.1205036  0.00179856 0.87769784]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.38      0.46       319
         1.0       0.60      0.02      0.04       140
         2.0       0.61      0.88      0.72       556

    accuracy                           0.60      1015
   macro avg       0.60      0.43      0.41      1015
weighted avg       0.60      0.60      0.54      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5754, Recall: 0.4126, Precision: 0.6377, F1 Score: 0.3914
Confusion Matrix: 
 [[0.34682081 0.00289017 0.65028902]
 [0.25925926 0.02962963 0.71111111]
 [0.13857678 0.         0.86142322]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.35      0.42       346
         1.0       0.80      0.03      0.06       135
         2.0       0.59      0.86      0.70       534

    accuracy                           0.58      1015
   macro avg       0.64      0.41      0.39      1015
weighted avg       0.59      0.58      0.52      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5695, Recall: 0.4102, Precision: 0.4665, F1 Score: 0.3777
Confusion Matrix: 
 [[0.33798883 0.00837989 0.65363128]
 [0.1971831  0.00704225 0.79577465]
 [0.11456311 0.         0.88543689]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.34      0.43       358
         1.0       0.25      0.01      0.01       142
         2.0       0.57      0.89      0.69       515

    accuracy                           0.57      1015
   macro avg       0.47      0.41      0.38      1015
weighted avg       0.53      0.57      0.50      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.4093, Precision: 0.5481, F1 Score: 0.3760
Confusion Matrix: 
 [[0.32957746 0.0056338  0.66478873]
 [0.14285714 0.01298701 0.84415584]
 [0.11462451 0.         0.88537549]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.33      0.42       355
         1.0       0.50      0.01      0.03       154
         2.0       0.55      0.89      0.68       506

    accuracy                           0.56      1015
   macro avg       0.55      0.41      0.38      1015
weighted avg       0.56      0.56      0.49      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5980, Recall: 0.4351, Precision: 0.5235, F1 Score: 0.4020
Confusion Matrix: 
 [[0.375      0.         0.625     ]
 [0.24137931 0.00689655 0.75172414]
 [0.07254902 0.00392157 0.92352941]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.38      0.48       360
         1.0       0.33      0.01      0.01       145
         2.0       0.59      0.92      0.72       510

    accuracy                           0.60      1015
   macro avg       0.52      0.44      0.40      1015
weighted avg       0.57      0.60      0.53      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5764, Recall: 0.4104, Precision: 0.6264, F1 Score: 0.3861
Confusion Matrix: 
 [[0.34036145 0.00301205 0.65662651]
 [0.16666667 0.02083333 0.8125    ]
 [0.12987013 0.         0.87012987]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.34      0.42       332
         1.0       0.75      0.02      0.04       144
         2.0       0.58      0.87      0.70       539

    accuracy                           0.58      1015
   macro avg       0.63      0.41      0.39      1015
weighted avg       0.59      0.58      0.51      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3981, Precision: 0.3658, F1 Score: 0.3654
Confusion Matrix: 
 [[0.33024691 0.01234568 0.65740741]
 [0.18181818 0.         0.81818182]
 [0.13221601 0.00372439 0.86405959]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.33      0.40       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.86      0.69       537

    accuracy                           0.56      1015
   macro avg       0.37      0.40      0.37      1015
weighted avg       0.47      0.56      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6128, Recall: 0.4284, Precision: 0.5751, F1 Score: 0.4114
Confusion Matrix: 
 [[0.39106145 0.         0.60893855]
 [0.21100917 0.01834862 0.7706422 ]
 [0.12043796 0.00364964 0.87591241]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.39      0.48       358
         1.0       0.50      0.02      0.04       109
         2.0       0.61      0.88      0.72       548

    accuracy                           0.61      1015
   macro avg       0.58      0.43      0.41      1015
weighted avg       0.60      0.61      0.56      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6089, Recall: 0.4032, Precision: 0.4387, F1 Score: 0.3828
Confusion Matrix: 
 [[0.32026144 0.00653595 0.67320261]
 [0.20833333 0.00833333 0.78333333]
 [0.11375212 0.00509338 0.8811545 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.32      0.40       306
         1.0       0.17      0.01      0.02       120
         2.0       0.63      0.88      0.74       589

    accuracy                           0.61      1015
   macro avg       0.44      0.40      0.38      1015
weighted avg       0.54      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5834, Precision: 0.5394, Recall: 0.4139, F1: 0.3877
    model    pca standard  ... precision    recall        f1
0  voting  False    False  ...   0.53943  0.413914  0.387683

[1 rows x 8 columns]
Model: voting, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5734, Recall: 0.4116, Precision: 0.5630, F1 Score: 0.3872
Confusion Matrix: 
 [[0.33333333 0.0030303  0.66363636]
 [0.20666667 0.02666667 0.76666667]
 [0.12149533 0.00373832 0.87476636]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.33      0.41       330
         1.0       0.57      0.03      0.05       150
         2.0       0.58      0.87      0.70       535

    accuracy                           0.57      1015
   macro avg       0.56      0.41      0.39      1015
weighted avg       0.57      0.57      0.51      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.6039, Recall: 0.4259, Precision: 0.5948, F1 Score: 0.4054
Confusion Matrix: 
 [[0.37304075 0.0031348  0.62382445]
 [0.17857143 0.02142857 0.8       ]
 [0.11510791 0.00179856 0.88309353]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.37      0.45       319
         1.0       0.60      0.02      0.04       140
         2.0       0.61      0.88      0.72       556

    accuracy                           0.60      1015
   macro avg       0.59      0.43      0.41      1015
weighted avg       0.60      0.60      0.54      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5714, Recall: 0.4110, Precision: 0.5759, F1 Score: 0.3918
Confusion Matrix: 
 [[0.33815029 0.00289017 0.65895954]
 [0.26666667 0.03703704 0.6962963 ]
 [0.13857678 0.00374532 0.8576779 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.34      0.41       346
         1.0       0.62      0.04      0.07       135
         2.0       0.59      0.86      0.70       534

    accuracy                           0.57      1015
   macro avg       0.58      0.41      0.39      1015
weighted avg       0.57      0.57      0.52      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5764, Recall: 0.4172, Precision: 0.4424, F1 Score: 0.3863
Confusion Matrix: 
 [[0.36312849 0.01117318 0.62569832]
 [0.23239437 0.00704225 0.76056338]
 [0.11650485 0.00194175 0.8815534 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.36      0.45       358
         1.0       0.17      0.01      0.01       142
         2.0       0.58      0.88      0.70       515

    accuracy                           0.58      1015
   macro avg       0.44      0.42      0.39      1015
weighted avg       0.52      0.58      0.51      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5635, Recall: 0.4142, Precision: 0.4977, F1 Score: 0.3810
Confusion Matrix: 
 [[0.36056338 0.0028169  0.63661972]
 [0.13636364 0.00649351 0.85714286]
 [0.12252964 0.00197628 0.87549407]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.36      0.45       355
         1.0       0.33      0.01      0.01       154
         2.0       0.55      0.88      0.68       506

    accuracy                           0.56      1015
   macro avg       0.50      0.41      0.38      1015
weighted avg       0.54      0.56      0.50      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.6030, Recall: 0.4398, Precision: 0.5291, F1 Score: 0.4076
Confusion Matrix: 
 [[0.38888889 0.00277778 0.60833333]
 [0.22068966 0.00689655 0.77241379]
 [0.0745098  0.00196078 0.92352941]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.67      0.39      0.49       360
         1.0       0.33      0.01      0.01       145
         2.0       0.59      0.92      0.72       510

    accuracy                           0.60      1015
   macro avg       0.53      0.44      0.41      1015
weighted avg       0.58      0.60      0.54      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.4015, Precision: 0.6968, F1 Score: 0.3767
Confusion Matrix: 
 [[0.32831325 0.         0.67168675]
 [0.17361111 0.02083333 0.80555556]
 [0.14471243 0.         0.85528757]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.33      0.40       332
         1.0       1.00      0.02      0.04       144
         2.0       0.58      0.86      0.69       539

    accuracy                           0.56      1015
   macro avg       0.70      0.40      0.38      1015
weighted avg       0.62      0.56      0.50      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5734, Recall: 0.4066, Precision: 0.3740, F1 Score: 0.3735
Confusion Matrix: 
 [[0.34259259 0.00925926 0.64814815]
 [0.2012987  0.         0.7987013 ]
 [0.12104283 0.0018622  0.87709497]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.34      0.42       324
         1.0       0.00      0.00      0.00       154
         2.0       0.59      0.88      0.70       537

    accuracy                           0.57      1015
   macro avg       0.37      0.41      0.37      1015
weighted avg       0.48      0.57      0.51      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6059, Recall: 0.4239, Precision: 0.4887, F1 Score: 0.4076
Confusion Matrix: 
 [[0.38826816 0.00558659 0.60614525]
 [0.18348624 0.01834862 0.79816514]
 [0.12773723 0.00729927 0.8649635 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.39      0.47       358
         1.0       0.25      0.02      0.03       109
         2.0       0.61      0.86      0.71       548

    accuracy                           0.61      1015
   macro avg       0.49      0.42      0.41      1015
weighted avg       0.57      0.61      0.56      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6158, Recall: 0.4120, Precision: 0.5539, F1 Score: 0.3944
Confusion Matrix: 
 [[0.33660131 0.00326797 0.66013072]
 [0.21666667 0.01666667 0.76666667]
 [0.11544992 0.00169779 0.88285229]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.34      0.41       306
         1.0       0.50      0.02      0.03       120
         2.0       0.64      0.88      0.74       589

    accuracy                           0.62      1015
   macro avg       0.55      0.41      0.39      1015
weighted avg       0.59      0.62      0.56      1015

Average metrics:
 Accuracy: 0.5851, Precision: 0.5316, Recall: 0.4164, F1: 0.3911
    model    pca standard  ... precision    recall        f1
0  voting  False    False  ...  0.539430  0.413914  0.387683
0  voting  False     True  ...  0.531626  0.416354  0.391135

[2 rows x 8 columns]
Model: voting, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3892, Precision: 0.4756, F1 Score: 0.3609
Confusion Matrix: 
 [[0.28787879 0.00606061 0.70606061]
 [0.19333333 0.02       0.78666667]
 [0.13457944 0.00560748 0.85981308]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.29      0.36       330
         1.0       0.38      0.02      0.04       150
         2.0       0.57      0.86      0.68       535

    accuracy                           0.55      1015
   macro avg       0.48      0.39      0.36      1015
weighted avg       0.51      0.55      0.48      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5872, Recall: 0.4121, Precision: 0.4909, F1 Score: 0.3913
Confusion Matrix: 
 [[0.34796238 0.00626959 0.64576803]
 [0.18571429 0.02142857 0.79285714]
 [0.12589928 0.00719424 0.86690647]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.35      0.42       319
         1.0       0.33      0.02      0.04       140
         2.0       0.60      0.87      0.71       556

    accuracy                           0.59      1015
   macro avg       0.49      0.41      0.39      1015
weighted avg       0.54      0.59      0.53      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3957, Precision: 0.4760, F1 Score: 0.3679
Confusion Matrix: 
 [[0.30346821 0.00289017 0.69364162]
 [0.22222222 0.01481481 0.76296296]
 [0.12546816 0.00561798 0.86891386]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.30      0.38       346
         1.0       0.33      0.01      0.03       135
         2.0       0.57      0.87      0.69       534

    accuracy                           0.56      1015
   macro avg       0.48      0.40      0.37      1015
weighted avg       0.52      0.56      0.50      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5616, Recall: 0.4013, Precision: 0.3717, F1 Score: 0.3643
Confusion Matrix: 
 [[0.31843575 0.         0.68156425]
 [0.23943662 0.         0.76056338]
 [0.11456311 0.         0.88543689]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.32      0.40       358
         1.0       0.00      0.00      0.00       142
         2.0       0.56      0.89      0.69       515

    accuracy                           0.56      1015
   macro avg       0.37      0.40      0.36      1015
weighted avg       0.48      0.56      0.49      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5399, Recall: 0.3924, Precision: 0.3591, F1 Score: 0.3548
Confusion Matrix: 
 [[0.31549296 0.01126761 0.67323944]
 [0.2012987  0.         0.7987013 ]
 [0.13438735 0.00395257 0.86166008]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.32      0.40       355
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.86      0.67       506

    accuracy                           0.54      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.46      0.54      0.47      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5882, Recall: 0.4240, Precision: 0.5202, F1 Score: 0.3875
Confusion Matrix: 
 [[0.32777778 0.00555556 0.66666667]
 [0.2137931  0.00689655 0.77931034]
 [0.0627451  0.         0.9372549 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.33      0.44       360
         1.0       0.33      0.01      0.01       145
         2.0       0.58      0.94      0.71       510

    accuracy                           0.59      1015
   macro avg       0.52      0.42      0.39      1015
weighted avg       0.57      0.59      0.51      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5448, Recall: 0.3772, Precision: 0.4541, F1 Score: 0.3436
Confusion Matrix: 
 [[0.26204819 0.         0.73795181]
 [0.19444444 0.00694444 0.79861111]
 [0.13358071 0.00371058 0.86270872]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.26      0.34       332
         1.0       0.33      0.01      0.01       144
         2.0       0.56      0.86      0.68       539

    accuracy                           0.54      1015
   macro avg       0.45      0.38      0.34      1015
weighted avg       0.50      0.54      0.47      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3918, Precision: 0.3571, F1 Score: 0.3556
Confusion Matrix: 
 [[0.2962963  0.00308642 0.70061728]
 [0.22077922 0.         0.77922078]
 [0.11918063 0.0018622  0.87895717]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.30      0.37       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.88      0.70       537

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.36      1015
weighted avg       0.46      0.56      0.49      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5921, Recall: 0.4055, Precision: 0.5003, F1 Score: 0.3815
Confusion Matrix: 
 [[0.32402235 0.00558659 0.67039106]
 [0.22018349 0.00917431 0.7706422 ]
 [0.11678832 0.         0.88321168]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.32      0.41       358
         1.0       0.33      0.01      0.02       109
         2.0       0.60      0.88      0.71       548

    accuracy                           0.59      1015
   macro avg       0.50      0.41      0.38      1015
weighted avg       0.56      0.59      0.53      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6118, Recall: 0.4081, Precision: 0.7180, F1 Score: 0.3877
Confusion Matrix: 
 [[0.33986928 0.         0.66013072]
 [0.19166667 0.00833333 0.8       ]
 [0.12393888 0.         0.87606112]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.34      0.41       306
         1.0       1.00      0.01      0.02       120
         2.0       0.63      0.88      0.74       589

    accuracy                           0.61      1015
   macro avg       0.72      0.41      0.39      1015
weighted avg       0.64      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5698, Precision: 0.4723, Recall: 0.3997, F1: 0.3695
    model    pca standard  ... precision    recall        f1
0  voting  False    False  ...  0.539430  0.413914  0.387683
0  voting  False     True  ...  0.531626  0.416354  0.391135
0  voting   True     True  ...  0.472293  0.399726  0.369509

[3 rows x 8 columns]
