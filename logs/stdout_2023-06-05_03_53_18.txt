OrderedDict([('data_path', './dataset/FireDataset.csv'),
             ('param_path', './models/config'),
             ('seed', 64),
             ('redirector', True),
             ('visual', False),
             ('model', 'ab'),
             ('param_load', False),
             ('voting_list', ['dt', 'knn', 'rf', 'ab', 'gb']),
             ('tune', 'grid'),
             ('n_iter', 10),
             ('cv', 5),
             ('pca', False),
             ('n_components', 0.95),
             ('smote', False),
             ('standard', False),
             ('eval', 'kfold'),
             ('n_split', 10),
             ('num_class', 3)])
------------------------------------------------------------
Model: dt, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
 Best Score : 0.5705418719211823
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
DecisionTreeClassifier(max_depth=3, min_samples_leaf=9, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3916, Precision: 0.3635, F1 Score: 0.3564
Confusion Matrix: 
 [[0.3        0.         0.7       ]
 [0.15333333 0.         0.84666667]
 [0.12523364 0.         0.87476636]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.30      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.87      0.69       535

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5921, Recall: 0.4084, Precision: 0.3872, F1 Score: 0.3792
Confusion Matrix: 
 [[0.33855799 0.         0.66144201]
 [0.15       0.         0.85      ]
 [0.11330935 0.         0.88669065]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.34      0.42       319
         1.0       0.00      0.00      0.00       140
         2.0       0.60      0.89      0.72       556

    accuracy                           0.59      1015
   macro avg       0.39      0.41      0.38      1015
weighted avg       0.50      0.59      0.52      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3881, Precision: 0.3646, F1 Score: 0.3533
Confusion Matrix: 
 [[0.28612717 0.         0.71387283]
 [0.17777778 0.         0.82222222]
 [0.12172285 0.         0.87827715]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.29      0.37       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.88      0.69       534

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.48      0.56      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5488, Recall: 0.3906, Precision: 0.3625, F1 Score: 0.3528
Confusion Matrix: 
 [[0.29608939 0.         0.70391061]
 [0.1971831  0.         0.8028169 ]
 [0.12427184 0.         0.87572816]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.30      0.38       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.88      0.68       515

    accuracy                           0.55      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.3874, Precision: 0.3557, F1 Score: 0.3451
Confusion Matrix: 
 [[0.27887324 0.         0.72112676]
 [0.19480519 0.         0.80519481]
 [0.11660079 0.         0.88339921]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.28      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.88      0.67       506

    accuracy                           0.54      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.45      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.4125, Precision: 0.3830, F1 Score: 0.3760
Confusion Matrix: 
 [[0.34722222 0.         0.65277778]
 [0.23448276 0.         0.76551724]
 [0.10980392 0.         0.89019608]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.35      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.89      0.69       510

    accuracy                           0.57      1015
   macro avg       0.38      0.41      0.38      1015
weighted avg       0.49      0.57      0.50      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3813, Precision: 0.3537, F1 Score: 0.3470
Confusion Matrix: 
 [[0.28313253 0.         0.71686747]
 [0.13194444 0.         0.86805556]
 [0.13914657 0.         0.86085343]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.28      0.36       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.86      0.68       539

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.46      0.55      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5734, Recall: 0.4029, Precision: 0.3751, F1 Score: 0.3675
Confusion Matrix: 
 [[0.31481481 0.         0.68518519]
 [0.18181818 0.         0.81818182]
 [0.10614525 0.         0.89385475]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.31      0.40       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.89      0.70       537

    accuracy                           0.57      1015
   macro avg       0.38      0.40      0.37      1015
weighted avg       0.48      0.57      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5980, Recall: 0.4112, Precision: 0.3945, F1 Score: 0.3864
Confusion Matrix: 
 [[0.36312849 0.         0.63687151]
 [0.21100917 0.         0.78899083]
 [0.12956204 0.         0.87043796]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.36      0.45       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.87      0.71       548

    accuracy                           0.60      1015
   macro avg       0.39      0.41      0.39      1015
weighted avg       0.53      0.60      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6099, Recall: 0.4000, Precision: 0.3823, F1 Score: 0.3753
Confusion Matrix: 
 [[0.31045752 0.         0.68954248]
 [0.2        0.         0.8       ]
 [0.11035654 0.         0.88964346]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.31      0.39       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.89      0.74       589

    accuracy                           0.61      1015
   macro avg       0.38      0.40      0.38      1015
weighted avg       0.52      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5699, Precision: 0.3722, Recall: 0.3974, F1: 0.3639
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
Model: dt, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
 Best Score : 0.5705418719211823
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
DecisionTreeClassifier(max_depth=3, min_samples_leaf=9, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3916, Precision: 0.3635, F1 Score: 0.3564
Confusion Matrix: 
 [[0.3        0.         0.7       ]
 [0.15333333 0.         0.84666667]
 [0.12523364 0.         0.87476636]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.30      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.87      0.69       535

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5921, Recall: 0.4084, Precision: 0.3872, F1 Score: 0.3792
Confusion Matrix: 
 [[0.33855799 0.         0.66144201]
 [0.15       0.         0.85      ]
 [0.11330935 0.         0.88669065]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.34      0.42       319
         1.0       0.00      0.00      0.00       140
         2.0       0.60      0.89      0.72       556

    accuracy                           0.59      1015
   macro avg       0.39      0.41      0.38      1015
weighted avg       0.50      0.59      0.52      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3881, Precision: 0.3646, F1 Score: 0.3533
Confusion Matrix: 
 [[0.28612717 0.         0.71387283]
 [0.17777778 0.         0.82222222]
 [0.12172285 0.         0.87827715]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.29      0.37       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.88      0.69       534

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.48      0.56      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5488, Recall: 0.3906, Precision: 0.3625, F1 Score: 0.3528
Confusion Matrix: 
 [[0.29608939 0.         0.70391061]
 [0.1971831  0.         0.8028169 ]
 [0.12427184 0.         0.87572816]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.30      0.38       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.88      0.68       515

    accuracy                           0.55      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.3874, Precision: 0.3557, F1 Score: 0.3451
Confusion Matrix: 
 [[0.27887324 0.         0.72112676]
 [0.19480519 0.         0.80519481]
 [0.11660079 0.         0.88339921]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.28      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.88      0.67       506

    accuracy                           0.54      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.45      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.4125, Precision: 0.3830, F1 Score: 0.3760
Confusion Matrix: 
 [[0.34722222 0.         0.65277778]
 [0.23448276 0.         0.76551724]
 [0.10980392 0.         0.89019608]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.35      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.89      0.69       510

    accuracy                           0.57      1015
   macro avg       0.38      0.41      0.38      1015
weighted avg       0.49      0.57      0.50      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3813, Precision: 0.3537, F1 Score: 0.3470
Confusion Matrix: 
 [[0.28313253 0.         0.71686747]
 [0.13194444 0.         0.86805556]
 [0.13914657 0.         0.86085343]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.28      0.36       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.86      0.68       539

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.46      0.55      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5734, Recall: 0.4029, Precision: 0.3751, F1 Score: 0.3675
Confusion Matrix: 
 [[0.31481481 0.         0.68518519]
 [0.18181818 0.         0.81818182]
 [0.10614525 0.         0.89385475]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.31      0.40       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.89      0.70       537

    accuracy                           0.57      1015
   macro avg       0.38      0.40      0.37      1015
weighted avg       0.48      0.57      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5980, Recall: 0.4112, Precision: 0.3945, F1 Score: 0.3864
Confusion Matrix: 
 [[0.36312849 0.         0.63687151]
 [0.21100917 0.         0.78899083]
 [0.12956204 0.         0.87043796]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.36      0.45       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.87      0.71       548

    accuracy                           0.60      1015
   macro avg       0.39      0.41      0.39      1015
weighted avg       0.53      0.60      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6099, Recall: 0.4000, Precision: 0.3823, F1 Score: 0.3753
Confusion Matrix: 
 [[0.31045752 0.         0.68954248]
 [0.2        0.         0.8       ]
 [0.11035654 0.         0.88964346]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.31      0.39       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.89      0.74       589

    accuracy                           0.61      1015
   macro avg       0.38      0.40      0.38      1015
weighted avg       0.52      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5699, Precision: 0.3722, Recall: 0.3974, F1: 0.3639
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
Model: dt, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
 Best Score : 0.5632512315270937
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5468, Recall: 0.3756, Precision: 0.6847, F1 Score: 0.3352
Confusion Matrix: 
 [[0.22121212 0.         0.77878788]
 [0.12666667 0.00666667 0.86666667]
 [0.10093458 0.         0.89906542]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.22      0.31       330
         1.0       1.00      0.01      0.01       150
         2.0       0.55      0.90      0.69       535

    accuracy                           0.55      1015
   macro avg       0.68      0.38      0.34      1015
weighted avg       0.60      0.55      0.46      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5823, Recall: 0.3948, Precision: 0.3765, F1 Score: 0.3621
Confusion Matrix: 
 [[0.28526646 0.         0.71473354]
 [0.15714286 0.         0.84285714]
 [0.10071942 0.         0.89928058]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.29      0.37       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.90      0.71       556

    accuracy                           0.58      1015
   macro avg       0.38      0.39      0.36      1015
weighted avg       0.49      0.58      0.51      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3751, Precision: 0.3538, F1 Score: 0.3341
Confusion Matrix: 
 [[0.2283237  0.         0.7716763 ]
 [0.17037037 0.         0.82962963]
 [0.10299625 0.         0.89700375]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.23      0.31       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.90      0.69       534

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.33      1015
weighted avg       0.47      0.55      0.47      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3969, Precision: 0.4724, F1 Score: 0.3618
Confusion Matrix: 
 [[0.27374302 0.01396648 0.7122905 ]
 [0.15492958 0.01408451 0.83098592]
 [0.09708738 0.         0.90291262]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.27      0.37       358
         1.0       0.29      0.01      0.03       142
         2.0       0.55      0.90      0.69       515

    accuracy                           0.56      1015
   macro avg       0.47      0.40      0.36      1015
weighted avg       0.52      0.56      0.48      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5517, Recall: 0.3944, Precision: 0.3877, F1 Score: 0.3485
Confusion Matrix: 
 [[0.25633803 0.         0.74366197]
 [0.11688312 0.         0.88311688]
 [0.07312253 0.         0.92687747]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.26      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.93      0.68       506

    accuracy                           0.55      1015
   macro avg       0.39      0.39      0.35      1015
weighted avg       0.49      0.55      0.47      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3975, Precision: 0.3702, F1 Score: 0.3591
Confusion Matrix: 
 [[0.30833333 0.         0.69166667]
 [0.2        0.         0.8       ]
 [0.11568627 0.         0.88431373]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.31      0.40       360
         1.0       0.00      0.00      0.00       145
         2.0       0.55      0.88      0.68       510

    accuracy                           0.55      1015
   macro avg       0.37      0.40      0.36      1015
weighted avg       0.48      0.55      0.48      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.3841, Precision: 0.3734, F1 Score: 0.3427
Confusion Matrix: 
 [[0.23192771 0.         0.76807229]
 [0.13194444 0.         0.86805556]
 [0.07977737 0.         0.92022263]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.55      0.23      0.33       332
         1.0       0.00      0.00      0.00       144
         2.0       0.57      0.92      0.70       539

    accuracy                           0.56      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.48      0.56      0.48      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3877, Precision: 0.3673, F1 Score: 0.3495
Confusion Matrix: 
 [[0.2654321  0.         0.7345679 ]
 [0.12987013 0.         0.87012987]
 [0.10055866 0.0018622  0.89757914]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.27      0.36       324
         1.0       0.00      0.00      0.00       154
         2.0       0.56      0.90      0.69       537

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.47      0.56      0.48      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5882, Recall: 0.3996, Precision: 0.3943, F1 Score: 0.3728
Confusion Matrix: 
 [[0.31564246 0.         0.68435754]
 [0.13761468 0.         0.86238532]
 [0.11313869 0.00364964 0.88321168]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.32      0.41       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.88      0.71       548

    accuracy                           0.59      1015
   macro avg       0.39      0.40      0.37      1015
weighted avg       0.53      0.59      0.53      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6148, Recall: 0.3993, Precision: 0.4633, F1 Score: 0.3762
Confusion Matrix: 
 [[0.2745098  0.00980392 0.71568627]
 [0.13333333 0.00833333 0.85833333]
 [0.08319185 0.00169779 0.91511036]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.27      0.37       306
         1.0       0.20      0.01      0.02       120
         2.0       0.63      0.92      0.74       589

    accuracy                           0.61      1015
   macro avg       0.46      0.40      0.38      1015
weighted avg       0.56      0.61      0.54      1015

Average metrics:
 Accuracy: 0.5668, Precision: 0.4243, Recall: 0.3905, F1: 0.3542
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
Model: knn, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'n_neighbors': 30}
 Best Score : 0.5465024630541871
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5458, Recall: 0.3800, Precision: 0.3460, F1 Score: 0.3429
Confusion Matrix: 
 [[0.27272727 0.         0.72727273]
 [0.18666667 0.         0.81333333]
 [0.13271028 0.         0.86728972]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.27      0.35       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.87      0.68       535

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.34      1015
weighted avg       0.45      0.55      0.47      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5665, Recall: 0.3857, Precision: 0.3591, F1 Score: 0.3539
Confusion Matrix: 
 [[0.28840125 0.         0.71159875]
 [0.15       0.         0.85      ]
 [0.13129496 0.         0.86870504]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.29      0.36       319
         1.0       0.00      0.00      0.00       140
         2.0       0.58      0.87      0.70       556

    accuracy                           0.57      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.57      0.50      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3759, Precision: 0.3435, F1 Score: 0.3414
Confusion Matrix: 
 [[0.27745665 0.         0.72254335]
 [0.20740741 0.         0.79259259]
 [0.14981273 0.         0.85018727]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.28      0.35       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.85      0.68       534

    accuracy                           0.54      1015
   macro avg       0.34      0.38      0.34      1015
weighted avg       0.45      0.54      0.47      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5488, Recall: 0.3903, Precision: 0.3649, F1 Score: 0.3526
Confusion Matrix: 
 [[0.29329609 0.         0.70670391]
 [0.18309859 0.         0.81690141]
 [0.12038835 0.00194175 0.8776699 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.29      0.38       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.88      0.68       515

    accuracy                           0.55      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5291, Recall: 0.3812, Precision: 0.3502, F1 Score: 0.3400
Confusion Matrix: 
 [[0.27605634 0.         0.72394366]
 [0.16233766 0.         0.83766234]
 [0.13043478 0.00197628 0.86758893]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.28      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.87      0.66       506

    accuracy                           0.53      1015
   macro avg       0.35      0.38      0.34      1015
weighted avg       0.45      0.53      0.45      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.3993, Precision: 0.3662, F1 Score: 0.3614
Confusion Matrix: 
 [[0.31944444 0.         0.68055556]
 [0.24827586 0.         0.75172414]
 [0.12156863 0.         0.87843137]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.32      0.40       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.88      0.68       510

    accuracy                           0.55      1015
   macro avg       0.37      0.40      0.36      1015
weighted avg       0.47      0.55      0.49      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.3723, Precision: 0.3440, F1 Score: 0.3359
Confusion Matrix: 
 [[0.2560241  0.         0.7439759 ]
 [0.125      0.         0.875     ]
 [0.13914657 0.         0.86085343]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.26      0.33       332
         1.0       0.00      0.00      0.00       144
         2.0       0.55      0.86      0.67       539

    accuracy                           0.54      1015
   macro avg       0.34      0.37      0.34      1015
weighted avg       0.45      0.54      0.47      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5291, Recall: 0.3660, Precision: 0.3260, F1 Score: 0.3275
Confusion Matrix: 
 [[0.24691358 0.         0.75308642]
 [0.18181818 0.         0.81818182]
 [0.14897579 0.         0.85102421]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.25      0.31       324
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.85      0.67       537

    accuracy                           0.53      1015
   macro avg       0.33      0.37      0.33      1015
weighted avg       0.43      0.53      0.45      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5931, Recall: 0.4030, Precision: 0.3932, F1 Score: 0.3752
Confusion Matrix: 
 [[0.31843575 0.         0.68156425]
 [0.19266055 0.         0.80733945]
 [0.10948905 0.         0.89051095]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.32      0.41       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.89      0.71       548

    accuracy                           0.59      1015
   macro avg       0.39      0.40      0.38      1015
weighted avg       0.53      0.59      0.53      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5842, Recall: 0.3822, Precision: 0.3560, F1 Score: 0.3568
Confusion Matrix: 
 [[0.29084967 0.         0.70915033]
 [0.19166667 0.         0.80833333]
 [0.14431239 0.         0.85568761]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.29      0.35       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.86      0.72       589

    accuracy                           0.58      1015
   macro avg       0.36      0.38      0.36      1015
weighted avg       0.49      0.58      0.52      1015

Average metrics:
 Accuracy: 0.5534, Precision: 0.3549, Recall: 0.3836, F1: 0.3488
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
Model: knn, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'n_neighbors': 29}
 Best Score : 0.5532019704433498
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 29}
KNeighborsClassifier(n_neighbors=29)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3927, Precision: 0.3598, F1 Score: 0.3580
Confusion Matrix: 
 [[0.30909091 0.0030303  0.68787879]
 [0.19333333 0.         0.80666667]
 [0.13084112 0.         0.86915888]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.31      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.87      0.69       535

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5882, Recall: 0.4136, Precision: 0.7127, F1 Score: 0.3884
Confusion Matrix: 
 [[0.37931034 0.         0.62068966]
 [0.17142857 0.00714286 0.82142857]
 [0.14568345 0.         0.85431655]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.38      0.44       319
         1.0       1.00      0.01      0.01       140
         2.0       0.60      0.85      0.71       556

    accuracy                           0.59      1015
   macro avg       0.71      0.41      0.39      1015
weighted avg       0.64      0.59      0.53      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3951, Precision: 0.3610, F1 Score: 0.3633
Confusion Matrix: 
 [[0.32947977 0.00289017 0.66763006]
 [0.26666667 0.         0.73333333]
 [0.14419476 0.         0.85580524]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.33      0.40       346
         1.0       0.00      0.00      0.00       135
         2.0       0.58      0.86      0.69       534

    accuracy                           0.56      1015
   macro avg       0.36      0.40      0.36      1015
weighted avg       0.48      0.56      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5557, Recall: 0.4028, Precision: 0.5301, F1 Score: 0.3718
Confusion Matrix: 
 [[0.3547486  0.0027933  0.6424581 ]
 [0.25352113 0.00704225 0.73943662]
 [0.15339806 0.         0.84660194]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.35      0.42       358
         1.0       0.50      0.01      0.01       142
         2.0       0.57      0.85      0.68       515

    accuracy                           0.56      1015
   macro avg       0.53      0.40      0.37      1015
weighted avg       0.54      0.56      0.50      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5340, Recall: 0.3879, Precision: 0.3513, F1 Score: 0.3494
Confusion Matrix: 
 [[0.30985915 0.0028169  0.68732394]
 [0.19480519 0.         0.80519481]
 [0.14624506 0.         0.85375494]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.31      0.39       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.85      0.66       506

    accuracy                           0.53      1015
   macro avg       0.35      0.39      0.35      1015
weighted avg       0.45      0.53      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.4086, Precision: 0.3803, F1 Score: 0.3732
Confusion Matrix: 
 [[0.34722222 0.         0.65277778]
 [0.2137931  0.         0.7862069 ]
 [0.11764706 0.00392157 0.87843137]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.35      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.88      0.69       510

    accuracy                           0.56      1015
   macro avg       0.38      0.41      0.37      1015
weighted avg       0.49      0.56      0.50      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5389, Recall: 0.3734, Precision: 0.3389, F1 Score: 0.3388
Confusion Matrix: 
 [[0.27409639 0.         0.72590361]
 [0.18055556 0.         0.81944444]
 [0.15213358 0.00185529 0.84601113]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.27      0.34       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.85      0.67       539

    accuracy                           0.54      1015
   macro avg       0.34      0.37      0.34      1015
weighted avg       0.45      0.54      0.47      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5458, Recall: 0.3843, Precision: 0.3440, F1 Score: 0.3494
Confusion Matrix: 
 [[0.30555556 0.         0.69444444]
 [0.20779221 0.         0.79220779]
 [0.15270019 0.         0.84729981]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.31      0.37       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.85      0.68       537

    accuracy                           0.55      1015
   macro avg       0.34      0.38      0.35      1015
weighted avg       0.45      0.55      0.48      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5911, Recall: 0.4076, Precision: 0.3895, F1 Score: 0.3836
Confusion Matrix: 
 [[0.36871508 0.         0.63128492]
 [0.17431193 0.         0.82568807]
 [0.1459854  0.         0.8540146 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.37      0.45       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.85      0.70       548

    accuracy                           0.59      1015
   macro avg       0.39      0.41      0.38      1015
weighted avg       0.52      0.59      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5901, Recall: 0.3924, Precision: 0.3632, F1 Score: 0.3689
Confusion Matrix: 
 [[0.33333333 0.00326797 0.66339869]
 [0.21666667 0.         0.78333333]
 [0.15619694 0.         0.84380306]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.33      0.39       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.84      0.72       589

    accuracy                           0.59      1015
   macro avg       0.36      0.39      0.37      1015
weighted avg       0.50      0.59      0.53      1015

Average metrics:
 Accuracy: 0.5630, Precision: 0.4131, Recall: 0.3958, F1: 0.3645
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
Model: knn, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'n_neighbors': 30}
 Best Score : 0.5521182266009853
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5468, Recall: 0.3822, Precision: 0.3452, F1 Score: 0.3459
Confusion Matrix: 
 [[0.28484848 0.         0.71515152]
 [0.21333333 0.         0.78666667]
 [0.13831776 0.         0.86168224]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.28      0.35       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.86      0.68       535

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.45      0.55      0.48      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5793, Recall: 0.4046, Precision: 0.5361, F1 Score: 0.3785
Confusion Matrix: 
 [[0.35423197 0.0031348  0.64263323]
 [0.19285714 0.00714286 0.8       ]
 [0.14748201 0.         0.85251799]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.35      0.42       319
         1.0       0.50      0.01      0.01       140
         2.0       0.60      0.85      0.70       556

    accuracy                           0.58      1015
   macro avg       0.54      0.40      0.38      1015
weighted avg       0.56      0.58      0.52      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.3997, Precision: 0.3688, F1 Score: 0.3671
Confusion Matrix: 
 [[0.3265896  0.         0.6734104 ]
 [0.25925926 0.         0.74074074]
 [0.12734082 0.         0.87265918]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.33      0.40       346
         1.0       0.00      0.00      0.00       135
         2.0       0.58      0.87      0.70       534

    accuracy                           0.57      1015
   macro avg       0.37      0.40      0.37      1015
weighted avg       0.49      0.57      0.50      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.4033, Precision: 0.3663, F1 Score: 0.3697
Confusion Matrix: 
 [[0.3575419  0.0027933  0.6396648 ]
 [0.26056338 0.         0.73943662]
 [0.14757282 0.         0.85242718]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.36      0.43       358
         1.0       0.00      0.00      0.00       142
         2.0       0.57      0.85      0.68       515

    accuracy                           0.56      1015
   macro avg       0.37      0.40      0.37      1015
weighted avg       0.48      0.56      0.50      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5320, Recall: 0.3860, Precision: 0.3497, F1 Score: 0.3471
Confusion Matrix: 
 [[0.30422535 0.         0.69577465]
 [0.18831169 0.         0.81168831]
 [0.14624506 0.         0.85375494]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.30      0.38       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.85      0.66       506

    accuracy                           0.53      1015
   macro avg       0.35      0.39      0.35      1015
weighted avg       0.45      0.53      0.46      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5606, Recall: 0.4065, Precision: 0.3755, F1 Score: 0.3716
Confusion Matrix: 
 [[0.35277778 0.         0.64722222]
 [0.20689655 0.         0.79310345]
 [0.13137255 0.00196078 0.86666667]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.35      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.87      0.68       510

    accuracy                           0.56      1015
   macro avg       0.38      0.41      0.37      1015
weighted avg       0.48      0.56      0.50      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3809, Precision: 0.3482, F1 Score: 0.3459
Confusion Matrix: 
 [[0.28012048 0.         0.71987952]
 [0.20138889 0.         0.79861111]
 [0.13543599 0.00185529 0.86270872]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.28      0.35       332
         1.0       0.00      0.00      0.00       144
         2.0       0.57      0.86      0.68       539

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.46      0.55      0.48      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3924, Precision: 0.6846, F1 Score: 0.3603
Confusion Matrix: 
 [[0.31790123 0.         0.68209877]
 [0.20779221 0.00649351 0.78571429]
 [0.14711359 0.         0.85288641]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.32      0.38       324
         1.0       1.00      0.01      0.01       154
         2.0       0.57      0.85      0.69       537

    accuracy                           0.55      1015
   macro avg       0.68      0.39      0.36      1015
weighted avg       0.61      0.55      0.49      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5911, Recall: 0.4066, Precision: 0.3898, F1 Score: 0.3822
Confusion Matrix: 
 [[0.3603352  0.         0.6396648 ]
 [0.17431193 0.         0.82568807]
 [0.14051095 0.         0.85948905]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.36      0.44       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.86      0.70       548

    accuracy                           0.59      1015
   macro avg       0.39      0.41      0.38      1015
weighted avg       0.52      0.59      0.54      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5961, Recall: 0.3973, Precision: 0.3699, F1 Score: 0.3743
Confusion Matrix: 
 [[0.34313725 0.00326797 0.65359477]
 [0.2        0.         0.8       ]
 [0.15110357 0.         0.84889643]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.34      0.40       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.85      0.72       589

    accuracy                           0.60      1015
   macro avg       0.37      0.40      0.37      1015
weighted avg       0.51      0.60      0.54      1015

Average metrics:
 Accuracy: 0.5638, Precision: 0.4134, Recall: 0.3960, F1: 0.3643
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
Model: rf, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion': ['gini', 'entropy']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
 Best Score : 0.5711330049261084
Tunning - Saved Hyperparameters [./models/config]
Model: rf, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
RandomForestClassifier(criterion='entropy', max_depth=6, max_features='auto',
                       n_estimators=200, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3776, Precision: 0.3658, F1 Score: 0.3334
Confusion Matrix: 
 [[0.21515152 0.         0.78484848]
 [0.10666667 0.         0.89333333]
 [0.08224299 0.         0.91775701]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.22      0.31       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.92      0.69       535

    accuracy                           0.55      1015
   macro avg       0.37      0.38      0.33      1015
weighted avg       0.47      0.55      0.46      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5901, Recall: 0.3939, Precision: 0.4003, F1 Score: 0.3571
Confusion Matrix: 
 [[0.24451411 0.         0.75548589]
 [0.1        0.         0.9       ]
 [0.06294964 0.         0.93705036]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.24      0.35       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.94      0.72       556

    accuracy                           0.59      1015
   macro avg       0.40      0.39      0.36      1015
weighted avg       0.51      0.59      0.51      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5635, Recall: 0.3835, Precision: 0.3773, F1 Score: 0.3409
Confusion Matrix: 
 [[0.22543353 0.         0.77456647]
 [0.14074074 0.         0.85925926]
 [0.07490637 0.         0.92509363]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.23      0.32       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.93      0.70       534

    accuracy                           0.56      1015
   macro avg       0.38      0.38      0.34      1015
weighted avg       0.49      0.56      0.48      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.3896, Precision: 0.3871, F1 Score: 0.3422
Confusion Matrix: 
 [[0.22905028 0.         0.77094972]
 [0.14788732 0.         0.85211268]
 [0.06019417 0.         0.93980583]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.23      0.33       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.94      0.69       515

    accuracy                           0.56      1015
   macro avg       0.39      0.39      0.34      1015
weighted avg       0.49      0.56      0.47      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3831, Precision: 0.3891, F1 Score: 0.3306
Confusion Matrix: 
 [[0.2084507  0.         0.7915493 ]
 [0.07792208 0.         0.92207792]
 [0.05928854 0.         0.94071146]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.21      0.31       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.94      0.68       506

    accuracy                           0.54      1015
   macro avg       0.39      0.38      0.33      1015
weighted avg       0.49      0.54      0.45      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5754, Recall: 0.4084, Precision: 0.4156, F1 Score: 0.3644
Confusion Matrix: 
 [[0.27222222 0.         0.72777778]
 [0.13793103 0.         0.86206897]
 [0.04705882 0.         0.95294118]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.27      0.39       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.95      0.70       510

    accuracy                           0.58      1015
   macro avg       0.42      0.41      0.36      1015
weighted avg       0.52      0.58      0.49      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5635, Recall: 0.3819, Precision: 0.3816, F1 Score: 0.3393
Confusion Matrix: 
 [[0.21987952 0.         0.78012048]
 [0.08333333 0.         0.91666667]
 [0.0742115  0.         0.9257885 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.22      0.32       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.93      0.70       539

    accuracy                           0.56      1015
   macro avg       0.38      0.38      0.34      1015
weighted avg       0.49      0.56      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5773, Recall: 0.3935, Precision: 0.4066, F1 Score: 0.3491
Confusion Matrix: 
 [[0.22530864 0.         0.77469136]
 [0.0974026  0.         0.9025974 ]
 [0.04469274 0.         0.95530726]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.23      0.33       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.96      0.71       537

    accuracy                           0.58      1015
   macro avg       0.41      0.39      0.35      1015
weighted avg       0.51      0.58      0.48      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5951, Recall: 0.3968, Precision: 0.4121, F1 Score: 0.3622
Confusion Matrix: 
 [[0.25418994 0.         0.74581006]
 [0.12844037 0.         0.87155963]
 [0.06386861 0.         0.93613139]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.25      0.37       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.94      0.72       548

    accuracy                           0.60      1015
   macro avg       0.41      0.40      0.36      1015
weighted avg       0.55      0.60      0.52      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6236, Recall: 0.3991, Precision: 0.4188, F1 Score: 0.3710
Confusion Matrix: 
 [[0.25490196 0.         0.74509804]
 [0.09166667 0.         0.90833333]
 [0.05772496 0.         0.94227504]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.25      0.36       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.94      0.75       589

    accuracy                           0.62      1015
   macro avg       0.42      0.40      0.37      1015
weighted avg       0.55      0.62      0.54      1015

Average metrics:
 Accuracy: 0.5742, Precision: 0.3954, Recall: 0.3907, F1: 0.3490
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
Model: rf, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion': ['gini', 'entropy']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
 Best Score : 0.5713300492610838
Tunning - Saved Hyperparameters [./models/config]
Model: rf, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
RandomForestClassifier(criterion='entropy', max_depth=6, max_features='auto',
                       n_estimators=200, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3776, Precision: 0.3658, F1 Score: 0.3334
Confusion Matrix: 
 [[0.21515152 0.         0.78484848]
 [0.10666667 0.         0.89333333]
 [0.08224299 0.         0.91775701]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.22      0.31       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.92      0.69       535

    accuracy                           0.55      1015
   macro avg       0.37      0.38      0.33      1015
weighted avg       0.47      0.55      0.46      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5901, Recall: 0.3939, Precision: 0.4003, F1 Score: 0.3571
Confusion Matrix: 
 [[0.24451411 0.         0.75548589]
 [0.1        0.         0.9       ]
 [0.06294964 0.         0.93705036]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.24      0.35       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.94      0.72       556

    accuracy                           0.59      1015
   macro avg       0.40      0.39      0.36      1015
weighted avg       0.51      0.59      0.51      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5635, Recall: 0.3835, Precision: 0.3773, F1 Score: 0.3409
Confusion Matrix: 
 [[0.22543353 0.         0.77456647]
 [0.14074074 0.         0.85925926]
 [0.07490637 0.         0.92509363]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.23      0.32       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.93      0.70       534

    accuracy                           0.56      1015
   macro avg       0.38      0.38      0.34      1015
weighted avg       0.49      0.56      0.48      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.3896, Precision: 0.3871, F1 Score: 0.3422
Confusion Matrix: 
 [[0.22905028 0.         0.77094972]
 [0.14788732 0.         0.85211268]
 [0.06019417 0.         0.93980583]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.23      0.33       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.94      0.69       515

    accuracy                           0.56      1015
   macro avg       0.39      0.39      0.34      1015
weighted avg       0.49      0.56      0.47      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3831, Precision: 0.3891, F1 Score: 0.3306
Confusion Matrix: 
 [[0.2084507  0.         0.7915493 ]
 [0.07792208 0.         0.92207792]
 [0.05928854 0.         0.94071146]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.21      0.31       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.94      0.68       506

    accuracy                           0.54      1015
   macro avg       0.39      0.38      0.33      1015
weighted avg       0.49      0.54      0.45      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5754, Recall: 0.4084, Precision: 0.4156, F1 Score: 0.3644
Confusion Matrix: 
 [[0.27222222 0.         0.72777778]
 [0.13793103 0.         0.86206897]
 [0.04705882 0.         0.95294118]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.27      0.39       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.95      0.70       510

    accuracy                           0.58      1015
   macro avg       0.42      0.41      0.36      1015
weighted avg       0.52      0.58      0.49      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5635, Recall: 0.3819, Precision: 0.3816, F1 Score: 0.3393
Confusion Matrix: 
 [[0.21987952 0.         0.78012048]
 [0.08333333 0.         0.91666667]
 [0.0742115  0.         0.9257885 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.22      0.32       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.93      0.70       539

    accuracy                           0.56      1015
   macro avg       0.38      0.38      0.34      1015
weighted avg       0.49      0.56      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5773, Recall: 0.3935, Precision: 0.4066, F1 Score: 0.3491
Confusion Matrix: 
 [[0.22530864 0.         0.77469136]
 [0.0974026  0.         0.9025974 ]
 [0.04469274 0.         0.95530726]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.23      0.33       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.96      0.71       537

    accuracy                           0.58      1015
   macro avg       0.41      0.39      0.35      1015
weighted avg       0.51      0.58      0.48      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5951, Recall: 0.3968, Precision: 0.4121, F1 Score: 0.3622
Confusion Matrix: 
 [[0.25418994 0.         0.74581006]
 [0.12844037 0.         0.87155963]
 [0.06386861 0.         0.93613139]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.25      0.37       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.94      0.72       548

    accuracy                           0.60      1015
   macro avg       0.41      0.40      0.36      1015
weighted avg       0.55      0.60      0.52      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6236, Recall: 0.3991, Precision: 0.4188, F1 Score: 0.3710
Confusion Matrix: 
 [[0.25490196 0.         0.74509804]
 [0.09166667 0.         0.90833333]
 [0.05772496 0.         0.94227504]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.25      0.36       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.94      0.75       589

    accuracy                           0.62      1015
   macro avg       0.42      0.40      0.37      1015
weighted avg       0.55      0.62      0.54      1015

Average metrics:
 Accuracy: 0.5742, Precision: 0.3954, Recall: 0.3907, F1: 0.3490
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
Model: rf, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion': ['gini', 'entropy']}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
 Best Score : 0.5683743842364533
Tunning - Saved Hyperparameters [./models/config]
Model: rf, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3823, Precision: 0.3715, F1 Score: 0.3393
Confusion Matrix: 
 [[0.22727273 0.         0.77272727]
 [0.11333333 0.         0.88666667]
 [0.08037383 0.         0.91962617]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.23      0.32       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.92      0.70       535

    accuracy                           0.56      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.48      0.56      0.47      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5990, Recall: 0.4028, Precision: 0.4128, F1 Score: 0.3688
Confusion Matrix: 
 [[0.26959248 0.         0.73040752]
 [0.09285714 0.         0.90714286]
 [0.06115108 0.         0.93884892]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.27      0.38       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.94      0.73       556

    accuracy                           0.60      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.53      0.60      0.52      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5616, Recall: 0.3823, Precision: 0.3743, F1 Score: 0.3398
Confusion Matrix: 
 [[0.22543353 0.         0.77456647]
 [0.14074074 0.         0.85925926]
 [0.07865169 0.         0.92134831]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.23      0.32       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.92      0.70       534

    accuracy                           0.56      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.49      0.56      0.48      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3943, Precision: 0.3941, F1 Score: 0.3487
Confusion Matrix: 
 [[0.24301676 0.         0.75698324]
 [0.14084507 0.         0.85915493]
 [0.06019417 0.         0.93980583]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.24      0.35       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.94      0.70       515

    accuracy                           0.56      1015
   macro avg       0.39      0.39      0.35      1015
weighted avg       0.50      0.56      0.48      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.3846, Precision: 0.3904, F1 Score: 0.3336
Confusion Matrix: 
 [[0.21690141 0.         0.78309859]
 [0.07142857 0.         0.92857143]
 [0.06324111 0.         0.93675889]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.22      0.32       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.94      0.68       506

    accuracy                           0.54      1015
   macro avg       0.39      0.38      0.33      1015
weighted avg       0.49      0.54      0.45      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5744, Recall: 0.4072, Precision: 0.4127, F1 Score: 0.3623
Confusion Matrix: 
 [[0.26666667 0.         0.73333333]
 [0.15172414 0.         0.84827586]
 [0.04509804 0.         0.95490196]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.68      0.27      0.38       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.95      0.70       510

    accuracy                           0.57      1015
   macro avg       0.41      0.41      0.36      1015
weighted avg       0.52      0.57      0.49      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3786, Precision: 0.3844, F1 Score: 0.3326
Confusion Matrix: 
 [[0.19879518 0.         0.80120482]
 [0.07638889 0.         0.92361111]
 [0.06307978 0.         0.93692022]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.20      0.30       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.94      0.70       539

    accuracy                           0.56      1015
   macro avg       0.38      0.38      0.33      1015
weighted avg       0.49      0.56      0.47      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5616, Recall: 0.3844, Precision: 0.3693, F1 Score: 0.3416
Confusion Matrix: 
 [[0.23148148 0.         0.76851852]
 [0.13636364 0.         0.86363636]
 [0.07821229 0.         0.92178771]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.23      0.32       324
         1.0       0.00      0.00      0.00       154
         2.0       0.56      0.92      0.70       537

    accuracy                           0.56      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.47      0.56      0.47      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6020, Recall: 0.4020, Precision: 0.4250, F1 Score: 0.3683
Confusion Matrix: 
 [[0.26256983 0.         0.73743017]
 [0.11009174 0.         0.88990826]
 [0.05656934 0.         0.94343066]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.26      0.38       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.94      0.73       548

    accuracy                           0.60      1015
   macro avg       0.42      0.40      0.37      1015
weighted avg       0.56      0.60      0.53      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6256, Recall: 0.4002, Precision: 0.4241, F1 Score: 0.3723
Confusion Matrix: 
 [[0.25490196 0.         0.74509804]
 [0.08333333 0.         0.91666667]
 [0.05432937 0.         0.94567063]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.25      0.37       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.95      0.75       589

    accuracy                           0.63      1015
   macro avg       0.42      0.40      0.37      1015
weighted avg       0.56      0.63      0.55      1015

Average metrics:
 Accuracy: 0.5751, Precision: 0.3959, Recall: 0.3919, F1: 0.3508
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0    rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
Model: ab, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 30], 'algorithm': ['SAMME', 'SAMME.R'], 'learning_rate': [0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
 Best Score : 0.5652216748768473
Tunning - Saved Hyperparameters [./models/config]
Model: ab, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.03, n_estimators=20, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5665, Recall: 0.3954, Precision: 0.3705, F1 Score: 0.3587
Confusion Matrix: 
 [[0.29090909 0.         0.70909091]
 [0.17333333 0.         0.82666667]
 [0.1046729  0.         0.8953271 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.29      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.90      0.70       535

    accuracy                           0.57      1015
   macro avg       0.37      0.40      0.36      1015
weighted avg       0.48      0.57      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5921, Recall: 0.4004, Precision: 0.4003, F1 Score: 0.3680
Confusion Matrix: 
 [[0.28213166 0.         0.71786834]
 [0.08571429 0.         0.91428571]
 [0.08093525 0.         0.91906475]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.28      0.39       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.92      0.72       556

    accuracy                           0.59      1015
   macro avg       0.40      0.40      0.37      1015
weighted avg       0.51      0.59      0.51      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3914, Precision: 0.3677, F1 Score: 0.3575
Confusion Matrix: 
 [[0.29768786 0.         0.70231214]
 [0.17777778 0.         0.82222222]
 [0.12359551 0.         0.87640449]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.30      0.38       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.88      0.69       534

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.36      1015
weighted avg       0.48      0.56      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5527, Recall: 0.3915, Precision: 0.3711, F1 Score: 0.3519
Confusion Matrix: 
 [[0.27932961 0.0027933  0.71787709]
 [0.16901408 0.         0.83098592]
 [0.10485437 0.         0.89514563]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.28      0.37       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.90      0.68       515

    accuracy                           0.55      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.48      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.3890, Precision: 0.3743, F1 Score: 0.3449
Confusion Matrix: 
 [[0.26197183 0.         0.73802817]
 [0.11038961 0.         0.88961039]
 [0.09486166 0.         0.90513834]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.26      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.91      0.67       506

    accuracy                           0.54      1015
   macro avg       0.37      0.39      0.34      1015
weighted avg       0.47      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5862, Recall: 0.4216, Precision: 0.4089, F1 Score: 0.3833
Confusion Matrix: 
 [[0.33333333 0.         0.66666667]
 [0.19310345 0.         0.80689655]
 [0.06862745 0.         0.93137255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.33      0.44       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.93      0.71       510

    accuracy                           0.59      1015
   macro avg       0.41      0.42      0.38      1015
weighted avg       0.52      0.59      0.51      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5557, Recall: 0.3839, Precision: 0.3546, F1 Score: 0.3477
Confusion Matrix: 
 [[0.27409639 0.         0.72590361]
 [0.1875     0.         0.8125    ]
 [0.12244898 0.         0.87755102]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.27      0.35       332
         1.0       0.00      0.00      0.00       144
         2.0       0.57      0.88      0.69       539

    accuracy                           0.56      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.46      0.56      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.3932, Precision: 0.3677, F1 Score: 0.3559
Confusion Matrix: 
 [[0.28395062 0.         0.71604938]
 [0.16233766 0.         0.83766234]
 [0.10428305 0.         0.89571695]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.28      0.37       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.90      0.70       537

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6069, Recall: 0.4125, Precision: 0.4121, F1 Score: 0.3851
Confusion Matrix: 
 [[0.32681564 0.         0.67318436]
 [0.16513761 0.         0.83486239]
 [0.08941606 0.         0.91058394]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.33      0.43       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.91      0.72       548

    accuracy                           0.61      1015
   macro avg       0.41      0.41      0.39      1015
weighted avg       0.55      0.61      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6099, Recall: 0.3927, Precision: 0.3864, F1 Score: 0.3650
Confusion Matrix: 
 [[0.26470588 0.         0.73529412]
 [0.15833333 0.         0.84166667]
 [0.08658744 0.         0.91341256]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.26      0.35       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.91      0.74       589

    accuracy                           0.61      1015
   macro avg       0.39      0.39      0.37      1015
weighted avg       0.52      0.61      0.54      1015

Average metrics:
 Accuracy: 0.5740, Precision: 0.3814, Recall: 0.3972, F1: 0.3618
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0    rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0    ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
Model: ab, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 30], 'algorithm': ['SAMME', 'SAMME.R'], 'learning_rate': [0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
 Best Score : 0.5652216748768473
Tunning - Saved Hyperparameters [./models/config]
Model: ab, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.03, n_estimators=20, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5665, Recall: 0.3954, Precision: 0.3705, F1 Score: 0.3587
Confusion Matrix: 
 [[0.29090909 0.         0.70909091]
 [0.17333333 0.         0.82666667]
 [0.1046729  0.         0.8953271 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.29      0.38       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.90      0.70       535

    accuracy                           0.57      1015
   macro avg       0.37      0.40      0.36      1015
weighted avg       0.48      0.57      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5911, Recall: 0.3994, Precision: 0.3994, F1 Score: 0.3668
Confusion Matrix: 
 [[0.27899687 0.0031348  0.71786834]
 [0.08571429 0.         0.91428571]
 [0.08093525 0.         0.91906475]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.28      0.38       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.92      0.72       556

    accuracy                           0.59      1015
   macro avg       0.40      0.40      0.37      1015
weighted avg       0.51      0.59      0.51      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3914, Precision: 0.3677, F1 Score: 0.3575
Confusion Matrix: 
 [[0.29768786 0.         0.70231214]
 [0.17777778 0.         0.82222222]
 [0.12359551 0.         0.87640449]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.30      0.38       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.88      0.69       534

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.36      1015
weighted avg       0.48      0.56      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5527, Recall: 0.3915, Precision: 0.3711, F1 Score: 0.3519
Confusion Matrix: 
 [[0.27932961 0.0027933  0.71787709]
 [0.16901408 0.         0.83098592]
 [0.10485437 0.         0.89514563]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.28      0.37       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.90      0.68       515

    accuracy                           0.55      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.48      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.3890, Precision: 0.3743, F1 Score: 0.3449
Confusion Matrix: 
 [[0.26197183 0.         0.73802817]
 [0.11038961 0.         0.88961039]
 [0.09486166 0.         0.90513834]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.26      0.36       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.91      0.67       506

    accuracy                           0.54      1015
   macro avg       0.37      0.39      0.34      1015
weighted avg       0.47      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5862, Recall: 0.4216, Precision: 0.4089, F1 Score: 0.3833
Confusion Matrix: 
 [[0.33333333 0.         0.66666667]
 [0.19310345 0.         0.80689655]
 [0.06862745 0.         0.93137255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.33      0.44       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.93      0.71       510

    accuracy                           0.59      1015
   macro avg       0.41      0.42      0.38      1015
weighted avg       0.52      0.59      0.51      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5557, Recall: 0.3839, Precision: 0.3546, F1 Score: 0.3477
Confusion Matrix: 
 [[0.27409639 0.         0.72590361]
 [0.1875     0.         0.8125    ]
 [0.12244898 0.         0.87755102]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.27      0.35       332
         1.0       0.00      0.00      0.00       144
         2.0       0.57      0.88      0.69       539

    accuracy                           0.56      1015
   macro avg       0.35      0.38      0.35      1015
weighted avg       0.46      0.56      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.3932, Precision: 0.3677, F1 Score: 0.3559
Confusion Matrix: 
 [[0.28395062 0.         0.71604938]
 [0.16233766 0.         0.83766234]
 [0.10428305 0.         0.89571695]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.28      0.37       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.90      0.70       537

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6069, Recall: 0.4125, Precision: 0.4121, F1 Score: 0.3851
Confusion Matrix: 
 [[0.32681564 0.         0.67318436]
 [0.16513761 0.         0.83486239]
 [0.08941606 0.         0.91058394]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.33      0.43       358
         1.0       0.00      0.00      0.00       109
         2.0       0.60      0.91      0.72       548

    accuracy                           0.61      1015
   macro avg       0.41      0.41      0.39      1015
weighted avg       0.55      0.61      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6099, Recall: 0.3927, Precision: 0.3864, F1 Score: 0.3650
Confusion Matrix: 
 [[0.26470588 0.         0.73529412]
 [0.15833333 0.         0.84166667]
 [0.08658744 0.         0.91341256]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.26      0.35       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.91      0.74       589

    accuracy                           0.61      1015
   macro avg       0.39      0.39      0.37      1015
weighted avg       0.52      0.61      0.54      1015

Average metrics:
 Accuracy: 0.5739, Precision: 0.3813, Recall: 0.3971, F1: 0.3617
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0    rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0    ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0    ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
Model: ab, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 30], 'algorithm': ['SAMME', 'SAMME.R'], 'learning_rate': [0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04]}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
 Best Score : 0.5636453201970444
Tunning - Saved Hyperparameters [./models/config]
Model: ab, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5478, Recall: 0.3747, Precision: 0.3572, F1 Score: 0.3322
Confusion Matrix: 
 [[0.22121212 0.00606061 0.77272727]
 [0.10666667 0.         0.89333333]
 [0.09719626 0.         0.90280374]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.22      0.31       330
         1.0       0.00      0.00      0.00       150
         2.0       0.55      0.90      0.69       535

    accuracy                           0.55      1015
   macro avg       0.36      0.37      0.33      1015
weighted avg       0.46      0.55      0.46      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5695, Recall: 0.3813, Precision: 0.3644, F1 Score: 0.3455
Confusion Matrix: 
 [[0.24451411 0.0031348  0.7523511 ]
 [0.12857143 0.         0.87142857]
 [0.10071942 0.         0.89928058]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.24      0.33       319
         1.0       0.00      0.00      0.00       140
         2.0       0.58      0.90      0.71       556

    accuracy                           0.57      1015
   macro avg       0.36      0.38      0.35      1015
weighted avg       0.48      0.57      0.49      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3827, Precision: 0.3724, F1 Score: 0.3427
Confusion Matrix: 
 [[0.23988439 0.         0.76011561]
 [0.12592593 0.         0.87407407]
 [0.0917603  0.         0.9082397 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.24      0.34       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.91      0.69       534

    accuracy                           0.56      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.48      0.56      0.48      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5448, Recall: 0.3821, Precision: 0.3623, F1 Score: 0.3373
Confusion Matrix: 
 [[0.23743017 0.         0.76256983]
 [0.17605634 0.         0.82394366]
 [0.09126214 0.         0.90873786]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.24      0.33       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.91      0.68       515

    accuracy                           0.54      1015
   macro avg       0.36      0.38      0.34      1015
weighted avg       0.47      0.54      0.46      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5399, Recall: 0.3843, Precision: 0.3681, F1 Score: 0.3361
Confusion Matrix: 
 [[0.23380282 0.0028169  0.76338028]
 [0.14285714 0.         0.85714286]
 [0.08102767 0.         0.91897233]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.23      0.33       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.92      0.68       506

    accuracy                           0.54      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.47      0.54      0.45      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5724, Recall: 0.4083, Precision: 0.4055, F1 Score: 0.3672
Confusion Matrix: 
 [[0.29166667 0.         0.70833333]
 [0.13793103 0.         0.86206897]
 [0.06666667 0.         0.93333333]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.29      0.40       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.93      0.70       510

    accuracy                           0.57      1015
   macro avg       0.41      0.41      0.37      1015
weighted avg       0.51      0.57      0.49      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.3677, Precision: 0.3401, F1 Score: 0.3252
Confusion Matrix: 
 [[0.21084337 0.         0.78915663]
 [0.15972222 0.         0.84027778]
 [0.10760668 0.         0.89239332]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.21      0.29       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.89      0.69       539

    accuracy                           0.54      1015
   macro avg       0.34      0.37      0.33      1015
weighted avg       0.45      0.54      0.46      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5606, Recall: 0.3863, Precision: 0.3629, F1 Score: 0.3459
Confusion Matrix: 
 [[0.25       0.00617284 0.74382716]
 [0.16883117 0.         0.83116883]
 [0.09124767 0.         0.90875233]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.25      0.34       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.91      0.70       537

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.56      0.48      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5813, Recall: 0.3883, Precision: 0.3904, F1 Score: 0.3548
Confusion Matrix: 
 [[0.25418994 0.         0.74581006]
 [0.13761468 0.         0.86238532]
 [0.08759124 0.00182482 0.91058394]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.25      0.36       358
         1.0       0.00      0.00      0.00       109
         2.0       0.58      0.91      0.71       548

    accuracy                           0.58      1015
   macro avg       0.39      0.39      0.35      1015
weighted avg       0.52      0.58      0.51      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6099, Recall: 0.3927, Precision: 0.3969, F1 Score: 0.3661
Confusion Matrix: 
 [[0.26470588 0.00326797 0.73202614]
 [0.075      0.         0.925     ]
 [0.08658744 0.         0.91341256]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.26      0.36       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.91      0.74       589

    accuracy                           0.61      1015
   macro avg       0.40      0.39      0.37      1015
weighted avg       0.53      0.61      0.54      1015

Average metrics:
 Accuracy: 0.5629, Precision: 0.3720, Recall: 0.3848, F1: 0.3453
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0    rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0    ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0    ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0    ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
Model: gb, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Error
Model: gb, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3925, Precision: 0.3662, F1 Score: 0.3560
Confusion Matrix: 
 [[0.28787879 0.         0.71212121]
 [0.18       0.         0.82      ]
 [0.10841121 0.00186916 0.88971963]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.29      0.37       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.89      0.70       535

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.6030, Recall: 0.4168, Precision: 0.4878, F1 Score: 0.3910
Confusion Matrix: 
 [[0.33855799 0.         0.66144201]
 [0.13571429 0.00714286 0.85714286]
 [0.08992806 0.00539568 0.90467626]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.34      0.44       319
         1.0       0.25      0.01      0.01       140
         2.0       0.60      0.90      0.72       556

    accuracy                           0.60      1015
   macro avg       0.49      0.42      0.39      1015
weighted avg       0.56      0.60      0.54      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5773, Recall: 0.4038, Precision: 0.3812, F1 Score: 0.3711
Confusion Matrix: 
 [[0.32369942 0.         0.67630058]
 [0.2        0.         0.8       ]
 [0.11235955 0.         0.88764045]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.32      0.41       346
         1.0       0.00      0.00      0.00       135
         2.0       0.58      0.89      0.70       534

    accuracy                           0.58      1015
   macro avg       0.38      0.40      0.37      1015
weighted avg       0.50      0.58      0.51      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3919, Precision: 0.3719, F1 Score: 0.3519
Confusion Matrix: 
 [[0.27653631 0.00558659 0.71787709]
 [0.17605634 0.         0.82394366]
 [0.10097087 0.         0.89902913]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.28      0.37       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.90      0.68       515

    accuracy                           0.55      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.48      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5517, Recall: 0.3975, Precision: 0.3867, F1 Score: 0.3560
Confusion Matrix: 
 [[0.28732394 0.         0.71267606]
 [0.09090909 0.         0.90909091]
 [0.09486166 0.         0.90513834]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.29      0.39       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.91      0.68       506

    accuracy                           0.55      1015
   macro avg       0.39      0.40      0.36      1015
weighted avg       0.49      0.55      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5862, Recall: 0.4208, Precision: 0.4138, F1 Score: 0.3821
Confusion Matrix: 
 [[0.325      0.00277778 0.67222222]
 [0.17241379 0.         0.82758621]
 [0.0627451  0.         0.9372549 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.67      0.33      0.44       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.94      0.71       510

    accuracy                           0.59      1015
   macro avg       0.41      0.42      0.38      1015
weighted avg       0.52      0.59      0.51      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3836, Precision: 0.5255, F1 Score: 0.3502
Confusion Matrix: 
 [[0.26807229 0.         0.73192771]
 [0.125      0.00694444 0.86805556]
 [0.12244898 0.00185529 0.87569573]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.27      0.35       332
         1.0       0.50      0.01      0.01       144
         2.0       0.56      0.88      0.68       539

    accuracy                           0.55      1015
   macro avg       0.53      0.38      0.35      1015
weighted avg       0.54      0.55      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5744, Recall: 0.3998, Precision: 0.3800, F1 Score: 0.3623
Confusion Matrix: 
 [[0.28703704 0.         0.71296296]
 [0.16233766 0.         0.83766234]
 [0.08752328 0.         0.91247672]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.29      0.38       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.91      0.71       537

    accuracy                           0.57      1015
   macro avg       0.38      0.40      0.36      1015
weighted avg       0.48      0.57      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6158, Recall: 0.4221, Precision: 0.4238, F1 Score: 0.3987
Confusion Matrix: 
 [[0.36312849 0.00558659 0.63128492]
 [0.14678899 0.         0.85321101]
 [0.09124088 0.00547445 0.90328467]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.36      0.47       358
         1.0       0.00      0.00      0.00       109
         2.0       0.61      0.90      0.73       548

    accuracy                           0.62      1015
   macro avg       0.42      0.42      0.40      1015
weighted avg       0.56      0.62      0.56      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6148, Recall: 0.4023, Precision: 0.3950, F1 Score: 0.3787
Confusion Matrix: 
 [[0.30718954 0.00653595 0.68627451]
 [0.14166667 0.         0.85833333]
 [0.09847199 0.00169779 0.89983022]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.31      0.40       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.90      0.74       589

    accuracy                           0.61      1015
   macro avg       0.39      0.40      0.38      1015
weighted avg       0.53      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5793, Precision: 0.4132, Recall: 0.4031, F1: 0.3698
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0    rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0    ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0    ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0    ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0    gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
Model: gb, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Error
Model: gb, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3925, Precision: 0.3662, F1 Score: 0.3560
Confusion Matrix: 
 [[0.28787879 0.         0.71212121]
 [0.18       0.         0.82      ]
 [0.10841121 0.00186916 0.88971963]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.29      0.37       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.89      0.70       535

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.36      1015
weighted avg       0.47      0.56      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.6030, Recall: 0.4168, Precision: 0.4878, F1 Score: 0.3910
Confusion Matrix: 
 [[0.33855799 0.         0.66144201]
 [0.13571429 0.00714286 0.85714286]
 [0.08992806 0.00539568 0.90467626]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.34      0.44       319
         1.0       0.25      0.01      0.01       140
         2.0       0.60      0.90      0.72       556

    accuracy                           0.60      1015
   macro avg       0.49      0.42      0.39      1015
weighted avg       0.56      0.60      0.54      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5773, Recall: 0.4038, Precision: 0.3812, F1 Score: 0.3711
Confusion Matrix: 
 [[0.32369942 0.         0.67630058]
 [0.2        0.         0.8       ]
 [0.11235955 0.         0.88764045]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.32      0.41       346
         1.0       0.00      0.00      0.00       135
         2.0       0.58      0.89      0.70       534

    accuracy                           0.58      1015
   macro avg       0.38      0.40      0.37      1015
weighted avg       0.50      0.58      0.51      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3919, Precision: 0.3719, F1 Score: 0.3519
Confusion Matrix: 
 [[0.27653631 0.00558659 0.71787709]
 [0.17605634 0.         0.82394366]
 [0.10097087 0.         0.89902913]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.28      0.37       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.90      0.68       515

    accuracy                           0.55      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.48      0.55      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5517, Recall: 0.3975, Precision: 0.3867, F1 Score: 0.3560
Confusion Matrix: 
 [[0.28732394 0.         0.71267606]
 [0.09090909 0.         0.90909091]
 [0.09486166 0.         0.90513834]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.29      0.39       355
         1.0       0.00      0.00      0.00       154
         2.0       0.54      0.91      0.68       506

    accuracy                           0.55      1015
   macro avg       0.39      0.40      0.36      1015
weighted avg       0.49      0.55      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5862, Recall: 0.4208, Precision: 0.4138, F1 Score: 0.3821
Confusion Matrix: 
 [[0.325      0.00277778 0.67222222]
 [0.17241379 0.         0.82758621]
 [0.0627451  0.         0.9372549 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.67      0.33      0.44       360
         1.0       0.00      0.00      0.00       145
         2.0       0.57      0.94      0.71       510

    accuracy                           0.59      1015
   macro avg       0.41      0.42      0.38      1015
weighted avg       0.52      0.59      0.51      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3836, Precision: 0.5255, F1 Score: 0.3502
Confusion Matrix: 
 [[0.26807229 0.         0.73192771]
 [0.125      0.00694444 0.86805556]
 [0.12244898 0.00185529 0.87569573]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.27      0.35       332
         1.0       0.50      0.01      0.01       144
         2.0       0.56      0.88      0.68       539

    accuracy                           0.55      1015
   macro avg       0.53      0.38      0.35      1015
weighted avg       0.54      0.55      0.48      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5744, Recall: 0.3998, Precision: 0.3800, F1 Score: 0.3623
Confusion Matrix: 
 [[0.28703704 0.         0.71296296]
 [0.16233766 0.         0.83766234]
 [0.08752328 0.         0.91247672]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.29      0.38       324
         1.0       0.00      0.00      0.00       154
         2.0       0.58      0.91      0.71       537

    accuracy                           0.57      1015
   macro avg       0.38      0.40      0.36      1015
weighted avg       0.48      0.57      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6158, Recall: 0.4221, Precision: 0.4238, F1 Score: 0.3987
Confusion Matrix: 
 [[0.36312849 0.00558659 0.63128492]
 [0.14678899 0.         0.85321101]
 [0.09124088 0.00547445 0.90328467]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.36      0.47       358
         1.0       0.00      0.00      0.00       109
         2.0       0.61      0.90      0.73       548

    accuracy                           0.62      1015
   macro avg       0.42      0.42      0.40      1015
weighted avg       0.56      0.62      0.56      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6148, Recall: 0.4023, Precision: 0.3950, F1 Score: 0.3787
Confusion Matrix: 
 [[0.30718954 0.00653595 0.68627451]
 [0.14166667 0.         0.85833333]
 [0.09847199 0.00169779 0.89983022]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.31      0.40       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.90      0.74       589

    accuracy                           0.61      1015
   macro avg       0.39      0.40      0.38      1015
weighted avg       0.53      0.61      0.55      1015

Average metrics:
 Accuracy: 0.5793, Precision: 0.4132, Recall: 0.4031, F1: 0.3698
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0    rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0    ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0    ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0    ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0    gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0    gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
Model: gb, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Error
Model: gb, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3894, Precision: 0.3706, F1 Score: 0.3510
Confusion Matrix: 
 [[0.26363636 0.00909091 0.72727273]
 [0.14666667 0.         0.85333333]
 [0.0953271  0.         0.9046729 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.26      0.36       330
         1.0       0.00      0.00      0.00       150
         2.0       0.57      0.90      0.70       535

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.48      0.56      0.48      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5862, Recall: 0.4017, Precision: 0.5459, F1 Score: 0.3729
Confusion Matrix: 
 [[0.30407524 0.0031348  0.69278997]
 [0.16428571 0.00714286 0.82857143]
 [0.10611511 0.         0.89388489]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.30      0.39       319
         1.0       0.50      0.01      0.01       140
         2.0       0.60      0.89      0.72       556

    accuracy                           0.59      1015
   macro avg       0.55      0.40      0.37      1015
weighted avg       0.57      0.59      0.52      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.3832, Precision: 0.3638, F1 Score: 0.3451
Confusion Matrix: 
 [[0.25433526 0.         0.74566474]
 [0.17777778 0.         0.82222222]
 [0.10299625 0.00187266 0.89513109]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.25      0.34       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.90      0.69       534

    accuracy                           0.56      1015
   macro avg       0.36      0.38      0.35      1015
weighted avg       0.48      0.56      0.48      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5606, Recall: 0.3975, Precision: 0.7142, F1 Score: 0.3585
Confusion Matrix: 
 [[0.27094972 0.         0.72905028]
 [0.16901408 0.00704225 0.82394366]
 [0.08543689 0.         0.91456311]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.27      0.37       358
         1.0       1.00      0.01      0.01       142
         2.0       0.55      0.91      0.69       515

    accuracy                           0.56      1015
   macro avg       0.71      0.40      0.36      1015
weighted avg       0.63      0.56      0.48      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3885, Precision: 0.4491, F1 Score: 0.3447
Confusion Matrix: 
 [[0.24788732 0.0056338  0.74647887]
 [0.16883117 0.00649351 0.82467532]
 [0.08695652 0.00197628 0.91106719]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.25      0.34       355
         1.0       0.25      0.01      0.01       154
         2.0       0.54      0.91      0.68       506

    accuracy                           0.54      1015
   macro avg       0.45      0.39      0.34      1015
weighted avg       0.50      0.54      0.46      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5734, Recall: 0.4123, Precision: 0.7295, F1 Score: 0.3750
Confusion Matrix: 
 [[0.30833333 0.         0.69166667]
 [0.17931034 0.00689655 0.8137931 ]
 [0.07843137 0.         0.92156863]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.31      0.41       360
         1.0       1.00      0.01      0.01       145
         2.0       0.56      0.92      0.70       510

    accuracy                           0.57      1015
   macro avg       0.73      0.41      0.37      1015
weighted avg       0.65      0.57      0.50      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5665, Recall: 0.3895, Precision: 0.3679, F1 Score: 0.3517
Confusion Matrix: 
 [[0.26506024 0.         0.73493976]
 [0.18055556 0.         0.81944444]
 [0.09647495 0.         0.90352505]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.27      0.35       332
         1.0       0.00      0.00      0.00       144
         2.0       0.57      0.90      0.70       539

    accuracy                           0.57      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.48      0.57      0.49      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3862, Precision: 0.3627, F1 Score: 0.3471
Confusion Matrix: 
 [[0.25925926 0.         0.74074074]
 [0.15584416 0.         0.84415584]
 [0.09869646 0.0018622  0.89944134]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.26      0.35       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.90      0.69       537

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.56      0.48      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5970, Recall: 0.4028, Precision: 0.4088, F1 Score: 0.3739
Confusion Matrix: 
 [[0.29608939 0.         0.70391061]
 [0.14678899 0.         0.85321101]
 [0.08211679 0.00547445 0.91240876]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.30      0.40       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.91      0.72       548

    accuracy                           0.60      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.54      0.60      0.53      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6256, Recall: 0.4070, Precision: 0.4119, F1 Score: 0.3825
Confusion Matrix: 
 [[0.29738562 0.         0.70261438]
 [0.11666667 0.         0.88333333]
 [0.07640068 0.         0.92359932]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.30      0.40       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.92      0.75       589

    accuracy                           0.63      1015
   macro avg       0.41      0.41      0.38      1015
weighted avg       0.55      0.63      0.55      1015

Average metrics:
 Accuracy: 0.5730, Precision: 0.4724, Recall: 0.3958, F1: 0.3602
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0    dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0    dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0   knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0   knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0   knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0    rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0    rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0    rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0    ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0    ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0    ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0    gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0    gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0    gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
Model: kmeans, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Error
Model: kmeans, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.2660, Recall: 0.2970, Precision: 0.2536, F1 Score: 0.2189
Confusion Matrix: 
 [[0.64545455 0.20909091 0.14545455]
 [0.74666667 0.19333333 0.06      ]
 [0.71588785 0.2317757  0.05233645]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.30      0.65      0.41       330
         1.0       0.13      0.19      0.16       150
         2.0       0.33      0.05      0.09       535

    accuracy                           0.27      1015
   macro avg       0.25      0.30      0.22      1015
weighted avg       0.29      0.27      0.20      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.2660, Recall: 0.3137, Precision: 0.2562, F1 Score: 0.2286
Confusion Matrix: 
 [[0.64263323 0.17868339 0.17868339]
 [0.7        0.24285714 0.05714286]
 [0.69604317 0.24820144 0.0557554 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.30      0.64      0.41       319
         1.0       0.15      0.24      0.18       140
         2.0       0.32      0.06      0.10       556

    accuracy                           0.27      1015
   macro avg       0.26      0.31      0.23      1015
weighted avg       0.29      0.27      0.21      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.4493, Recall: 0.3297, Precision: 0.3218, F1 Score: 0.3194
Confusion Matrix: 
 [[0.21098266 0.15606936 0.63294798]
 [0.2962963  0.08148148 0.62222222]
 [0.23595506 0.06741573 0.69662921]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.31      0.21      0.25       346
         1.0       0.11      0.08      0.09       135
         2.0       0.55      0.70      0.62       534

    accuracy                           0.45      1015
   macro avg       0.32      0.33      0.32      1015
weighted avg       0.41      0.45      0.42      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.1980, Recall: 0.3225, Precision: 0.2503, F1 Score: 0.1936
Confusion Matrix: 
 [[0.20391061 0.6396648  0.15642458]
 [0.19014085 0.71126761 0.09859155]
 [0.23883495 0.70873786 0.05242718]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.33      0.20      0.25       358
         1.0       0.15      0.71      0.24       142
         2.0       0.28      0.05      0.09       515

    accuracy                           0.20      1015
   macro avg       0.25      0.32      0.19      1015
weighted avg       0.28      0.20      0.17      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.2690, Recall: 0.2995, Precision: 0.2400, F1 Score: 0.2259
Confusion Matrix: 
 [[0.5971831  0.25070423 0.15211268]
 [0.68181818 0.25974026 0.05844156]
 [0.70355731 0.25494071 0.04150198]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.32      0.60      0.41       355
         1.0       0.16      0.26      0.19       154
         2.0       0.25      0.04      0.07       506

    accuracy                           0.27      1015
   macro avg       0.24      0.30      0.23      1015
weighted avg       0.26      0.27      0.21      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.3714, Recall: 0.3348, Precision: 0.3569, F1 Score: 0.3118
Confusion Matrix: 
 [[0.61666667 0.18611111 0.19722222]
 [0.66206897 0.11724138 0.22068966]
 [0.69607843 0.03333333 0.27058824]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.33      0.62      0.43       360
         1.0       0.17      0.12      0.14       145
         2.0       0.57      0.27      0.37       510

    accuracy                           0.37      1015
   macro avg       0.36      0.33      0.31      1015
weighted avg       0.43      0.37      0.36      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.2581, Recall: 0.3397, Precision: 0.3965, F1 Score: 0.2449
Confusion Matrix: 
 [[0.10240964 0.68674699 0.21084337]
 [0.07638889 0.67361111 0.25      ]
 [0.04267161 0.71428571 0.24304267]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.10      0.17       332
         1.0       0.14      0.67      0.23       144
         2.0       0.55      0.24      0.34       539

    accuracy                           0.26      1015
   macro avg       0.40      0.34      0.24      1015
weighted avg       0.48      0.26      0.27      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.2453, Recall: 0.2882, Precision: 0.2234, F1 Score: 0.2069
Confusion Matrix: 
 [[0.60185185 0.25308642 0.14506173]
 [0.7012987  0.22727273 0.07142857]
 [0.71880819 0.24581006 0.03538175]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.60      0.38       324
         1.0       0.14      0.23      0.17       154
         2.0       0.25      0.04      0.06       537

    accuracy                           0.25      1015
   macro avg       0.22      0.29      0.21      1015
weighted avg       0.24      0.25      0.18      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.2532, Recall: 0.2783, Precision: 0.2170, F1 Score: 0.2027
Confusion Matrix: 
 [[0.58938547 0.22905028 0.18156425]
 [0.72477064 0.20183486 0.0733945 ]
 [0.69343066 0.26277372 0.04379562]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.31      0.59      0.41       358
         1.0       0.09      0.20      0.12       109
         2.0       0.25      0.04      0.07       548

    accuracy                           0.25      1015
   macro avg       0.22      0.28      0.20      1015
weighted avg       0.25      0.25      0.20      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.2414, Recall: 0.3061, Precision: 0.2385, F1 Score: 0.2086
Confusion Matrix: 
 [[0.61764706 0.2254902  0.15686275]
 [0.68333333 0.25833333 0.05833333]
 [0.73684211 0.22071307 0.04244482]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.27      0.62      0.37       306
         1.0       0.13      0.26      0.18       120
         2.0       0.31      0.04      0.07       589

    accuracy                           0.24      1015
   macro avg       0.24      0.31      0.21      1015
weighted avg       0.28      0.24      0.18      1015

Average metrics:
 Accuracy: 0.2818, Precision: 0.2754, Recall: 0.3110, F1: 0.2361
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
Model: kmeans, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Error
Model: kmeans, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.3586, Recall: 0.3697, Precision: 0.4569, F1 Score: 0.3229
Confusion Matrix: 
 [[0.14242424 0.54848485 0.30909091]
 [0.05333333 0.52       0.42666667]
 [0.03551402 0.51775701 0.44672897]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.14      0.23       330
         1.0       0.15      0.52      0.23       150
         2.0       0.59      0.45      0.51       535

    accuracy                           0.36      1015
   macro avg       0.46      0.37      0.32      1015
weighted avg       0.54      0.36      0.38      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.2404, Recall: 0.3106, Precision: 0.2531, F1 Score: 0.2232
Confusion Matrix: 
 [[0.50470219 0.32288401 0.17241379]
 [0.56428571 0.37142857 0.06428571]
 [0.56115108 0.38309353 0.0557554 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.29      0.50      0.37       319
         1.0       0.14      0.37      0.20       140
         2.0       0.33      0.06      0.10       556

    accuracy                           0.24      1015
   macro avg       0.25      0.31      0.22      1015
weighted avg       0.29      0.24      0.20      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.2611, Recall: 0.3105, Precision: 0.2543, F1 Score: 0.2293
Confusion Matrix: 
 [[0.56069364 0.28612717 0.15317919]
 [0.6        0.31851852 0.08148148]
 [0.582397   0.36516854 0.05243446]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.33      0.56      0.42       346
         1.0       0.13      0.32      0.18       135
         2.0       0.30      0.05      0.09       534

    accuracy                           0.26      1015
   macro avg       0.25      0.31      0.23      1015
weighted avg       0.29      0.26      0.21      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.1931, Recall: 0.2830, Precision: 0.2226, F1 Score: 0.1878
Confusion Matrix: 
 [[0.26536313 0.57821229 0.15642458]
 [0.37323944 0.53521127 0.0915493 ]
 [0.40194175 0.54951456 0.04854369]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.27      0.27      0.27       358
         1.0       0.13      0.54      0.21       142
         2.0       0.27      0.05      0.08       515

    accuracy                           0.19      1015
   macro avg       0.22      0.28      0.19      1015
weighted avg       0.25      0.19      0.17      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.4246, Recall: 0.3589, Precision: 0.3600, F1 Score: 0.3414
Confusion Matrix: 
 [[0.6028169  0.13802817 0.25915493]
 [0.59090909 0.06493506 0.34415584]
 [0.54940711 0.04150198 0.40909091]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.37      0.60      0.46       355
         1.0       0.12      0.06      0.09       154
         2.0       0.59      0.41      0.48       506

    accuracy                           0.42      1015
   macro avg       0.36      0.36      0.34      1015
weighted avg       0.44      0.42      0.41      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.4286, Recall: 0.3933, Precision: 0.4640, F1 Score: 0.3658
Confusion Matrix: 
 [[0.18888889 0.25833333 0.55277778]
 [0.09655172 0.37931034 0.52413793]
 [0.03137255 0.35686275 0.61176471]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.19      0.30       360
         1.0       0.17      0.38      0.23       145
         2.0       0.53      0.61      0.57       510

    accuracy                           0.43      1015
   macro avg       0.46      0.39      0.37      1015
weighted avg       0.54      0.43      0.42      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.1931, Recall: 0.2932, Precision: 0.2240, F1 Score: 0.1859
Confusion Matrix: 
 [[0.31024096 0.5873494  0.10240964]
 [0.39583333 0.54166667 0.0625    ]
 [0.38218924 0.58998145 0.02782931]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.31      0.30       332
         1.0       0.13      0.54      0.21       144
         2.0       0.26      0.03      0.05       539

    accuracy                           0.19      1015
   macro avg       0.22      0.29      0.19      1015
weighted avg       0.25      0.19      0.15      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.4000, Recall: 0.3056, Precision: 0.3089, F1 Score: 0.3022
Confusion Matrix: 
 [[0.2654321  0.14197531 0.59259259]
 [0.35064935 0.07792208 0.57142857]
 [0.39292365 0.03351955 0.5735568 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.25      0.27      0.25       324
         1.0       0.16      0.08      0.10       154
         2.0       0.52      0.57      0.55       537

    accuracy                           0.40      1015
   macro avg       0.31      0.31      0.30      1015
weighted avg       0.38      0.40      0.39      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.1833, Recall: 0.3011, Precision: 0.2027, F1 Score: 0.1787
Confusion Matrix: 
 [[0.29050279 0.53072626 0.17877095]
 [0.34862385 0.57798165 0.0733945 ]
 [0.40145985 0.56386861 0.03467153]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.29      0.29      0.29       358
         1.0       0.11      0.58      0.19       109
         2.0       0.21      0.03      0.06       548

    accuracy                           0.18      1015
   macro avg       0.20      0.30      0.18      1015
weighted avg       0.23      0.18      0.15      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.3399, Recall: 0.3587, Precision: 0.4443, F1 Score: 0.3039
Confusion Matrix: 
 [[0.1503268  0.5130719  0.33660131]
 [0.05       0.525      0.425     ]
 [0.03904924 0.56027165 0.40067912]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.15      0.24       306
         1.0       0.11      0.53      0.19       120
         2.0       0.61      0.40      0.48       589

    accuracy                           0.34      1015
   macro avg       0.44      0.36      0.30      1015
weighted avg       0.55      0.34      0.37      1015

Average metrics:
 Accuracy: 0.3023, Precision: 0.3191, Recall: 0.3285, F1: 0.2641
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
Model: kmeans, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Error
Model: kmeans, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.2611, Recall: 0.3379, Precision: 0.2514, F1 Score: 0.2378
Confusion Matrix: 
 [[0.55151515 0.30606061 0.14242424]
 [0.52       0.42666667 0.05333333]
 [0.51588785 0.44859813 0.03551402]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.34      0.55      0.42       330
         1.0       0.16      0.43      0.23       150
         2.0       0.26      0.04      0.06       535

    accuracy                           0.26      1015
   macro avg       0.25      0.34      0.24      1015
weighted avg       0.27      0.26      0.20      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4167, Recall: 0.3151, Precision: 0.3122, F1 Score: 0.3122
Confusion Matrix: 
 [[0.31974922 0.17241379 0.50783699]
 [0.36428571 0.06428571 0.57142857]
 [0.38309353 0.0557554  0.56115108]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.32      0.30       319
         1.0       0.09      0.06      0.08       140
         2.0       0.56      0.56      0.56       556

    accuracy                           0.42      1015
   macro avg       0.31      0.32      0.31      1015
weighted avg       0.41      0.42      0.41      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4148, Recall: 0.3167, Precision: 0.3147, F1 Score: 0.3141
Confusion Matrix: 
 [[0.28612717 0.15317919 0.56069364]
 [0.31851852 0.08148148 0.6       ]
 [0.36516854 0.05243446 0.582397  ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.29      0.29      0.29       346
         1.0       0.12      0.08      0.10       135
         2.0       0.53      0.58      0.56       534

    accuracy                           0.41      1015
   macro avg       0.31      0.32      0.31      1015
weighted avg       0.40      0.41      0.40      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.1931, Recall: 0.2830, Precision: 0.2228, F1 Score: 0.1878
Confusion Matrix: 
 [[0.26536313 0.57821229 0.15642458]
 [0.37323944 0.53521127 0.0915493 ]
 [0.4        0.55145631 0.04854369]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.27      0.27      0.27       358
         1.0       0.13      0.54      0.21       142
         2.0       0.27      0.05      0.08       515

    accuracy                           0.19      1015
   macro avg       0.22      0.28      0.19      1015
weighted avg       0.25      0.19      0.17      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3419, Recall: 0.3793, Precision: 0.4522, F1 Score: 0.3183
Confusion Matrix: 
 [[0.13802817 0.6028169  0.25915493]
 [0.06493506 0.59090909 0.34415584]
 [0.04150198 0.54940711 0.40909091]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.14      0.23       355
         1.0       0.16      0.59      0.25       154
         2.0       0.59      0.41      0.48       506

    accuracy                           0.34      1015
   macro avg       0.45      0.38      0.32      1015
weighted avg       0.53      0.34      0.36      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.1823, Recall: 0.2713, Precision: 0.1915, F1 Score: 0.1766
Confusion Matrix: 
 [[0.25833333 0.55277778 0.18888889]
 [0.37931034 0.52413793 0.09655172]
 [0.35686275 0.61176471 0.03137255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.26      0.27       360
         1.0       0.13      0.52      0.21       145
         2.0       0.16      0.03      0.05       510

    accuracy                           0.18      1015
   macro avg       0.19      0.27      0.18      1015
weighted avg       0.20      0.18      0.15      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.1931, Recall: 0.2932, Precision: 0.2240, F1 Score: 0.1859
Confusion Matrix: 
 [[0.31024096 0.5873494  0.10240964]
 [0.39583333 0.54166667 0.0625    ]
 [0.38218924 0.58998145 0.02782931]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.31      0.30       332
         1.0       0.13      0.54      0.21       144
         2.0       0.26      0.03      0.05       539

    accuracy                           0.19      1015
   macro avg       0.22      0.29      0.19      1015
weighted avg       0.25      0.19      0.15      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.1882, Recall: 0.2895, Precision: 0.2070, F1 Score: 0.1824
Confusion Matrix: 
 [[0.2654321  0.59259259 0.14197531]
 [0.35064935 0.57142857 0.07792208]
 [0.39292365 0.57541899 0.03165736]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.25      0.27      0.25       324
         1.0       0.15      0.57      0.24       154
         2.0       0.23      0.03      0.06       537

    accuracy                           0.19      1015
   macro avg       0.21      0.29      0.18      1015
weighted avg       0.22      0.19      0.15      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4049, Recall: 0.3638, Precision: 0.4527, F1 Score: 0.3344
Confusion Matrix: 
 [[0.17877095 0.29050279 0.53072626]
 [0.0733945  0.34862385 0.57798165]
 [0.03467153 0.40145985 0.56386861]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.70      0.18      0.29       358
         1.0       0.10      0.35      0.16       109
         2.0       0.55      0.56      0.56       548

    accuracy                           0.40      1015
   macro avg       0.45      0.36      0.33      1015
weighted avg       0.56      0.40      0.42      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4325, Recall: 0.3156, Precision: 0.3147, F1 Score: 0.3123
Confusion Matrix: 
 [[0.33660131 0.1503268  0.5130719 ]
 [0.425      0.05       0.525     ]
 [0.40067912 0.03904924 0.56027165]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.26      0.34      0.30       306
         1.0       0.08      0.05      0.06       120
         2.0       0.60      0.56      0.58       589

    accuracy                           0.43      1015
   macro avg       0.31      0.32      0.31      1015
weighted avg       0.44      0.43      0.43      1015

Average metrics:
 Accuracy: 0.3029, Precision: 0.2943, Recall: 0.3165, F1: 0.2562
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
0  kmeans   True     True  NaN  0.302857   0.294329  0.316542  0.256169
Model: bag, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Error
Model: bag, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.3682, Precision: 0.3970, F1 Score: 0.3083
Confusion Matrix: 
 [[0.13636364 0.         0.86363636]
 [0.05333333 0.         0.94666667]
 [0.0317757  0.         0.9682243 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.14      0.23       330
         1.0       0.00      0.00      0.00       150
         2.0       0.55      0.97      0.70       535

    accuracy                           0.55      1015
   macro avg       0.40      0.37      0.31      1015
weighted avg       0.50      0.55      0.44      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5793, Recall: 0.3761, Precision: 0.4090, F1 Score: 0.3277
Confusion Matrix: 
 [[0.1661442  0.         0.8338558 ]
 [0.05       0.         0.95      ]
 [0.03776978 0.         0.96223022]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.17      0.27       319
         1.0       0.00      0.00      0.00       140
         2.0       0.57      0.96      0.72       556

    accuracy                           0.58      1015
   macro avg       0.41      0.38      0.33      1015
weighted avg       0.52      0.58      0.48      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5517, Recall: 0.3672, Precision: 0.3796, F1 Score: 0.3117
Confusion Matrix: 
 [[0.15028902 0.         0.84971098]
 [0.07407407 0.         0.92592593]
 [0.04868914 0.         0.95131086]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.15      0.24       346
         1.0       0.00      0.00      0.00       135
         2.0       0.55      0.95      0.70       534

    accuracy                           0.55      1015
   macro avg       0.38      0.37      0.31      1015
weighted avg       0.49      0.55      0.45      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.3710, Precision: 0.3860, F1 Score: 0.3106
Confusion Matrix: 
 [[0.15363128 0.         0.84636872]
 [0.08450704 0.         0.91549296]
 [0.0407767  0.         0.9592233 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.15      0.25       358
         1.0       0.00      0.00      0.00       142
         2.0       0.53      0.96      0.69       515

    accuracy                           0.54      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.49      0.54      0.43      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5271, Recall: 0.3650, Precision: 0.3994, F1 Score: 0.2958
Confusion Matrix: 
 [[0.12676056 0.         0.87323944]
 [0.03246753 0.         0.96753247]
 [0.03162055 0.         0.96837945]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.68      0.13      0.21       355
         1.0       0.00      0.00      0.00       154
         2.0       0.52      0.97      0.67       506

    accuracy                           0.53      1015
   macro avg       0.40      0.37      0.30      1015
weighted avg       0.50      0.53      0.41      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3873, Precision: 0.4218, F1 Score: 0.3295
Confusion Matrix: 
 [[0.18333333 0.         0.81666667]
 [0.09655172 0.         0.90344828]
 [0.02156863 0.         0.97843137]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.73      0.18      0.29       360
         1.0       0.00      0.00      0.00       145
         2.0       0.54      0.98      0.70       510

    accuracy                           0.56      1015
   macro avg       0.42      0.39      0.33      1015
weighted avg       0.53      0.56      0.45      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.3580, Precision: 0.3954, F1 Score: 0.2894
Confusion Matrix: 
 [[0.09638554 0.         0.90361446]
 [0.04166667 0.         0.95833333]
 [0.02226345 0.         0.97773655]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.10      0.17       332
         1.0       0.00      0.00      0.00       144
         2.0       0.55      0.98      0.70       539

    accuracy                           0.55      1015
   macro avg       0.40      0.36      0.29      1015
weighted avg       0.50      0.55      0.43      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3683, Precision: 0.3889, F1 Score: 0.3076
Confusion Matrix: 
 [[0.13271605 0.         0.86728395]
 [0.07792208 0.         0.92207792]
 [0.02793296 0.         0.97206704]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.13      0.22       324
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.97      0.70       537

    accuracy                           0.56      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.49      0.56      0.44      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5852, Recall: 0.3810, Precision: 0.4384, F1 Score: 0.3324
Confusion Matrix: 
 [[0.17039106 0.         0.82960894]
 [0.05504587 0.         0.94495413]
 [0.02737226 0.         0.97262774]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.74      0.17      0.28       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.97      0.72       548

    accuracy                           0.59      1015
   macro avg       0.44      0.38      0.33      1015
weighted avg       0.57      0.59      0.49      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6089, Recall: 0.3743, Precision: 0.4283, F1 Score: 0.3315
Confusion Matrix: 
 [[0.15359477 0.         0.84640523]
 [0.03333333 0.         0.96666667]
 [0.03056027 0.         0.96943973]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.68      0.15      0.25       306
         1.0       0.00      0.00      0.00       120
         2.0       0.60      0.97      0.74       589

    accuracy                           0.61      1015
   macro avg       0.43      0.37      0.33      1015
weighted avg       0.56      0.61      0.51      1015

Average metrics:
 Accuracy: 0.5612, Precision: 0.4044, Recall: 0.3716, F1: 0.3145
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
0  kmeans   True     True  NaN  0.302857   0.294329  0.316542  0.256169
0     bag  False    False  NaN  0.561182   0.404371  0.371643  0.314456
Model: bag, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Error
Model: bag, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.3682, Precision: 0.3970, F1 Score: 0.3083
Confusion Matrix: 
 [[0.13636364 0.         0.86363636]
 [0.05333333 0.         0.94666667]
 [0.0317757  0.         0.9682243 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.14      0.23       330
         1.0       0.00      0.00      0.00       150
         2.0       0.55      0.97      0.70       535

    accuracy                           0.55      1015
   macro avg       0.40      0.37      0.31      1015
weighted avg       0.50      0.55      0.44      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5793, Recall: 0.3761, Precision: 0.4090, F1 Score: 0.3277
Confusion Matrix: 
 [[0.1661442  0.         0.8338558 ]
 [0.05       0.         0.95      ]
 [0.03776978 0.         0.96223022]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.17      0.27       319
         1.0       0.00      0.00      0.00       140
         2.0       0.57      0.96      0.72       556

    accuracy                           0.58      1015
   macro avg       0.41      0.38      0.33      1015
weighted avg       0.52      0.58      0.48      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5517, Recall: 0.3672, Precision: 0.3796, F1 Score: 0.3117
Confusion Matrix: 
 [[0.15028902 0.         0.84971098]
 [0.07407407 0.         0.92592593]
 [0.04868914 0.         0.95131086]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.15      0.24       346
         1.0       0.00      0.00      0.00       135
         2.0       0.55      0.95      0.70       534

    accuracy                           0.55      1015
   macro avg       0.38      0.37      0.31      1015
weighted avg       0.49      0.55      0.45      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.3710, Precision: 0.3860, F1 Score: 0.3106
Confusion Matrix: 
 [[0.15363128 0.         0.84636872]
 [0.08450704 0.         0.91549296]
 [0.0407767  0.         0.9592233 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.15      0.25       358
         1.0       0.00      0.00      0.00       142
         2.0       0.53      0.96      0.69       515

    accuracy                           0.54      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.49      0.54      0.43      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5271, Recall: 0.3650, Precision: 0.3994, F1 Score: 0.2958
Confusion Matrix: 
 [[0.12676056 0.         0.87323944]
 [0.03246753 0.         0.96753247]
 [0.03162055 0.         0.96837945]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.68      0.13      0.21       355
         1.0       0.00      0.00      0.00       154
         2.0       0.52      0.97      0.67       506

    accuracy                           0.53      1015
   macro avg       0.40      0.37      0.30      1015
weighted avg       0.50      0.53      0.41      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3873, Precision: 0.4218, F1 Score: 0.3295
Confusion Matrix: 
 [[0.18333333 0.         0.81666667]
 [0.09655172 0.         0.90344828]
 [0.02156863 0.         0.97843137]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.73      0.18      0.29       360
         1.0       0.00      0.00      0.00       145
         2.0       0.54      0.98      0.70       510

    accuracy                           0.56      1015
   macro avg       0.42      0.39      0.33      1015
weighted avg       0.53      0.56      0.45      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.3580, Precision: 0.3954, F1 Score: 0.2894
Confusion Matrix: 
 [[0.09638554 0.         0.90361446]
 [0.04166667 0.         0.95833333]
 [0.02226345 0.         0.97773655]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.10      0.17       332
         1.0       0.00      0.00      0.00       144
         2.0       0.55      0.98      0.70       539

    accuracy                           0.55      1015
   macro avg       0.40      0.36      0.29      1015
weighted avg       0.50      0.55      0.43      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3683, Precision: 0.3889, F1 Score: 0.3076
Confusion Matrix: 
 [[0.13271605 0.         0.86728395]
 [0.07792208 0.         0.92207792]
 [0.02793296 0.         0.97206704]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.13      0.22       324
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.97      0.70       537

    accuracy                           0.56      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.49      0.56      0.44      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5852, Recall: 0.3810, Precision: 0.4384, F1 Score: 0.3324
Confusion Matrix: 
 [[0.17039106 0.         0.82960894]
 [0.05504587 0.         0.94495413]
 [0.02737226 0.         0.97262774]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.74      0.17      0.28       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.97      0.72       548

    accuracy                           0.59      1015
   macro avg       0.44      0.38      0.33      1015
weighted avg       0.57      0.59      0.49      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6089, Recall: 0.3743, Precision: 0.4283, F1 Score: 0.3315
Confusion Matrix: 
 [[0.15359477 0.         0.84640523]
 [0.03333333 0.         0.96666667]
 [0.03056027 0.         0.96943973]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.68      0.15      0.25       306
         1.0       0.00      0.00      0.00       120
         2.0       0.60      0.97      0.74       589

    accuracy                           0.61      1015
   macro avg       0.43      0.37      0.33      1015
weighted avg       0.56      0.61      0.51      1015

Average metrics:
 Accuracy: 0.5612, Precision: 0.4044, Recall: 0.3716, F1: 0.3145
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
0  kmeans   True     True  NaN  0.302857   0.294329  0.316542  0.256169
0     bag  False    False  NaN  0.561182   0.404371  0.371643  0.314456
0     bag  False     True  NaN  0.561182   0.404371  0.371643  0.314456
Model: bag, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Error
Model: bag, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.3630, Precision: 0.3963, F1 Score: 0.2981
Confusion Matrix: 
 [[0.11515152 0.         0.88484848]
 [0.04666667 0.         0.95333333]
 [0.02616822 0.         0.97383178]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.12      0.20       330
         1.0       0.00      0.00      0.00       150
         2.0       0.54      0.97      0.70       535

    accuracy                           0.55      1015
   macro avg       0.40      0.36      0.30      1015
weighted avg       0.50      0.55      0.43      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5773, Recall: 0.3749, Precision: 0.4035, F1 Score: 0.3267
Confusion Matrix: 
 [[0.1661442  0.         0.8338558 ]
 [0.05       0.         0.95      ]
 [0.04136691 0.         0.95863309]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.17      0.26       319
         1.0       0.00      0.00      0.00       140
         2.0       0.57      0.96      0.72       556

    accuracy                           0.58      1015
   macro avg       0.40      0.37      0.33      1015
weighted avg       0.51      0.58      0.48      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3681, Precision: 0.3899, F1 Score: 0.3117
Confusion Matrix: 
 [[0.14739884 0.         0.85260116]
 [0.05925926 0.         0.94074074]
 [0.04307116 0.         0.95692884]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.15      0.24       346
         1.0       0.00      0.00      0.00       135
         2.0       0.55      0.96      0.70       534

    accuracy                           0.55      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.50      0.55      0.45      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.3704, Precision: 0.3879, F1 Score: 0.3086
Confusion Matrix: 
 [[0.14804469 0.         0.85195531]
 [0.08450704 0.         0.91549296]
 [0.0368932  0.         0.9631068 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.15      0.24       358
         1.0       0.00      0.00      0.00       142
         2.0       0.53      0.96      0.69       515

    accuracy                           0.54      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.49      0.54      0.43      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5291, Recall: 0.3669, Precision: 0.4029, F1 Score: 0.2989
Confusion Matrix: 
 [[0.13239437 0.         0.86760563]
 [0.03246753 0.         0.96753247]
 [0.03162055 0.         0.96837945]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.13      0.22       355
         1.0       0.00      0.00      0.00       154
         2.0       0.52      0.97      0.67       506

    accuracy                           0.53      1015
   macro avg       0.40      0.37      0.30      1015
weighted avg       0.50      0.53      0.41      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3839, Precision: 0.4242, F1 Score: 0.3234
Confusion Matrix: 
 [[0.16944444 0.         0.83055556]
 [0.08965517 0.         0.91034483]
 [0.01764706 0.         0.98235294]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.73      0.17      0.28       360
         1.0       0.00      0.00      0.00       145
         2.0       0.54      0.98      0.69       510

    accuracy                           0.55      1015
   macro avg       0.42      0.38      0.32      1015
weighted avg       0.53      0.55      0.45      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.3573, Precision: 0.3994, F1 Score: 0.2868
Confusion Matrix: 
 [[0.09036145 0.         0.90963855]
 [0.04166667 0.         0.95833333]
 [0.01855288 0.         0.98144712]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.09      0.16       332
         1.0       0.00      0.00      0.00       144
         2.0       0.55      0.98      0.70       539

    accuracy                           0.55      1015
   macro avg       0.40      0.36      0.29      1015
weighted avg       0.50      0.55      0.42      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3705, Precision: 0.4032, F1 Score: 0.3103
Confusion Matrix: 
 [[0.13580247 0.         0.86419753]
 [0.06493506 0.         0.93506494]
 [0.02420857 0.         0.97579143]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.14      0.23       324
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.98      0.71       537

    accuracy                           0.56      1015
   macro avg       0.40      0.37      0.31      1015
weighted avg       0.50      0.56      0.45      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5803, Recall: 0.3764, Precision: 0.4348, F1 Score: 0.3250
Confusion Matrix: 
 [[0.15642458 0.         0.84357542]
 [0.04587156 0.         0.95412844]
 [0.02737226 0.         0.97262774]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.74      0.16      0.26       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.97      0.72       548

    accuracy                           0.58      1015
   macro avg       0.43      0.38      0.32      1015
weighted avg       0.57      0.58      0.48      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6089, Recall: 0.3728, Precision: 0.4338, F1 Score: 0.3278
Confusion Matrix: 
 [[0.14379085 0.         0.85620915]
 [0.03333333 0.         0.96666667]
 [0.02546689 0.         0.97453311]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.70      0.14      0.24       306
         1.0       0.00      0.00      0.00       120
         2.0       0.60      0.97      0.74       589

    accuracy                           0.61      1015
   macro avg       0.43      0.37      0.33      1015
weighted avg       0.56      0.61      0.50      1015

Average metrics:
 Accuracy: 0.5605, Precision: 0.4076, Recall: 0.3704, F1: 0.3117
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
0  kmeans   True     True  NaN  0.302857   0.294329  0.316542  0.256169
0     bag  False    False  NaN  0.561182   0.404371  0.371643  0.314456
0     bag  False     True  NaN  0.561182   0.404371  0.371643  0.314456
0     bag   True     True  NaN  0.560493   0.407577  0.370420  0.311720
Model: voting, PCA: False, Standard: False, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'voting': ['soft', 'hard']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'voting': 'hard'}
 Best Score : 0.5536945812807883
Tunning - Saved Hyperparameters [./models/config]
Model: voting, PCA: False, Standard: False, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'voting': 'hard'}
VotingClassifier(estimators=[('dt',
                              DecisionTreeClassifier(criterion='entropy',
                                                     max_depth=5,
                                                     min_samples_leaf=7,
                                                     random_state=64)),
                             ('knn', KNeighborsClassifier(n_neighbors=30)),
                             ('rf',
                              RandomForestClassifier(max_depth=8,
                                                     max_features='auto',
                                                     n_estimators=500,
                                                     random_state=64)),
                             ('ab',
                              AdaBoostClassifier(learning_rate=1.04,
                                                 n_estimators=20,
                                                 random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3864, Precision: 0.3673, F1 Score: 0.3467
Confusion Matrix: 
 [[0.25454545 0.         0.74545455]
 [0.14       0.         0.86      ]
 [0.0953271  0.         0.9046729 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.25      0.35       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.90      0.69       535

    accuracy                           0.56      1015
   macro avg       0.37      0.39      0.35      1015
weighted avg       0.47      0.56      0.48      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5970, Recall: 0.4038, Precision: 0.4053, F1 Score: 0.3714
Confusion Matrix: 
 [[0.28526646 0.         0.71473354]
 [0.1        0.         0.9       ]
 [0.07374101 0.         0.92625899]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.29      0.39       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.93      0.72       556

    accuracy                           0.60      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.52      0.60      0.52      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5675, Recall: 0.3891, Precision: 0.3776, F1 Score: 0.3497
Confusion Matrix: 
 [[0.25144509 0.         0.74855491]
 [0.16296296 0.         0.83703704]
 [0.08426966 0.         0.91573034]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.25      0.35       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.92      0.70       534

    accuracy                           0.57      1015
   macro avg       0.38      0.39      0.35      1015
weighted avg       0.49      0.57      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.3894, Precision: 0.3786, F1 Score: 0.3450
Confusion Matrix: 
 [[0.24581006 0.         0.75418994]
 [0.15492958 0.         0.84507042]
 [0.0776699  0.         0.9223301 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.25      0.35       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.92      0.69       515

    accuracy                           0.55      1015
   macro avg       0.38      0.39      0.34      1015
weighted avg       0.49      0.55      0.47      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5438, Recall: 0.3869, Precision: 0.3826, F1 Score: 0.3385
Confusion Matrix: 
 [[0.23380282 0.         0.76619718]
 [0.0974026  0.         0.9025974 ]
 [0.07312253 0.         0.92687747]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.23      0.34       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.93      0.68       506

    accuracy                           0.54      1015
   macro avg       0.38      0.39      0.34      1015
weighted avg       0.48      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5842, Recall: 0.4173, Precision: 0.4195, F1 Score: 0.3764
Confusion Matrix: 
 [[0.30277778 0.         0.69722222]
 [0.15172414 0.         0.84827586]
 [0.05098039 0.         0.94901961]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.30      0.42       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.95      0.71       510

    accuracy                           0.58      1015
   macro avg       0.42      0.42      0.38      1015
weighted avg       0.53      0.58      0.51      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.3794, Precision: 0.3648, F1 Score: 0.3408
Confusion Matrix: 
 [[0.2439759  0.         0.7560241 ]
 [0.09027778 0.         0.90972222]
 [0.10575139 0.         0.89424861]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.24      0.34       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.89      0.69       539

    accuracy                           0.55      1015
   macro avg       0.36      0.38      0.34      1015
weighted avg       0.47      0.55      0.47      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.3925, Precision: 0.3803, F1 Score: 0.3513
Confusion Matrix: 
 [[0.25       0.         0.75      ]
 [0.14285714 0.         0.85714286]
 [0.0726257  0.         0.9273743 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.25      0.35       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.93      0.71       537

    accuracy                           0.57      1015
   macro avg       0.38      0.39      0.35      1015
weighted avg       0.48      0.57      0.48      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6030, Recall: 0.4068, Precision: 0.4142, F1 Score: 0.3772
Confusion Matrix: 
 [[0.29888268 0.         0.70111732]
 [0.13761468 0.         0.86238532]
 [0.07846715 0.         0.92153285]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.30      0.41       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.92      0.72       548

    accuracy                           0.60      1015
   macro avg       0.41      0.41      0.38      1015
weighted avg       0.55      0.60      0.53      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6256, Recall: 0.4039, Precision: 0.4144, F1 Score: 0.3777
Confusion Matrix: 
 [[0.27777778 0.         0.72222222]
 [0.11666667 0.         0.88333333]
 [0.06621392 0.         0.93378608]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.28      0.38       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.93      0.75       589

    accuracy                           0.63      1015
   macro avg       0.41      0.40      0.38      1015
weighted avg       0.55      0.63      0.55      1015

Average metrics:
 Accuracy: 0.5761, Precision: 0.3904, Recall: 0.3955, F1: 0.3575
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
0  kmeans   True     True  NaN  0.302857   0.294329  0.316542  0.256169
0     bag  False    False  NaN  0.561182   0.404371  0.371643  0.314456
0     bag  False     True  NaN  0.561182   0.404371  0.371643  0.314456
0     bag   True     True  NaN  0.560493   0.407577  0.370420  0.311720
0  voting  False    False  NaN  0.576059   0.390450  0.395537  0.357481
Model: voting, PCA: False, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'voting': ['soft', 'hard']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'voting': 'hard'}
 Best Score : 0.5557635467980295
Tunning - Saved Hyperparameters [./models/config]
Model: voting, PCA: False, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'voting': 'hard'}
VotingClassifier(estimators=[('dt',
                              DecisionTreeClassifier(criterion='entropy',
                                                     max_depth=5,
                                                     min_samples_leaf=7,
                                                     random_state=64)),
                             ('knn', KNeighborsClassifier(n_neighbors=30)),
                             ('rf',
                              RandomForestClassifier(max_depth=8,
                                                     max_features='auto',
                                                     n_estimators=500,
                                                     random_state=64)),
                             ('ab',
                              AdaBoostClassifier(learning_rate=1.04,
                                                 n_estimators=20,
                                                 random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.3859, Precision: 0.3645, F1 Score: 0.3471
Confusion Matrix: 
 [[0.26060606 0.         0.73939394]
 [0.14       0.         0.86      ]
 [0.10280374 0.         0.89719626]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.26      0.35       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.90      0.69       535

    accuracy                           0.56      1015
   macro avg       0.36      0.39      0.35      1015
weighted avg       0.47      0.56      0.48      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5951, Recall: 0.4026, Precision: 0.3999, F1 Score: 0.3700
Confusion Matrix: 
 [[0.28526646 0.         0.71473354]
 [0.11428571 0.         0.88571429]
 [0.07733813 0.         0.92266187]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.29      0.39       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.92      0.72       556

    accuracy                           0.60      1015
   macro avg       0.40      0.40      0.37      1015
weighted avg       0.52      0.60      0.52      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5724, Recall: 0.3946, Precision: 0.3847, F1 Score: 0.3575
Confusion Matrix: 
 [[0.2716763  0.         0.7283237 ]
 [0.14814815 0.         0.85185185]
 [0.08801498 0.         0.91198502]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.27      0.37       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.91      0.70       534

    accuracy                           0.57      1015
   macro avg       0.38      0.39      0.36      1015
weighted avg       0.50      0.57      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.3922, Precision: 0.3819, F1 Score: 0.3487
Confusion Matrix: 
 [[0.25418994 0.         0.74581006]
 [0.15492958 0.         0.84507042]
 [0.0776699  0.         0.9223301 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.25      0.36       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.92      0.69       515

    accuracy                           0.56      1015
   macro avg       0.38      0.39      0.35      1015
weighted avg       0.49      0.56      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.3862, Precision: 0.3822, F1 Score: 0.3380
Confusion Matrix: 
 [[0.23380282 0.         0.76619718]
 [0.09090909 0.         0.90909091]
 [0.07509881 0.         0.92490119]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.23      0.34       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.92      0.68       506

    accuracy                           0.54      1015
   macro avg       0.38      0.39      0.34      1015
weighted avg       0.48      0.54      0.46      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5862, Recall: 0.4191, Precision: 0.4224, F1 Score: 0.3789
Confusion Matrix: 
 [[0.30833333 0.         0.69166667]
 [0.14482759 0.         0.85517241]
 [0.05098039 0.         0.94901961]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.70      0.31      0.43       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.95      0.71       510

    accuracy                           0.59      1015
   macro avg       0.42      0.42      0.38      1015
weighted avg       0.53      0.59      0.51      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3792, Precision: 0.3615, F1 Score: 0.3409
Confusion Matrix: 
 [[0.24698795 0.         0.75301205]
 [0.10416667 0.         0.89583333]
 [0.10946197 0.         0.89053803]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.25      0.34       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.89      0.69       539

    accuracy                           0.55      1015
   macro avg       0.36      0.38      0.34      1015
weighted avg       0.47      0.55      0.47      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5773, Recall: 0.3993, Precision: 0.3900, F1 Score: 0.3600
Confusion Matrix: 
 [[0.26851852 0.         0.73148148]
 [0.13636364 0.         0.86363636]
 [0.0707635  0.         0.9292365 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.60      0.27      0.37       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.93      0.71       537

    accuracy                           0.58      1015
   macro avg       0.39      0.40      0.36      1015
weighted avg       0.49      0.58      0.49      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6020, Recall: 0.4072, Precision: 0.4133, F1 Score: 0.3787
Confusion Matrix: 
 [[0.30726257 0.         0.69273743]
 [0.11926606 0.         0.88073394]
 [0.08576642 0.         0.91423358]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.31      0.42       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.91      0.72       548

    accuracy                           0.60      1015
   macro avg       0.41      0.41      0.38      1015
weighted avg       0.55      0.60      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6296, Recall: 0.4077, Precision: 0.4182, F1 Score: 0.3823
Confusion Matrix: 
 [[0.2875817  0.         0.7124183 ]
 [0.125      0.         0.875     ]
 [0.06451613 0.         0.93548387]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.29      0.39       306
         1.0       0.00      0.00      0.00       120
         2.0       0.63      0.94      0.75       589

    accuracy                           0.63      1015
   macro avg       0.42      0.41      0.38      1015
weighted avg       0.55      0.63      0.56      1015

Average metrics:
 Accuracy: 0.5774, Precision: 0.3919, Recall: 0.3974, F1: 0.3602
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
0  kmeans   True     True  NaN  0.302857   0.294329  0.316542  0.256169
0     bag  False    False  NaN  0.561182   0.404371  0.371643  0.314456
0     bag  False     True  NaN  0.561182   0.404371  0.371643  0.314456
0     bag   True     True  NaN  0.560493   0.407577  0.370420  0.311720
0  voting  False    False  NaN  0.576059   0.390450  0.395537  0.357481
0  voting  False     True  NaN  0.577438   0.391874  0.397394  0.360216
Model: voting, PCA: True, Standard: True, SMOTE: False, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'voting': ['soft', 'hard']}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'voting': 'hard'}
 Best Score : 0.5544827586206897
Tunning - Saved Hyperparameters [./models/config]
Model: voting, PCA: True, Standard: True, SMOTE: False, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'voting': 'hard'}
VotingClassifier(estimators=[('dt',
                              DecisionTreeClassifier(criterion='entropy',
                                                     max_depth=5,
                                                     min_samples_leaf=7,
                                                     random_state=64)),
                             ('knn', KNeighborsClassifier(n_neighbors=30)),
                             ('rf',
                              RandomForestClassifier(max_depth=8,
                                                     max_features='auto',
                                                     n_estimators=500,
                                                     random_state=64)),
                             ('ab',
                              AdaBoostClassifier(learning_rate=1.04,
                                                 n_estimators=20,
                                                 random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3814, Precision: 0.3675, F1 Score: 0.3392
Confusion Matrix: 
 [[0.23030303 0.0030303  0.76666667]
 [0.12       0.         0.88      ]
 [0.08598131 0.         0.91401869]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.23      0.32       330
         1.0       0.00      0.00      0.00       150
         2.0       0.56      0.91      0.69       535

    accuracy                           0.56      1015
   macro avg       0.37      0.38      0.34      1015
weighted avg       0.47      0.56      0.47      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5951, Recall: 0.4009, Precision: 0.4041, F1 Score: 0.3672
Confusion Matrix: 
 [[0.27272727 0.         0.72727273]
 [0.1        0.         0.9       ]
 [0.07014388 0.         0.92985612]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.27      0.38       319
         1.0       0.00      0.00      0.00       140
         2.0       0.59      0.93      0.72       556

    accuracy                           0.60      1015
   macro avg       0.40      0.40      0.37      1015
weighted avg       0.52      0.60      0.51      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5685, Recall: 0.3880, Precision: 0.3804, F1 Score: 0.3465
Confusion Matrix: 
 [[0.23699422 0.         0.76300578]
 [0.16296296 0.         0.83703704]
 [0.07303371 0.         0.92696629]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.24      0.34       346
         1.0       0.00      0.00      0.00       135
         2.0       0.57      0.93      0.70       534

    accuracy                           0.57      1015
   macro avg       0.38      0.39      0.35      1015
weighted avg       0.49      0.57      0.48      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5626, Recall: 0.3951, Precision: 0.3888, F1 Score: 0.3507
Confusion Matrix: 
 [[0.25139665 0.         0.74860335]
 [0.16197183 0.         0.83802817]
 [0.06601942 0.         0.93398058]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.25      0.36       358
         1.0       0.00      0.00      0.00       142
         2.0       0.55      0.93      0.70       515

    accuracy                           0.56      1015
   macro avg       0.39      0.40      0.35      1015
weighted avg       0.50      0.56      0.48      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3850, Precision: 0.3777, F1 Score: 0.3358
Confusion Matrix: 
 [[0.22816901 0.         0.77183099]
 [0.11038961 0.         0.88961039]
 [0.07312253 0.         0.92687747]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.60      0.23      0.33       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.93      0.68       506

    accuracy                           0.54      1015
   macro avg       0.38      0.39      0.34      1015
weighted avg       0.48      0.54      0.45      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5803, Recall: 0.4133, Precision: 0.4141, F1 Score: 0.3708
Confusion Matrix: 
 [[0.28888889 0.         0.71111111]
 [0.16551724 0.         0.83448276]
 [0.04901961 0.         0.95098039]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.68      0.29      0.41       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.95      0.71       510

    accuracy                           0.58      1015
   macro avg       0.41      0.41      0.37      1015
weighted avg       0.52      0.58      0.50      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5635, Recall: 0.3819, Precision: 0.3764, F1 Score: 0.3390
Confusion Matrix: 
 [[0.21987952 0.         0.78012048]
 [0.11111111 0.         0.88888889]
 [0.0742115  0.         0.9257885 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.22      0.32       332
         1.0       0.00      0.00      0.00       144
         2.0       0.56      0.93      0.70       539

    accuracy                           0.56      1015
   macro avg       0.38      0.38      0.34      1015
weighted avg       0.48      0.56      0.48      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5685, Recall: 0.3900, Precision: 0.3781, F1 Score: 0.3478
Confusion Matrix: 
 [[0.24074074 0.         0.75925926]
 [0.14285714 0.         0.85714286]
 [0.0707635  0.         0.9292365 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.24      0.34       324
         1.0       0.00      0.00      0.00       154
         2.0       0.57      0.93      0.71       537

    accuracy                           0.57      1015
   macro avg       0.38      0.39      0.35      1015
weighted avg       0.48      0.57      0.48      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5980, Recall: 0.4012, Precision: 0.4121, F1 Score: 0.3693
Confusion Matrix: 
 [[0.27653631 0.         0.72346369]
 [0.12844037 0.         0.87155963]
 [0.0729927  0.         0.9270073 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.28      0.39       358
         1.0       0.00      0.00      0.00       109
         2.0       0.59      0.93      0.72       548

    accuracy                           0.60      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.55      0.60      0.53      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6256, Recall: 0.4033, Precision: 0.4229, F1 Score: 0.3776
Confusion Matrix: 
 [[0.2745098  0.         0.7254902 ]
 [0.06666667 0.         0.93333333]
 [0.06451613 0.         0.93548387]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.27      0.39       306
         1.0       0.00      0.00      0.00       120
         2.0       0.62      0.94      0.75       589

    accuracy                           0.63      1015
   macro avg       0.42      0.40      0.38      1015
weighted avg       0.56      0.63      0.55      1015

Average metrics:
 Accuracy: 0.5761, Precision: 0.3922, Recall: 0.3940, F1: 0.3544
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.569852   0.372183  0.397408  0.363901
0      dt  False     True  NaN  0.569852   0.372183  0.397408  0.363901
0      dt   True     True  NaN  0.566798   0.424344  0.390513  0.354200
0     knn  False    False  NaN  0.553399   0.354900  0.383585  0.348770
0     knn  False     True  NaN  0.562956   0.413083  0.395826  0.364472
0     knn   True     True  NaN  0.563842   0.413425  0.395968  0.364260
0      rf  False    False  NaN  0.574187   0.395435  0.390732  0.349026
0      rf  False     True  NaN  0.574187   0.395435  0.390732  0.349026
0      rf   True     True  NaN  0.575074   0.395866  0.391858  0.350754
0      ab  False    False  NaN  0.573990   0.381359  0.397155  0.361808
0      ab  False     True  NaN  0.573892   0.381270  0.397050  0.361692
0      ab   True     True  NaN  0.562857   0.372009  0.384825  0.345286
0      gb  False    False  NaN  0.579310   0.413184  0.403109  0.369809
0      gb  False     True  NaN  0.579310   0.413184  0.403109  0.369809
0      gb   True     True  NaN  0.573005   0.472446  0.395815  0.360245
0  kmeans  False    False  NaN  0.281773   0.275428  0.310967  0.236136
0  kmeans  False     True  NaN  0.302266   0.319101  0.328481  0.264108
0  kmeans   True     True  NaN  0.302857   0.294329  0.316542  0.256169
0     bag  False    False  NaN  0.561182   0.404371  0.371643  0.314456
0     bag  False     True  NaN  0.561182   0.404371  0.371643  0.314456
0     bag   True     True  NaN  0.560493   0.407577  0.370420  0.311720
0  voting  False    False  NaN  0.576059   0.390450  0.395537  0.357481
0  voting  False     True  NaN  0.577438   0.391874  0.397394  0.360216
0  voting   True     True  NaN  0.576059   0.392197  0.394011  0.354401
