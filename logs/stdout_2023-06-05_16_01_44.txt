OrderedDict([('data_path', './dataset/FireDataset.csv'),
             ('param_path', './models/config'),
             ('seed', 64),
             ('redirector', True),
             ('visual', False),
             ('model', 'ab'),
             ('param_load', False),
             ('voting_list', ['dt', 'knn', 'rf', 'ab', 'gb']),
             ('tune', 'grid'),
             ('n_iter', 10),
             ('cv', 5),
             ('pca', False),
             ('n_components', 0.95),
             ('smote', True),
             ('standard', False),
             ('eval', 'kfold'),
             ('n_split', 10),
             ('num_class', 3)])
------------------------------------------------------------
Model: dt, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
 Best Score : 0.5705418719211823
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
DecisionTreeClassifier(max_depth=3, min_samples_leaf=9, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5478, Recall: 0.3576, Precision: 0.4111, F1 Score: 0.2853
Confusion Matrix: 
 [[0.08787879 0.0030303  0.90909091]
 [0.04       0.         0.96      ]
 [0.01308411 0.00186916 0.98504673]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.09      0.16       330
         1.0       0.00      0.00      0.00       150
         2.0       0.54      0.99      0.70       535

    accuracy                           0.55      1015
   macro avg       0.41      0.36      0.29      1015
weighted avg       0.51      0.55      0.42      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5764, Recall: 0.3681, Precision: 0.4301, F1 Score: 0.3097
Confusion Matrix: 
 [[0.12225705 0.         0.87774295]
 [0.03571429 0.         0.96428571]
 [0.01798561 0.         0.98201439]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.72      0.12      0.21       319
         1.0       0.00      0.00      0.00       140
         2.0       0.57      0.98      0.72       556

    accuracy                           0.58      1015
   macro avg       0.43      0.37      0.31      1015
weighted avg       0.54      0.58      0.46      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5438, Recall: 0.3745, Precision: 0.4224, F1 Score: 0.3399
Confusion Matrix: 
 [[0.17630058 0.04913295 0.77456647]
 [0.0962963  0.03703704 0.86666667]
 [0.05805243 0.03183521 0.91011236]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.18      0.27       346
         1.0       0.13      0.04      0.06       135
         2.0       0.56      0.91      0.69       534

    accuracy                           0.54      1015
   macro avg       0.42      0.37      0.34      1015
weighted avg       0.51      0.54      0.46      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5340, Recall: 0.3761, Precision: 0.3478, F1 Score: 0.3341
Confusion Matrix: 
 [[0.24860335 0.         0.75139665]
 [0.18309859 0.         0.81690141]
 [0.12038835 0.         0.87961165]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.25      0.33       358
         1.0       0.00      0.00      0.00       142
         2.0       0.54      0.88      0.67       515

    accuracy                           0.53      1015
   macro avg       0.35      0.38      0.33      1015
weighted avg       0.45      0.53      0.46      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5113, Recall: 0.3677, Precision: 0.3264, F1 Score: 0.3259
Confusion Matrix: 
 [[0.25915493 0.         0.74084507]
 [0.20779221 0.         0.79220779]
 [0.15612648 0.         0.84387352]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.26      0.33       355
         1.0       0.00      0.00      0.00       154
         2.0       0.53      0.84      0.65       506

    accuracy                           0.51      1015
   macro avg       0.33      0.37      0.33      1015
weighted avg       0.42      0.51      0.44      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.3812, Precision: 0.4203, F1 Score: 0.3190
Confusion Matrix: 
 [[0.16111111 0.         0.83888889]
 [0.08965517 0.         0.91034483]
 [0.01764706 0.         0.98235294]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.72      0.16      0.26       360
         1.0       0.00      0.00      0.00       145
         2.0       0.54      0.98      0.69       510

    accuracy                           0.55      1015
   macro avg       0.42      0.38      0.32      1015
weighted avg       0.53      0.55      0.44      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5251, Recall: 0.3582, Precision: 0.3219, F1 Score: 0.3191
Confusion Matrix: 
 [[0.22289157 0.         0.77710843]
 [0.15972222 0.         0.84027778]
 [0.14842301 0.         0.85157699]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.22      0.29       332
         1.0       0.00      0.00      0.00       144
         2.0       0.55      0.85      0.67       539

    accuracy                           0.53      1015
   macro avg       0.32      0.36      0.32      1015
weighted avg       0.43      0.53      0.45      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3802, Precision: 0.3501, F1 Score: 0.3411
Confusion Matrix: 
 [[0.25617284 0.         0.74382716]
 [0.16233766 0.         0.83766234]
 [0.11545624 0.         0.88454376]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.26      0.34       324
         1.0       0.00      0.00      0.00       154
         2.0       0.56      0.88      0.69       537

    accuracy                           0.55      1015
   macro avg       0.35      0.38      0.34      1015
weighted avg       0.45      0.55      0.47      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5803, Recall: 0.3741, Precision: 0.4609, F1 Score: 0.3178
Confusion Matrix: 
 [[0.13687151 0.         0.86312849]
 [0.03669725 0.         0.96330275]
 [0.01277372 0.00182482 0.98540146]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.82      0.14      0.23       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.99      0.72       548

    accuracy                           0.58      1015
   macro avg       0.46      0.37      0.32      1015
weighted avg       0.59      0.58      0.47      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6069, Recall: 0.3701, Precision: 0.4321, F1 Score: 0.3230
Confusion Matrix: 
 [[0.13398693 0.         0.86601307]
 [0.03333333 0.         0.96666667]
 [0.0237691  0.         0.9762309 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.69      0.13      0.22       306
         1.0       0.00      0.00      0.00       120
         2.0       0.60      0.98      0.74       589

    accuracy                           0.61      1015
   macro avg       0.43      0.37      0.32      1015
weighted avg       0.56      0.61      0.50      1015

Average metrics:
 Accuracy: 0.5526, Precision: 0.3923, Recall: 0.3708, F1: 0.3215
  model    pca standard tune  accuracy  precision    recall      f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.3215
Model: dt, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
 Best Score : 0.5705418719211823
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 9, 'min_samples_split': 2}
DecisionTreeClassifier(max_depth=3, min_samples_leaf=9, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.2522, Recall: 0.3545, Precision: 0.4588, F1 Score: 0.2432
Confusion Matrix: 
 [[0.11212121 0.7        0.18787879]
 [0.03333333 0.75333333 0.21333333]
 [0.02056075 0.78130841 0.19813084]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.70      0.11      0.19       330
         1.0       0.15      0.75      0.25       150
         2.0       0.53      0.20      0.29       535

    accuracy                           0.25      1015
   macro avg       0.46      0.35      0.24      1015
weighted avg       0.53      0.25      0.25      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.4266, Recall: 0.4235, Precision: 0.4489, F1 Score: 0.3973
Confusion Matrix: 
 [[0.32601881 0.31347962 0.36050157]
 [0.13571429 0.47142857 0.39285714]
 [0.10431655 0.42266187 0.47302158]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.33      0.42       319
         1.0       0.16      0.47      0.24       140
         2.0       0.61      0.47      0.53       556

    accuracy                           0.43      1015
   macro avg       0.45      0.42      0.40      1015
weighted avg       0.54      0.43      0.46      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5261, Recall: 0.3762, Precision: 0.4292, F1 Score: 0.3527
Confusion Matrix: 
 [[0.17630058 0.07225434 0.75144509]
 [0.0962963  0.08888889 0.81481481]
 [0.05805243 0.07865169 0.86329588]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.18      0.27       346
         1.0       0.15      0.09      0.11       135
         2.0       0.55      0.86      0.68       534

    accuracy                           0.53      1015
   macro avg       0.43      0.38      0.35      1015
weighted avg       0.51      0.53      0.46      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.4847, Recall: 0.3593, Precision: 0.4205, F1 Score: 0.3368
Confusion Matrix: 
 [[0.36871508 0.00558659 0.62569832]
 [0.28873239 0.01408451 0.6971831 ]
 [0.30097087 0.0038835  0.69514563]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.40      0.37      0.38       358
         1.0       0.33      0.01      0.03       142
         2.0       0.53      0.70      0.60       515

    accuracy                           0.48      1015
   macro avg       0.42      0.36      0.34      1015
weighted avg       0.46      0.48      0.44      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.3635, Recall: 0.3627, Precision: 0.3950, F1 Score: 0.3449
Confusion Matrix: 
 [[0.27887324 0.30704225 0.41408451]
 [0.17532468 0.3961039  0.42857143]
 [0.11264822 0.4743083  0.41304348]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.28      0.37       355
         1.0       0.15      0.40      0.22       154
         2.0       0.50      0.41      0.45       506

    accuracy                           0.36      1015
   macro avg       0.40      0.36      0.34      1015
weighted avg       0.46      0.36      0.39      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5291, Recall: 0.3905, Precision: 0.4176, F1 Score: 0.3641
Confusion Matrix: 
 [[0.36944444 0.01388889 0.61666667]
 [0.26896552 0.0137931  0.71724138]
 [0.20784314 0.00392157 0.78823529]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.37      0.42       360
         1.0       0.22      0.01      0.03       145
         2.0       0.55      0.79      0.65       510

    accuracy                           0.53      1015
   macro avg       0.42      0.39      0.36      1015
weighted avg       0.48      0.53      0.48      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.3633, Precision: 0.5752, F1 Score: 0.3010
Confusion Matrix: 
 [[0.08433735 0.0060241  0.90963855]
 [0.00694444 0.02777778 0.96527778]
 [0.01669759 0.00556586 0.97773655]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.74      0.08      0.15       332
         1.0       0.44      0.03      0.05       144
         2.0       0.54      0.98      0.70       539

    accuracy                           0.55      1015
   macro avg       0.58      0.36      0.30      1015
weighted avg       0.59      0.55      0.43      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5241, Recall: 0.3733, Precision: 0.3710, F1 Score: 0.3459
Confusion Matrix: 
 [[0.30246914 0.0154321  0.68209877]
 [0.27272727 0.01298701 0.71428571]
 [0.18063315 0.01489758 0.80446927]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.41      0.30      0.35       324
         1.0       0.13      0.01      0.02       154
         2.0       0.57      0.80      0.66       537

    accuracy                           0.52      1015
   macro avg       0.37      0.37      0.35      1015
weighted avg       0.45      0.52      0.47      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5813, Recall: 0.3760, Precision: 0.4490, F1 Score: 0.3226
Confusion Matrix: 
 [[0.14804469 0.         0.85195531]
 [0.04587156 0.         0.95412844]
 [0.01824818 0.00182482 0.97992701]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.78      0.15      0.25       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.98      0.72       548

    accuracy                           0.58      1015
   macro avg       0.45      0.38      0.32      1015
weighted avg       0.58      0.58      0.48      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5606, Recall: 0.3665, Precision: 0.3465, F1 Score: 0.3456
Confusion Matrix: 
 [[0.27777778 0.02614379 0.69607843]
 [0.175      0.         0.825     ]
 [0.15449915 0.0237691  0.82173175]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.28      0.34       306
         1.0       0.00      0.00      0.00       120
         2.0       0.61      0.82      0.70       589

    accuracy                           0.56      1015
   macro avg       0.35      0.37      0.35      1015
weighted avg       0.48      0.56      0.51      1015

Average metrics:
 Accuracy: 0.4799, Precision: 0.4312, Recall: 0.3746, F1: 0.3354
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
Model: dt, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'max_depth': [2, 3, 4, 5, 6, None], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
 Best Score : 0.5632512315270937
Tunning - Saved Hyperparameters [./models/config]
Model: dt, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3300, Recall: 0.3784, Precision: 0.3954, F1 Score: 0.3292
Confusion Matrix: 
 [[0.33939394 0.48787879 0.17272727]
 [0.24666667 0.52666667 0.22666667]
 [0.22056075 0.51028037 0.26915888]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.34      0.38       330
         1.0       0.15      0.53      0.24       150
         2.0       0.61      0.27      0.37       535

    accuracy                           0.33      1015
   macro avg       0.40      0.38      0.33      1015
weighted avg       0.48      0.33      0.35      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4759, Recall: 0.4023, Precision: 0.4103, F1 Score: 0.4019
Confusion Matrix: 
 [[0.39184953 0.20062696 0.40752351]
 [0.27142857 0.22857143 0.5       ]
 [0.18884892 0.22482014 0.58633094]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.39      0.43       319
         1.0       0.14      0.23      0.18       140
         2.0       0.62      0.59      0.60       556

    accuracy                           0.48      1015
   macro avg       0.41      0.40      0.40      1015
weighted avg       0.51      0.48      0.49      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3468, Recall: 0.3643, Precision: 0.4071, F1 Score: 0.3323
Confusion Matrix: 
 [[0.25722543 0.49710983 0.24566474]
 [0.21481481 0.45925926 0.32592593]
 [0.11985019 0.50374532 0.37640449]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.26      0.34       346
         1.0       0.12      0.46      0.19       135
         2.0       0.61      0.38      0.47       534

    accuracy                           0.35      1015
   macro avg       0.41      0.36      0.33      1015
weighted avg       0.50      0.35      0.39      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3212, Recall: 0.3734, Precision: 0.4074, F1 Score: 0.3187
Confusion Matrix: 
 [[0.24301676 0.55027933 0.20670391]
 [0.19014085 0.57042254 0.23943662]
 [0.12621359 0.56699029 0.30679612]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.24      0.32       358
         1.0       0.14      0.57      0.23       142
         2.0       0.59      0.31      0.40       515

    accuracy                           0.32      1015
   macro avg       0.41      0.37      0.32      1015
weighted avg       0.49      0.32      0.35      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3773, Recall: 0.4124, Precision: 0.4431, F1 Score: 0.3706
Confusion Matrix: 
 [[0.29295775 0.45633803 0.25070423]
 [0.14285714 0.56493506 0.29220779]
 [0.11264822 0.50790514 0.37944664]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.57      0.29      0.39       355
         1.0       0.17      0.56      0.26       154
         2.0       0.59      0.38      0.46       506

    accuracy                           0.38      1015
   macro avg       0.44      0.41      0.37      1015
weighted avg       0.52      0.38      0.41      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3123, Recall: 0.3595, Precision: 0.4104, F1 Score: 0.3156
Confusion Matrix: 
 [[0.27777778 0.53888889 0.18333333]
 [0.2        0.52413793 0.27586207]
 [0.11764706 0.60588235 0.27647059]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.28      0.36       360
         1.0       0.13      0.52      0.21       145
         2.0       0.57      0.28      0.37       510

    accuracy                           0.31      1015
   macro avg       0.41      0.36      0.32      1015
weighted avg       0.49      0.31      0.35      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3232, Recall: 0.4058, Precision: 0.4361, F1 Score: 0.3241
Confusion Matrix: 
 [[0.24698795 0.59036145 0.1626506 ]
 [0.14583333 0.70138889 0.15277778]
 [0.1187384  0.6122449  0.2690167 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.25      0.33       332
         1.0       0.16      0.70      0.26       144
         2.0       0.66      0.27      0.38       539

    accuracy                           0.32      1015
   macro avg       0.44      0.41      0.32      1015
weighted avg       0.53      0.32      0.35      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3360, Recall: 0.3602, Precision: 0.3727, F1 Score: 0.3283
Confusion Matrix: 
 [[0.36419753 0.40740741 0.22839506]
 [0.33766234 0.42207792 0.24025974]
 [0.25884544 0.44692737 0.29422719]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.38      0.36      0.37       324
         1.0       0.15      0.42      0.22       154
         2.0       0.59      0.29      0.39       537

    accuracy                           0.34      1015
   macro avg       0.37      0.36      0.33      1015
weighted avg       0.46      0.34      0.36      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3192, Recall: 0.3667, Precision: 0.4146, F1 Score: 0.3157
Confusion Matrix: 
 [[0.30167598 0.52793296 0.17039106]
 [0.2293578  0.50458716 0.26605505]
 [0.14963504 0.55656934 0.29379562]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.30      0.38       358
         1.0       0.10      0.50      0.17       109
         2.0       0.64      0.29      0.40       548

    accuracy                           0.32      1015
   macro avg       0.41      0.37      0.32      1015
weighted avg       0.53      0.32      0.37      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3862, Recall: 0.3989, Precision: 0.4177, F1 Score: 0.3627
Confusion Matrix: 
 [[0.35947712 0.39869281 0.24183007]
 [0.24166667 0.45       0.30833333]
 [0.17317487 0.43972835 0.38709677]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.36      0.40       306
         1.0       0.12      0.45      0.19       120
         2.0       0.67      0.39      0.49       589

    accuracy                           0.39      1015
   macro avg       0.42      0.40      0.36      1015
weighted avg       0.54      0.39      0.43      1015

Average metrics:
 Accuracy: 0.3528, Precision: 0.4115, Recall: 0.3822, F1: 0.3399
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
Model: knn, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'n_neighbors': 30}
 Best Score : 0.5465024630541871
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.3734, Recall: 0.4031, Precision: 0.4094, F1 Score: 0.3650
Confusion Matrix: 
 [[0.41818182 0.38787879 0.19393939]
 [0.26666667 0.47333333 0.26      ]
 [0.25420561 0.42803738 0.31775701]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.42      0.43       330
         1.0       0.17      0.47      0.25       150
         2.0       0.62      0.32      0.42       535

    accuracy                           0.37      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.50      0.37      0.40      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.3507, Recall: 0.3720, Precision: 0.3816, F1 Score: 0.3377
Confusion Matrix: 
 [[0.42633229 0.36050157 0.21316614]
 [0.35       0.39285714 0.25714286]
 [0.28776978 0.41546763 0.29676259]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.39      0.43      0.41       319
         1.0       0.14      0.39      0.20       140
         2.0       0.61      0.30      0.40       556

    accuracy                           0.35      1015
   macro avg       0.38      0.37      0.34      1015
weighted avg       0.48      0.35      0.38      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.3429, Recall: 0.3751, Precision: 0.3864, F1 Score: 0.3340
Confusion Matrix: 
 [[0.4017341  0.41040462 0.18786127]
 [0.3037037  0.44444444 0.25185185]
 [0.28089888 0.44007491 0.27902622]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.40      0.41       346
         1.0       0.14      0.44      0.21       135
         2.0       0.60      0.28      0.38       534

    accuracy                           0.34      1015
   macro avg       0.39      0.38      0.33      1015
weighted avg       0.48      0.34      0.37      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.3645, Recall: 0.3787, Precision: 0.3936, F1 Score: 0.3510
Confusion Matrix: 
 [[0.41620112 0.37430168 0.20949721]
 [0.35211268 0.40140845 0.24647887]
 [0.26990291 0.41165049 0.3184466 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.42      0.43       358
         1.0       0.14      0.40      0.21       142
         2.0       0.60      0.32      0.42       515

    accuracy                           0.36      1015
   macro avg       0.39      0.38      0.35      1015
weighted avg       0.48      0.36      0.39      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.3448, Recall: 0.3571, Precision: 0.3711, F1 Score: 0.3335
Confusion Matrix: 
 [[0.3943662  0.38873239 0.21690141]
 [0.37012987 0.37662338 0.25324675]
 [0.30237154 0.3972332  0.30039526]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.40      0.39      0.40       355
         1.0       0.15      0.38      0.21       154
         2.0       0.57      0.30      0.39       506

    accuracy                           0.34      1015
   macro avg       0.37      0.36      0.33      1015
weighted avg       0.44      0.34      0.37      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.3429, Recall: 0.3640, Precision: 0.3817, F1 Score: 0.3327
Confusion Matrix: 
 [[0.43611111 0.38055556 0.18333333]
 [0.37241379 0.39310345 0.23448276]
 [0.29019608 0.44705882 0.2627451 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.44      0.44       360
         1.0       0.14      0.39      0.20       145
         2.0       0.57      0.26      0.36       510

    accuracy                           0.34      1015
   macro avg       0.38      0.36      0.33      1015
weighted avg       0.46      0.34      0.36      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.3113, Recall: 0.3205, Precision: 0.3421, F1 Score: 0.3002
Confusion Matrix: 
 [[0.36746988 0.40361446 0.22891566]
 [0.31944444 0.31944444 0.36111111]
 [0.283859   0.44155844 0.27458256]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.38      0.37      0.37       332
         1.0       0.11      0.32      0.16       144
         2.0       0.54      0.27      0.36       539

    accuracy                           0.31      1015
   macro avg       0.34      0.32      0.30      1015
weighted avg       0.42      0.31      0.34      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.3557, Recall: 0.3652, Precision: 0.3837, F1 Score: 0.3423
Confusion Matrix: 
 [[0.41358025 0.38580247 0.20061728]
 [0.36363636 0.36363636 0.27272727]
 [0.27746741 0.40409683 0.31843575]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.40      0.41      0.40       324
         1.0       0.14      0.36      0.20       154
         2.0       0.62      0.32      0.42       537

    accuracy                           0.36      1015
   macro avg       0.38      0.37      0.34      1015
weighted avg       0.47      0.36      0.38      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.3704, Recall: 0.4001, Precision: 0.4101, F1 Score: 0.3535
Confusion Matrix: 
 [[0.44413408 0.36871508 0.18715084]
 [0.26605505 0.44954128 0.28440367]
 [0.25912409 0.43430657 0.30656934]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.44      0.46       358
         1.0       0.12      0.45      0.19       109
         2.0       0.63      0.31      0.41       548

    accuracy                           0.37      1015
   macro avg       0.41      0.40      0.35      1015
weighted avg       0.52      0.37      0.41      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.3330, Recall: 0.3660, Precision: 0.3742, F1 Score: 0.3179
Confusion Matrix: 
 [[0.37254902 0.42810458 0.19934641]
 [0.325      0.43333333 0.24166667]
 [0.30560272 0.40237691 0.29202037]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.34      0.37      0.36       306
         1.0       0.12      0.43      0.19       120
         2.0       0.66      0.29      0.40       589

    accuracy                           0.33      1015
   macro avg       0.37      0.37      0.32      1015
weighted avg       0.50      0.33      0.36      1015

Average metrics:
 Accuracy: 0.3490, Precision: 0.3834, Recall: 0.3702, F1: 0.3368
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
Model: knn, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'n_neighbors': 29}
 Best Score : 0.5532019704433498
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 29}
KNeighborsClassifier(n_neighbors=29)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.3754, Recall: 0.3839, Precision: 0.3999, F1 Score: 0.3600
Confusion Matrix: 
 [[0.43333333 0.36363636 0.2030303 ]
 [0.35333333 0.38       0.26666667]
 [0.26168224 0.4        0.33831776]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.43      0.43       330
         1.0       0.15      0.38      0.21       150
         2.0       0.63      0.34      0.44       535

    accuracy                           0.38      1015
   macro avg       0.40      0.38      0.36      1015
weighted avg       0.49      0.38      0.40      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.3517, Recall: 0.3606, Precision: 0.3775, F1 Score: 0.3342
Confusion Matrix: 
 [[0.42946708 0.36050157 0.21003135]
 [0.39285714 0.34285714 0.26428571]
 [0.29676259 0.39388489 0.30935252]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.38      0.43      0.41       319
         1.0       0.13      0.34      0.18       140
         2.0       0.62      0.31      0.41       556

    accuracy                           0.35      1015
   macro avg       0.38      0.36      0.33      1015
weighted avg       0.48      0.35      0.38      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.3517, Recall: 0.3682, Precision: 0.3860, F1 Score: 0.3376
Confusion Matrix: 
 [[0.43641618 0.3699422  0.19364162]
 [0.37037037 0.37777778 0.25185185]
 [0.28651685 0.42322097 0.29026217]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.44      0.43       346
         1.0       0.13      0.38      0.19       135
         2.0       0.61      0.29      0.39       534

    accuracy                           0.35      1015
   macro avg       0.39      0.37      0.34      1015
weighted avg       0.48      0.35      0.38      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.3379, Recall: 0.3677, Precision: 0.3789, F1 Score: 0.3297
Confusion Matrix: 
 [[0.41340782 0.40502793 0.18156425]
 [0.31690141 0.42957746 0.25352113]
 [0.30097087 0.43883495 0.26019417]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.41      0.42       358
         1.0       0.14      0.43      0.21       142
         2.0       0.57      0.26      0.36       515

    accuracy                           0.34      1015
   macro avg       0.38      0.37      0.33      1015
weighted avg       0.46      0.34      0.36      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.3478, Recall: 0.3760, Precision: 0.3898, F1 Score: 0.3421
Confusion Matrix: 
 [[0.42816901 0.38028169 0.1915493 ]
 [0.32467532 0.43506494 0.24025974]
 [0.256917   0.47826087 0.26482213]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.43      0.44       355
         1.0       0.15      0.44      0.22       154
         2.0       0.56      0.26      0.36       506

    accuracy                           0.35      1015
   macro avg       0.39      0.38      0.34      1015
weighted avg       0.46      0.35      0.37      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.3714, Recall: 0.3796, Precision: 0.4019, F1 Score: 0.3571
Confusion Matrix: 
 [[0.45277778 0.37222222 0.175     ]
 [0.32413793 0.37241379 0.30344828]
 [0.26470588 0.42156863 0.31372549]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.45      0.46       360
         1.0       0.13      0.37      0.20       145
         2.0       0.60      0.31      0.41       510

    accuracy                           0.37      1015
   macro avg       0.40      0.38      0.36      1015
weighted avg       0.49      0.37      0.40      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.3586, Recall: 0.3814, Precision: 0.3944, F1 Score: 0.3474
Confusion Matrix: 
 [[0.4126506  0.39759036 0.18975904]
 [0.32638889 0.42361111 0.25      ]
 [0.27829314 0.41372913 0.30797774]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.41      0.41      0.41       332
         1.0       0.15      0.42      0.22       144
         2.0       0.63      0.31      0.41       539

    accuracy                           0.36      1015
   macro avg       0.39      0.38      0.35      1015
weighted avg       0.49      0.36      0.38      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.3547, Recall: 0.3618, Precision: 0.3759, F1 Score: 0.3404
Confusion Matrix: 
 [[0.40432099 0.36728395 0.22839506]
 [0.33766234 0.35714286 0.30519481]
 [0.27374302 0.40223464 0.32402235]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.40      0.40      0.40       324
         1.0       0.14      0.36      0.20       154
         2.0       0.59      0.32      0.42       537

    accuracy                           0.35      1015
   macro avg       0.38      0.36      0.34      1015
weighted avg       0.46      0.35      0.38      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.3665, Recall: 0.3552, Precision: 0.3893, F1 Score: 0.3379
Confusion Matrix: 
 [[0.41620112 0.37709497 0.20670391]
 [0.37614679 0.30275229 0.32110092]
 [0.26277372 0.39051095 0.34671533]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.42      0.43       358
         1.0       0.09      0.30      0.13       109
         2.0       0.64      0.35      0.45       548

    accuracy                           0.37      1015
   macro avg       0.39      0.36      0.34      1015
weighted avg       0.51      0.37      0.41      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.3675, Recall: 0.3756, Precision: 0.3900, F1 Score: 0.3433
Confusion Matrix: 
 [[0.46078431 0.34313725 0.19607843]
 [0.33333333 0.34166667 0.325     ]
 [0.28862479 0.38709677 0.32427844]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.40      0.46      0.43       306
         1.0       0.11      0.34      0.17       120
         2.0       0.66      0.32      0.43       589

    accuracy                           0.37      1015
   macro avg       0.39      0.38      0.34      1015
weighted avg       0.52      0.37      0.40      1015

Average metrics:
 Accuracy: 0.3583, Precision: 0.3884, Recall: 0.3710, F1: 0.3430
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
Model: knn, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'n_neighbors': 30}
 Best Score : 0.5521182266009853
Tunning - Saved Hyperparameters [./models/config]
Model: knn, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3685, Recall: 0.3685, Precision: 0.3849, F1 Score: 0.3500
Confusion Matrix: 
 [[0.38484848 0.37575758 0.23939394]
 [0.34       0.36       0.3       ]
 [0.25233645 0.38691589 0.36074766]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.41      0.38      0.40       330
         1.0       0.14      0.36      0.20       150
         2.0       0.61      0.36      0.45       535

    accuracy                           0.37      1015
   macro avg       0.38      0.37      0.35      1015
weighted avg       0.47      0.37      0.40      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3655, Recall: 0.3739, Precision: 0.3890, F1 Score: 0.3470
Confusion Matrix: 
 [[0.43887147 0.36050157 0.20062696]
 [0.36428571 0.35714286 0.27857143]
 [0.28956835 0.38489209 0.32553957]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.40      0.44      0.42       319
         1.0       0.13      0.36      0.19       140
         2.0       0.64      0.33      0.43       556

    accuracy                           0.37      1015
   macro avg       0.39      0.37      0.35      1015
weighted avg       0.49      0.37      0.39      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3557, Recall: 0.3607, Precision: 0.3872, F1 Score: 0.3389
Confusion Matrix: 
 [[0.43063584 0.37283237 0.19653179]
 [0.38518519 0.34074074 0.27407407]
 [0.2659176  0.42322097 0.31086142]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.43      0.43       346
         1.0       0.11      0.34      0.17       135
         2.0       0.61      0.31      0.41       534

    accuracy                           0.36      1015
   macro avg       0.39      0.36      0.34      1015
weighted avg       0.49      0.36      0.39      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3340, Recall: 0.3677, Precision: 0.3791, F1 Score: 0.3270
Confusion Matrix: 
 [[0.40502793 0.41620112 0.17877095]
 [0.32394366 0.44366197 0.23239437]
 [0.29902913 0.44660194 0.25436893]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.41      0.41       358
         1.0       0.14      0.44      0.22       142
         2.0       0.57      0.25      0.35       515

    accuracy                           0.33      1015
   macro avg       0.38      0.37      0.33      1015
weighted avg       0.46      0.33      0.35      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3507, Recall: 0.3692, Precision: 0.3835, F1 Score: 0.3422
Confusion Matrix: 
 [[0.4        0.38591549 0.21408451]
 [0.33116883 0.40909091 0.25974026]
 [0.26284585 0.43873518 0.29841897]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.40      0.42       355
         1.0       0.15      0.41      0.22       154
         2.0       0.57      0.30      0.39       506

    accuracy                           0.35      1015
   macro avg       0.38      0.37      0.34      1015
weighted avg       0.46      0.35      0.37      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3823, Recall: 0.3970, Precision: 0.4117, F1 Score: 0.3690
Confusion Matrix: 
 [[0.45555556 0.36666667 0.17777778]
 [0.28965517 0.4137931  0.29655172]
 [0.26470588 0.41372549 0.32156863]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.46      0.47       360
         1.0       0.15      0.41      0.22       145
         2.0       0.61      0.32      0.42       510

    accuracy                           0.38      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.50      0.38      0.41      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3813, Recall: 0.4000, Precision: 0.4103, F1 Score: 0.3672
Confusion Matrix: 
 [[0.40662651 0.39156627 0.20180723]
 [0.3125     0.44444444 0.24305556]
 [0.2541744  0.39703154 0.34879406]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.41      0.42       332
         1.0       0.16      0.44      0.23       144
         2.0       0.65      0.35      0.45       539

    accuracy                           0.38      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.51      0.38      0.41      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3517, Recall: 0.3646, Precision: 0.3723, F1 Score: 0.3394
Confusion Matrix: 
 [[0.40432099 0.35185185 0.24382716]
 [0.31168831 0.37662338 0.31168831]
 [0.27746741 0.40968343 0.31284916]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.40      0.40      0.40       324
         1.0       0.15      0.38      0.21       154
         2.0       0.57      0.31      0.40       537

    accuracy                           0.35      1015
   macro avg       0.37      0.36      0.34      1015
weighted avg       0.45      0.35      0.37      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3823, Recall: 0.3849, Precision: 0.4031, F1 Score: 0.3553
Confusion Matrix: 
 [[0.41899441 0.36871508 0.2122905 ]
 [0.33027523 0.37614679 0.29357798]
 [0.26094891 0.37956204 0.35948905]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.42      0.44       358
         1.0       0.11      0.38      0.17       109
         2.0       0.65      0.36      0.46       548

    accuracy                           0.38      1015
   macro avg       0.40      0.38      0.36      1015
weighted avg       0.52      0.38      0.42      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3675, Recall: 0.3710, Precision: 0.3840, F1 Score: 0.3414
Confusion Matrix: 
 [[0.41830065 0.35620915 0.2254902 ]
 [0.30833333 0.35       0.34166667]
 [0.27504244 0.3803056  0.34465195]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.39      0.42      0.40       306
         1.0       0.11      0.35      0.17       120
         2.0       0.65      0.34      0.45       589

    accuracy                           0.37      1015
   macro avg       0.38      0.37      0.34      1015
weighted avg       0.51      0.37      0.40      1015

Average metrics:
 Accuracy: 0.3639, Precision: 0.3905, Recall: 0.3757, F1: 0.3477
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
Model: rf, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion': ['gini', 'entropy']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
 Best Score : 0.5711330049261084
Tunning - Saved Hyperparameters [./models/config]
Model: rf, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
RandomForestClassifier(criterion='entropy', max_depth=6, max_features='auto',
                       n_estimators=200, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.3993, Precision: 0.4385, F1 Score: 0.3908
Confusion Matrix: 
 [[0.28787879 0.04848485 0.66363636]
 [0.14       0.09333333 0.76666667]
 [0.12523364 0.05794393 0.81682243]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.29      0.37       330
         1.0       0.23      0.09      0.13       150
         2.0       0.57      0.82      0.67       535

    accuracy                           0.54      1015
   macro avg       0.44      0.40      0.39      1015
weighted avg       0.50      0.54      0.49      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5399, Recall: 0.4060, Precision: 0.4421, F1 Score: 0.4066
Confusion Matrix: 
 [[0.30721003 0.11285266 0.5799373 ]
 [0.13571429 0.13571429 0.72857143]
 [0.09532374 0.1294964  0.77517986]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.31      0.40       319
         1.0       0.15      0.14      0.14       140
         2.0       0.60      0.78      0.68       556

    accuracy                           0.54      1015
   macro avg       0.44      0.41      0.41      1015
weighted avg       0.53      0.54      0.52      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5310, Recall: 0.4016, Precision: 0.4255, F1 Score: 0.3969
Confusion Matrix: 
 [[0.30346821 0.09248555 0.60404624]
 [0.17037037 0.11851852 0.71111111]
 [0.13670412 0.08052434 0.78277154]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.30      0.38       346
         1.0       0.18      0.12      0.14       135
         2.0       0.58      0.78      0.67       534

    accuracy                           0.53      1015
   macro avg       0.43      0.40      0.40      1015
weighted avg       0.51      0.53      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5113, Recall: 0.3858, Precision: 0.4044, F1 Score: 0.3773
Confusion Matrix: 
 [[0.30726257 0.08938547 0.60335196]
 [0.21830986 0.07746479 0.70422535]
 [0.1184466  0.10873786 0.77281553]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.31      0.39       358
         1.0       0.11      0.08      0.09       142
         2.0       0.56      0.77      0.65       515

    accuracy                           0.51      1015
   macro avg       0.40      0.39      0.38      1015
weighted avg       0.49      0.51      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5202, Recall: 0.3970, Precision: 0.4131, F1 Score: 0.3852
Confusion Matrix: 
 [[0.31267606 0.11549296 0.57183099]
 [0.18831169 0.07792208 0.73376623]
 [0.12648221 0.07312253 0.80039526]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.31      0.40       355
         1.0       0.13      0.08      0.10       154
         2.0       0.56      0.80      0.66       506

    accuracy                           0.52      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.49      0.52      0.48      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.4148, Precision: 0.4472, F1 Score: 0.4105
Confusion Matrix: 
 [[0.35277778 0.11666667 0.53055556]
 [0.22068966 0.08965517 0.68965517]
 [0.07254902 0.1254902  0.80196078]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.35      0.46       360
         1.0       0.11      0.09      0.10       145
         2.0       0.58      0.80      0.68       510

    accuracy                           0.54      1015
   macro avg       0.45      0.41      0.41      1015
weighted avg       0.54      0.54      0.52      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5389, Recall: 0.3923, Precision: 0.4160, F1 Score: 0.3804
Confusion Matrix: 
 [[0.28915663 0.0753012  0.63554217]
 [0.15277778 0.06944444 0.77777778]
 [0.14285714 0.03896104 0.81818182]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.29      0.36       332
         1.0       0.18      0.07      0.10       144
         2.0       0.58      0.82      0.68       539

    accuracy                           0.54      1015
   macro avg       0.42      0.39      0.38      1015
weighted avg       0.49      0.54      0.49      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.3955, Precision: 0.4146, F1 Score: 0.3828
Confusion Matrix: 
 [[0.29938272 0.08333333 0.61728395]
 [0.18181818 0.05844156 0.75974026]
 [0.10614525 0.06517691 0.82867784]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.30      0.38       324
         1.0       0.13      0.06      0.08       154
         2.0       0.58      0.83      0.69       537

    accuracy                           0.54      1015
   macro avg       0.41      0.40      0.38      1015
weighted avg       0.50      0.54      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.4131, Precision: 0.4476, F1 Score: 0.4126
Confusion Matrix: 
 [[0.34078212 0.11173184 0.54748603]
 [0.17431193 0.11009174 0.71559633]
 [0.09854015 0.11313869 0.78832117]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.34      0.44       358
         1.0       0.11      0.11      0.11       109
         2.0       0.61      0.79      0.69       548

    accuracy                           0.56      1015
   macro avg       0.45      0.41      0.41      1015
weighted avg       0.56      0.56      0.54      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5685, Recall: 0.4089, Precision: 0.4427, F1 Score: 0.4110
Confusion Matrix: 
 [[0.30718954 0.12745098 0.56535948]
 [0.16666667 0.125      0.70833333]
 [0.09168081 0.11375212 0.79456706]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.31      0.40       306
         1.0       0.12      0.12      0.12       120
         2.0       0.64      0.79      0.71       589

    accuracy                           0.57      1015
   macro avg       0.44      0.41      0.41      1015
weighted avg       0.56      0.57      0.55      1015

Average metrics:
 Accuracy: 0.5389, Precision: 0.4292, Recall: 0.4014, F1: 0.3954
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
Model: rf, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion': ['gini', 'entropy']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
 Best Score : 0.5713300492610838
Tunning - Saved Hyperparameters [./models/config]
Model: rf, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}
RandomForestClassifier(criterion='entropy', max_depth=6, max_features='auto',
                       n_estimators=200, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5123, Recall: 0.4230, Precision: 0.4420, F1 Score: 0.4233
Confusion Matrix: 
 [[0.32424242 0.11818182 0.55757576]
 [0.13333333 0.24       0.62666667]
 [0.15327103 0.14205607 0.7046729 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.32      0.40       330
         1.0       0.24      0.24      0.24       150
         2.0       0.58      0.70      0.63       535

    accuracy                           0.51      1015
   macro avg       0.44      0.42      0.42      1015
weighted avg       0.51      0.51      0.50      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.4369, Precision: 0.4593, F1 Score: 0.4397
Confusion Matrix: 
 [[0.36050157 0.11285266 0.52664577]
 [0.17857143 0.19285714 0.62857143]
 [0.13129496 0.11151079 0.75719424]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.36      0.43       319
         1.0       0.22      0.19      0.20       140
         2.0       0.62      0.76      0.68       556

    accuracy                           0.55      1015
   macro avg       0.46      0.44      0.44      1015
weighted avg       0.54      0.55      0.54      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.4768, Recall: 0.3901, Precision: 0.4025, F1 Score: 0.3877
Confusion Matrix: 
 [[0.30924855 0.16763006 0.52312139]
 [0.22962963 0.20740741 0.56296296]
 [0.15730337 0.18913858 0.65355805]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.31      0.38       346
         1.0       0.15      0.21      0.17       135
         2.0       0.58      0.65      0.61       534

    accuracy                           0.48      1015
   macro avg       0.40      0.39      0.39      1015
weighted avg       0.49      0.48      0.47      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.4887, Recall: 0.3919, Precision: 0.4035, F1 Score: 0.3900
Confusion Matrix: 
 [[0.32960894 0.13407821 0.53631285]
 [0.26760563 0.15492958 0.57746479]
 [0.1592233  0.14951456 0.69126214]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.33      0.40       358
         1.0       0.15      0.15      0.15       142
         2.0       0.57      0.69      0.62       515

    accuracy                           0.49      1015
   macro avg       0.40      0.39      0.39      1015
weighted avg       0.48      0.49      0.48      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.4857, Recall: 0.3917, Precision: 0.4106, F1 Score: 0.3889
Confusion Matrix: 
 [[0.30985915 0.18591549 0.50422535]
 [0.19480519 0.15584416 0.64935065]
 [0.13636364 0.1541502  0.70948617]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.31      0.39       355
         1.0       0.14      0.16      0.15       154
         2.0       0.56      0.71      0.63       506

    accuracy                           0.49      1015
   macro avg       0.41      0.39      0.39      1015
weighted avg       0.49      0.49      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5300, Recall: 0.4427, Precision: 0.4629, F1 Score: 0.4451
Confusion Matrix: 
 [[0.425      0.15555556 0.41944444]
 [0.24827586 0.20689655 0.54482759]
 [0.11568627 0.18823529 0.69607843]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.42      0.50       360
         1.0       0.16      0.21      0.18       145
         2.0       0.61      0.70      0.65       510

    accuracy                           0.53      1015
   macro avg       0.46      0.44      0.45      1015
weighted avg       0.55      0.53      0.53      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5084, Recall: 0.4167, Precision: 0.4312, F1 Score: 0.4157
Confusion Matrix: 
 [[0.3253012  0.16566265 0.50903614]
 [0.15277778 0.22916667 0.61805556]
 [0.15584416 0.14842301 0.69573284]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.33      0.40       332
         1.0       0.20      0.23      0.21       144
         2.0       0.59      0.70      0.64       539

    accuracy                           0.51      1015
   macro avg       0.43      0.42      0.42      1015
weighted avg       0.51      0.51      0.50      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5005, Recall: 0.3857, Precision: 0.4087, F1 Score: 0.3880
Confusion Matrix: 
 [[0.34567901 0.12962963 0.52469136]
 [0.22727273 0.1038961  0.66883117]
 [0.11173184 0.18063315 0.70763501]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.35      0.42       324
         1.0       0.10      0.10      0.10       154
         2.0       0.58      0.71      0.64       537

    accuracy                           0.50      1015
   macro avg       0.41      0.39      0.39      1015
weighted avg       0.50      0.50      0.49      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5232, Recall: 0.4098, Precision: 0.4356, F1 Score: 0.4134
Confusion Matrix: 
 [[0.39106145 0.17597765 0.43296089]
 [0.21100917 0.1559633  0.63302752]
 [0.13868613 0.17883212 0.68248175]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.39      0.47       358
         1.0       0.10      0.16      0.12       109
         2.0       0.63      0.68      0.65       548

    accuracy                           0.52      1015
   macro avg       0.44      0.41      0.41      1015
weighted avg       0.55      0.52      0.53      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.4221, Precision: 0.4372, F1 Score: 0.4246
Confusion Matrix: 
 [[0.3627451  0.16013072 0.47712418]
 [0.25833333 0.16666667 0.575     ]
 [0.13073005 0.13242784 0.73684211]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.36      0.42       306
         1.0       0.14      0.17      0.15       120
         2.0       0.67      0.74      0.70       589

    accuracy                           0.56      1015
   macro avg       0.44      0.42      0.42      1015
weighted avg       0.56      0.56      0.55      1015

Average metrics:
 Accuracy: 0.5137, Precision: 0.4293, Recall: 0.4111, F1: 0.4116
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
Model: rf, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [200, 500], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion': ['gini', 'entropy']}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
 Best Score : 0.5683743842364533
Tunning - Saved Hyperparameters [./models/config]
Model: rf, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4680, Recall: 0.4391, Precision: 0.4393, F1 Score: 0.4253
Confusion Matrix: 
 [[0.38181818 0.25151515 0.36666667]
 [0.24666667 0.39333333 0.36      ]
 [0.17196262 0.28598131 0.54205607]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.38      0.43       330
         1.0       0.20      0.39      0.27       150
         2.0       0.62      0.54      0.58       535

    accuracy                           0.47      1015
   macro avg       0.44      0.44      0.43      1015
weighted avg       0.52      0.47      0.48      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4345, Recall: 0.4154, Precision: 0.4233, F1 Score: 0.3987
Confusion Matrix: 
 [[0.39811912 0.29153605 0.31034483]
 [0.24285714 0.37857143 0.37857143]
 [0.1852518  0.34532374 0.46942446]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.40      0.44       319
         1.0       0.16      0.38      0.22       140
         2.0       0.63      0.47      0.54       556

    accuracy                           0.43      1015
   macro avg       0.42      0.42      0.40      1015
weighted avg       0.52      0.43      0.46      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4227, Recall: 0.3894, Precision: 0.4114, F1 Score: 0.3820
Confusion Matrix: 
 [[0.37572254 0.30924855 0.3150289 ]
 [0.26666667 0.31111111 0.42222222]
 [0.17602996 0.34269663 0.48127341]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.38      0.43       346
         1.0       0.13      0.31      0.18       135
         2.0       0.61      0.48      0.54       534

    accuracy                           0.42      1015
   macro avg       0.41      0.39      0.38      1015
weighted avg       0.51      0.42      0.45      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4158, Recall: 0.3939, Precision: 0.4209, F1 Score: 0.3823
Confusion Matrix: 
 [[0.33519553 0.37709497 0.2877095 ]
 [0.22535211 0.35915493 0.41549296]
 [0.15533981 0.35728155 0.48737864]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.34      0.41       358
         1.0       0.14      0.36      0.20       142
         2.0       0.61      0.49      0.54       515

    accuracy                           0.42      1015
   macro avg       0.42      0.39      0.38      1015
weighted avg       0.51      0.42      0.45      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4433, Recall: 0.4134, Precision: 0.4263, F1 Score: 0.4034
Confusion Matrix: 
 [[0.34366197 0.30704225 0.34929577]
 [0.21428571 0.35714286 0.42857143]
 [0.16205534 0.29841897 0.53952569]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.34      0.41       355
         1.0       0.17      0.36      0.23       154
         2.0       0.59      0.54      0.56       506

    accuracy                           0.44      1015
   macro avg       0.43      0.41      0.40      1015
weighted avg       0.50      0.44      0.46      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4305, Recall: 0.4123, Precision: 0.4380, F1 Score: 0.4022
Confusion Matrix: 
 [[0.40277778 0.32222222 0.275     ]
 [0.23448276 0.36551724 0.4       ]
 [0.15294118 0.37843137 0.46862745]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.40      0.47       360
         1.0       0.15      0.37      0.21       145
         2.0       0.60      0.47      0.53       510

    accuracy                           0.43      1015
   macro avg       0.44      0.41      0.40      1015
weighted avg       0.52      0.43      0.46      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4493, Recall: 0.4233, Precision: 0.4332, F1 Score: 0.4084
Confusion Matrix: 
 [[0.36144578 0.31626506 0.32228916]
 [0.20138889 0.38888889 0.40972222]
 [0.16697588 0.3135436  0.51948052]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.36      0.42       332
         1.0       0.17      0.39      0.24       144
         2.0       0.63      0.52      0.57       539

    accuracy                           0.45      1015
   macro avg       0.43      0.42      0.41      1015
weighted avg       0.52      0.45      0.47      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4355, Recall: 0.4017, Precision: 0.4111, F1 Score: 0.3946
Confusion Matrix: 
 [[0.37962963 0.27469136 0.34567901]
 [0.24675325 0.32467532 0.42857143]
 [0.18994413 0.30912477 0.5009311 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.38      0.42       324
         1.0       0.16      0.32      0.22       154
         2.0       0.60      0.50      0.55       537

    accuracy                           0.44      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.49      0.44      0.46      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4365, Recall: 0.3988, Precision: 0.4195, F1 Score: 0.3854
Confusion Matrix: 
 [[0.37709497 0.29888268 0.32402235]
 [0.22018349 0.32110092 0.4587156 ]
 [0.1770073  0.32481752 0.49817518]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.38      0.44       358
         1.0       0.11      0.32      0.16       109
         2.0       0.62      0.50      0.55       548

    accuracy                           0.44      1015
   macro avg       0.42      0.40      0.39      1015
weighted avg       0.53      0.44      0.47      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4690, Recall: 0.4079, Precision: 0.4147, F1 Score: 0.3990
Confusion Matrix: 
 [[0.39542484 0.26470588 0.33986928]
 [0.25833333 0.28333333 0.45833333]
 [0.20203735 0.25297114 0.54499151]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.40      0.42       306
         1.0       0.13      0.28      0.18       120
         2.0       0.67      0.54      0.60       589

    accuracy                           0.47      1015
   macro avg       0.41      0.41      0.40      1015
weighted avg       0.54      0.47      0.50      1015

Average metrics:
 Accuracy: 0.4405, Precision: 0.4238, Recall: 0.4095, F1: 0.3981
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0    rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
Model: ab, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 30], 'algorithm': ['SAMME', 'SAMME.R'], 'learning_rate': [0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
 Best Score : 0.5652216748768473
Tunning - Saved Hyperparameters [./models/config]
Model: ab, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.03, n_estimators=20, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.4759, Recall: 0.3716, Precision: 0.3783, F1 Score: 0.3699
Confusion Matrix: 
 [[0.3030303  0.13333333 0.56363636]
 [0.26       0.13333333 0.60666667]
 [0.18130841 0.14018692 0.67850467]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.30      0.35       330
         1.0       0.14      0.13      0.14       150
         2.0       0.57      0.68      0.62       535

    accuracy                           0.48      1015
   macro avg       0.38      0.37      0.37      1015
weighted avg       0.46      0.48      0.46      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.4788, Recall: 0.3885, Precision: 0.4006, F1 Score: 0.3893
Confusion Matrix: 
 [[0.3322884  0.1630094  0.50470219]
 [0.15       0.2        0.65      ]
 [0.17985612 0.18705036 0.63309353]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.33      0.39       319
         1.0       0.15      0.20      0.17       140
         2.0       0.58      0.63      0.61       556

    accuracy                           0.48      1015
   macro avg       0.40      0.39      0.39      1015
weighted avg       0.49      0.48      0.48      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.4709, Recall: 0.3748, Precision: 0.3822, F1 Score: 0.3742
Confusion Matrix: 
 [[0.32080925 0.19364162 0.48554913]
 [0.22962963 0.15555556 0.61481481]
 [0.20599251 0.14606742 0.64794007]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.32      0.37       346
         1.0       0.13      0.16      0.14       135
         2.0       0.58      0.65      0.61       534

    accuracy                           0.47      1015
   macro avg       0.38      0.37      0.37      1015
weighted avg       0.47      0.47      0.47      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.4768, Recall: 0.3955, Precision: 0.4120, F1 Score: 0.3937
Confusion Matrix: 
 [[0.32402235 0.16759777 0.50837989]
 [0.23239437 0.20422535 0.56338028]
 [0.14368932 0.19805825 0.65825243]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.32      0.40       358
         1.0       0.15      0.20      0.17       142
         2.0       0.56      0.66      0.61       515

    accuracy                           0.48      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.49      0.48      0.47      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.4857, Recall: 0.3863, Precision: 0.4047, F1 Score: 0.3858
Confusion Matrix: 
 [[0.34647887 0.14929577 0.50422535]
 [0.22727273 0.11688312 0.65584416]
 [0.13636364 0.16798419 0.69565217]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.35      0.42       355
         1.0       0.12      0.12      0.12       154
         2.0       0.56      0.70      0.62       506

    accuracy                           0.49      1015
   macro avg       0.40      0.39      0.39      1015
weighted avg       0.48      0.49      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5015, Recall: 0.4037, Precision: 0.4212, F1 Score: 0.4044
Confusion Matrix: 
 [[0.37222222 0.13611111 0.49166667]
 [0.26206897 0.14482759 0.59310345]
 [0.13529412 0.17058824 0.69411765]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.56      0.37      0.45       360
         1.0       0.13      0.14      0.14       145
         2.0       0.57      0.69      0.63       510

    accuracy                           0.50      1015
   macro avg       0.42      0.40      0.40      1015
weighted avg       0.50      0.50      0.49      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5153, Recall: 0.3954, Precision: 0.4032, F1 Score: 0.3922
Confusion Matrix: 
 [[0.37650602 0.08433735 0.53915663]
 [0.25694444 0.09722222 0.64583333]
 [0.22077922 0.06679035 0.71243043]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.38      0.41       332
         1.0       0.18      0.10      0.13       144
         2.0       0.59      0.71      0.64       539

    accuracy                           0.52      1015
   macro avg       0.40      0.40      0.39      1015
weighted avg       0.48      0.52      0.49      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.4818, Recall: 0.3782, Precision: 0.3985, F1 Score: 0.3729
Confusion Matrix: 
 [[0.23765432 0.19753086 0.56481481]
 [0.13636364 0.18181818 0.68181818]
 [0.12476723 0.16014898 0.7150838 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.24      0.31       324
         1.0       0.16      0.18      0.17       154
         2.0       0.57      0.72      0.64       537

    accuracy                           0.48      1015
   macro avg       0.40      0.38      0.37      1015
weighted avg       0.48      0.48      0.46      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.4936, Recall: 0.4026, Precision: 0.4339, F1 Score: 0.4003
Confusion Matrix: 
 [[0.33798883 0.17318436 0.48882682]
 [0.12844037 0.22018349 0.65137615]
 [0.12408759 0.22627737 0.64963504]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.60      0.34      0.43       358
         1.0       0.11      0.22      0.15       109
         2.0       0.59      0.65      0.62       548

    accuracy                           0.49      1015
   macro avg       0.43      0.40      0.40      1015
weighted avg       0.54      0.49      0.50      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5281, Recall: 0.4145, Precision: 0.4204, F1 Score: 0.4145
Confusion Matrix: 
 [[0.3627451  0.16013072 0.47712418]
 [0.25833333 0.2        0.54166667]
 [0.17317487 0.14601019 0.68081494]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.36      0.40       306
         1.0       0.15      0.20      0.17       120
         2.0       0.66      0.68      0.67       589

    accuracy                           0.53      1015
   macro avg       0.42      0.41      0.41      1015
weighted avg       0.54      0.53      0.53      1015

Average metrics:
 Accuracy: 0.4908, Precision: 0.4055, Recall: 0.3911, F1: 0.3897
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0    rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0    ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
Model: ab, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 30], 'algorithm': ['SAMME', 'SAMME.R'], 'learning_rate': [0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04]}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
 Best Score : 0.5652216748768473
Tunning - Saved Hyperparameters [./models/config]
Model: ab, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.03, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.03, n_estimators=20, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.4552, Recall: 0.4080, Precision: 0.4042, F1 Score: 0.3997
Confusion Matrix: 
 [[0.32727273 0.2        0.47272727]
 [0.26       0.32666667 0.41333333]
 [0.20373832 0.22616822 0.57009346]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.33      0.37       330
         1.0       0.21      0.33      0.25       150
         2.0       0.58      0.57      0.58       535

    accuracy                           0.46      1015
   macro avg       0.40      0.41      0.40      1015
weighted avg       0.48      0.46      0.46      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5034, Recall: 0.3879, Precision: 0.3881, F1 Score: 0.3870
Confusion Matrix: 
 [[0.39811912 0.15360502 0.44827586]
 [0.22857143 0.1        0.67142857]
 [0.24280576 0.09172662 0.66546763]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.40      0.41       319
         1.0       0.12      0.10      0.11       140
         2.0       0.61      0.67      0.64       556

    accuracy                           0.50      1015
   macro avg       0.39      0.39      0.39      1015
weighted avg       0.49      0.50      0.49      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.4433, Recall: 0.3839, Precision: 0.3955, F1 Score: 0.3751
Confusion Matrix: 
 [[0.28034682 0.25722543 0.46242775]
 [0.20740741 0.28148148 0.51111111]
 [0.15917603 0.25093633 0.58988764]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.28      0.35       346
         1.0       0.15      0.28      0.19       135
         2.0       0.58      0.59      0.58       534

    accuracy                           0.44      1015
   macro avg       0.40      0.38      0.38      1015
weighted avg       0.48      0.44      0.45      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.4532, Recall: 0.3873, Precision: 0.4039, F1 Score: 0.3867
Confusion Matrix: 
 [[0.34636872 0.18156425 0.47206704]
 [0.23239437 0.22535211 0.54225352]
 [0.16116505 0.24854369 0.59029126]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.35      0.41       358
         1.0       0.14      0.23      0.17       142
         2.0       0.55      0.59      0.57       515

    accuracy                           0.45      1015
   macro avg       0.40      0.39      0.39      1015
weighted avg       0.48      0.45      0.46      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.4709, Recall: 0.4034, Precision: 0.4116, F1 Score: 0.4057
Confusion Matrix: 
 [[0.45070423 0.2        0.34929577]
 [0.2987013  0.18831169 0.51298701]
 [0.21541502 0.21343874 0.57114625]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.45      0.48       355
         1.0       0.14      0.19      0.16       154
         2.0       0.59      0.57      0.58       506

    accuracy                           0.47      1015
   macro avg       0.41      0.40      0.41      1015
weighted avg       0.49      0.47      0.48      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.4552, Recall: 0.4094, Precision: 0.4204, F1 Score: 0.4075
Confusion Matrix: 
 [[0.475      0.225      0.3       ]
 [0.31724138 0.25517241 0.42758621]
 [0.21764706 0.28431373 0.49803922]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.47      0.50       360
         1.0       0.14      0.26      0.18       145
         2.0       0.60      0.50      0.54       510

    accuracy                           0.46      1015
   macro avg       0.42      0.41      0.41      1015
weighted avg       0.51      0.46      0.48      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.4611, Recall: 0.3878, Precision: 0.4198, F1 Score: 0.3827
Confusion Matrix: 
 [[0.26506024 0.24096386 0.4939759 ]
 [0.11111111 0.26388889 0.625     ]
 [0.11131725 0.2541744  0.63450835]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.27      0.35       332
         1.0       0.15      0.26      0.19       144
         2.0       0.57      0.63      0.60       539

    accuracy                           0.46      1015
   macro avg       0.42      0.39      0.38      1015
weighted avg       0.50      0.46      0.46      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.4562, Recall: 0.4025, Precision: 0.4025, F1 Score: 0.3995
Confusion Matrix: 
 [[0.39197531 0.1882716  0.41975309]
 [0.28571429 0.26623377 0.44805195]
 [0.22905028 0.22160149 0.54934823]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.39      0.41       324
         1.0       0.19      0.27      0.22       154
         2.0       0.59      0.55      0.57       537

    accuracy                           0.46      1015
   macro avg       0.40      0.40      0.40      1015
weighted avg       0.48      0.46      0.47      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.4493, Recall: 0.3996, Precision: 0.4475, F1 Score: 0.3880
Confusion Matrix: 
 [[0.31564246 0.27932961 0.40502793]
 [0.1559633  0.32110092 0.52293578]
 [0.08941606 0.34854015 0.5620438 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.32      0.42       358
         1.0       0.11      0.32      0.16       109
         2.0       0.60      0.56      0.58       548

    accuracy                           0.45      1015
   macro avg       0.45      0.40      0.39      1015
weighted avg       0.56      0.45      0.48      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5034, Recall: 0.4030, Precision: 0.4073, F1 Score: 0.4021
Confusion Matrix: 
 [[0.37908497 0.18300654 0.4379085 ]
 [0.275      0.2        0.525     ]
 [0.19864177 0.17147708 0.62988115]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.38      0.41       306
         1.0       0.13      0.20      0.16       120
         2.0       0.65      0.63      0.64       589

    accuracy                           0.50      1015
   macro avg       0.41      0.40      0.40      1015
weighted avg       0.53      0.50      0.51      1015

Average metrics:
 Accuracy: 0.4651, Precision: 0.4101, Recall: 0.3973, F1: 0.3934
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0    rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0    ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0    ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
Model: ab, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 20, 30], 'algorithm': ['SAMME', 'SAMME.R'], 'learning_rate': [0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04]}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
 Best Score : 0.5636453201970444
Tunning - Saved Hyperparameters [./models/config]
Model: ab, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3872, Recall: 0.3964, Precision: 0.4096, F1 Score: 0.3713
Confusion Matrix: 
 [[0.37272727 0.37272727 0.25454545]
 [0.26666667 0.43333333 0.3       ]
 [0.19813084 0.41869159 0.38317757]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.37      0.41       330
         1.0       0.16      0.43      0.23       150
         2.0       0.61      0.38      0.47       535

    accuracy                           0.39      1015
   macro avg       0.41      0.40      0.37      1015
weighted avg       0.50      0.39      0.42      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3892, Recall: 0.3922, Precision: 0.3996, F1 Score: 0.3667
Confusion Matrix: 
 [[0.37931034 0.34482759 0.27586207]
 [0.26428571 0.40714286 0.32857143]
 [0.21942446 0.39028777 0.39028777]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.38      0.40       319
         1.0       0.15      0.41      0.22       140
         2.0       0.62      0.39      0.48       556

    accuracy                           0.39      1015
   macro avg       0.40      0.39      0.37      1015
weighted avg       0.49      0.39      0.42      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3803, Recall: 0.3642, Precision: 0.3892, F1 Score: 0.3521
Confusion Matrix: 
 [[0.3583815  0.38728324 0.25433526]
 [0.3037037  0.32592593 0.37037037]
 [0.22097378 0.37078652 0.4082397 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.44      0.36      0.39       346
         1.0       0.12      0.33      0.17       135
         2.0       0.61      0.41      0.49       534

    accuracy                           0.38      1015
   macro avg       0.39      0.36      0.35      1015
weighted avg       0.49      0.38      0.42      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3734, Recall: 0.3666, Precision: 0.3826, F1 Score: 0.3514
Confusion Matrix: 
 [[0.3575419  0.33240223 0.31005587]
 [0.28873239 0.35211268 0.35915493]
 [0.21165049 0.39805825 0.39029126]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.36      0.40       358
         1.0       0.13      0.35      0.19       142
         2.0       0.55      0.39      0.46       515

    accuracy                           0.37      1015
   macro avg       0.38      0.37      0.35      1015
weighted avg       0.46      0.37      0.40      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4020, Recall: 0.3904, Precision: 0.4010, F1 Score: 0.3783
Confusion Matrix: 
 [[0.4056338  0.31549296 0.27887324]
 [0.28571429 0.35064935 0.36363636]
 [0.23320158 0.35177866 0.41501976]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.41      0.44       355
         1.0       0.16      0.35      0.22       154
         2.0       0.58      0.42      0.48       506

    accuracy                           0.40      1015
   macro avg       0.40      0.39      0.38      1015
weighted avg       0.48      0.40      0.43      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4010, Recall: 0.4028, Precision: 0.4212, F1 Score: 0.3842
Confusion Matrix: 
 [[0.43888889 0.31666667 0.24444444]
 [0.26206897 0.39310345 0.34482759]
 [0.19411765 0.42941176 0.37647059]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.44      0.48       360
         1.0       0.15      0.39      0.21       145
         2.0       0.58      0.38      0.46       510

    accuracy                           0.40      1015
   macro avg       0.42      0.40      0.38      1015
weighted avg       0.50      0.40      0.43      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4010, Recall: 0.3861, Precision: 0.3923, F1 Score: 0.3685
Confusion Matrix: 
 [[0.33433735 0.34638554 0.31927711]
 [0.27777778 0.375      0.34722222]
 [0.21706865 0.33395176 0.44897959]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.41      0.33      0.37       332
         1.0       0.15      0.38      0.22       144
         2.0       0.61      0.45      0.52       539

    accuracy                           0.40      1015
   macro avg       0.39      0.39      0.37      1015
weighted avg       0.48      0.40      0.43      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4099, Recall: 0.4010, Precision: 0.4019, F1 Score: 0.3826
Confusion Matrix: 
 [[0.37962963 0.31790123 0.30246914]
 [0.31818182 0.38961039 0.29220779]
 [0.24022346 0.32588454 0.43389199]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.41      0.38      0.39       324
         1.0       0.18      0.39      0.24       154
         2.0       0.62      0.43      0.51       537

    accuracy                           0.41      1015
   macro avg       0.40      0.40      0.38      1015
weighted avg       0.49      0.41      0.43      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3833, Recall: 0.3834, Precision: 0.4053, F1 Score: 0.3562
Confusion Matrix: 
 [[0.37988827 0.37430168 0.24581006]
 [0.25688073 0.3853211  0.35779817]
 [0.21167883 0.40328467 0.3850365 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.38      0.43       358
         1.0       0.11      0.39      0.17       109
         2.0       0.62      0.39      0.48       548

    accuracy                           0.38      1015
   macro avg       0.41      0.38      0.36      1015
weighted avg       0.52      0.38      0.43      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4355, Recall: 0.4311, Precision: 0.4244, F1 Score: 0.3968
Confusion Matrix: 
 [[0.41176471 0.31045752 0.27777778]
 [0.29166667 0.43333333 0.275     ]
 [0.22580645 0.32597623 0.44821732]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.41      0.42       306
         1.0       0.15      0.43      0.23       120
         2.0       0.69      0.45      0.54       589

    accuracy                           0.44      1015
   macro avg       0.42      0.43      0.40      1015
weighted avg       0.55      0.44      0.47      1015

Average metrics:
 Accuracy: 0.3963, Precision: 0.4027, Recall: 0.3914, F1: 0.3708
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0    rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0    ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0    ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0    ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
Model: gb, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Error
Model: gb, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.4074, Precision: 0.4324, F1 Score: 0.3848
Confusion Matrix: 
 [[0.39090909 0.00909091 0.6       ]
 [0.24666667 0.02       0.73333333]
 [0.17383178 0.01495327 0.81121495]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.39      0.44       330
         1.0       0.21      0.02      0.04       150
         2.0       0.58      0.81      0.68       535

    accuracy                           0.56      1015
   macro avg       0.43      0.41      0.38      1015
weighted avg       0.50      0.56      0.51      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5842, Recall: 0.4188, Precision: 0.4745, F1 Score: 0.4022
Confusion Matrix: 
 [[0.39498433 0.01253918 0.59247649]
 [0.17142857 0.02857143 0.8       ]
 [0.15647482 0.01079137 0.83273381]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.39      0.45       319
         1.0       0.29      0.03      0.05       140
         2.0       0.61      0.83      0.70       556

    accuracy                           0.58      1015
   macro avg       0.47      0.42      0.40      1015
weighted avg       0.54      0.58      0.53      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5645, Recall: 0.4063, Precision: 0.3951, F1 Score: 0.3831
Confusion Matrix: 
 [[0.39884393 0.01445087 0.5867052 ]
 [0.23703704 0.00740741 0.75555556]
 [0.17228464 0.01498127 0.81273408]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.40      0.45       346
         1.0       0.07      0.01      0.01       135
         2.0       0.59      0.81      0.68       534

    accuracy                           0.56      1015
   macro avg       0.40      0.41      0.38      1015
weighted avg       0.50      0.56      0.52      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5458, Recall: 0.4020, Precision: 0.4524, F1 Score: 0.3814
Confusion Matrix: 
 [[0.34357542 0.01117318 0.6452514 ]
 [0.23943662 0.03521127 0.72535211]
 [0.15533981 0.01747573 0.82718447]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.34      0.41       358
         1.0       0.28      0.04      0.06       142
         2.0       0.56      0.83      0.67       515

    accuracy                           0.55      1015
   macro avg       0.45      0.40      0.38      1015
weighted avg       0.51      0.55      0.49      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5320, Recall: 0.3929, Precision: 0.4022, F1 Score: 0.3639
Confusion Matrix: 
 [[0.34366197 0.01971831 0.63661972]
 [0.17532468 0.01298701 0.81168831]
 [0.16798419 0.00988142 0.82213439]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.34      0.41       355
         1.0       0.14      0.01      0.02       154
         2.0       0.54      0.82      0.65       506

    accuracy                           0.53      1015
   macro avg       0.40      0.39      0.36      1015
weighted avg       0.47      0.53      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5931, Recall: 0.4395, Precision: 0.4670, F1 Score: 0.4140
Confusion Matrix: 
 [[0.43611111 0.00277778 0.56111111]
 [0.22068966 0.0137931  0.76551724]
 [0.11568627 0.01568627 0.86862745]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.44      0.52       360
         1.0       0.18      0.01      0.03       145
         2.0       0.59      0.87      0.70       510

    accuracy                           0.59      1015
   macro avg       0.47      0.44      0.41      1015
weighted avg       0.54      0.59      0.54      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5488, Recall: 0.3935, Precision: 0.4074, F1 Score: 0.3724
Confusion Matrix: 
 [[0.34337349 0.02108434 0.63554217]
 [0.18055556 0.02083333 0.79861111]
 [0.16512059 0.01855288 0.81632653]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.34      0.41       332
         1.0       0.15      0.02      0.04       144
         2.0       0.57      0.82      0.67       539

    accuracy                           0.55      1015
   macro avg       0.41      0.39      0.37      1015
weighted avg       0.49      0.55      0.50      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5685, Recall: 0.4091, Precision: 0.4222, F1 Score: 0.3797
Confusion Matrix: 
 [[0.37345679 0.00925926 0.61728395]
 [0.23376623 0.00649351 0.75974026]
 [0.14897579 0.00372439 0.84729981]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.37      0.43       324
         1.0       0.17      0.01      0.01       154
         2.0       0.59      0.85      0.70       537

    accuracy                           0.57      1015
   macro avg       0.42      0.41      0.38      1015
weighted avg       0.50      0.57      0.51      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6118, Recall: 0.4318, Precision: 0.4468, F1 Score: 0.4141
Confusion Matrix: 
 [[0.44692737 0.0027933  0.55027933]
 [0.26605505 0.00917431 0.72477064]
 [0.14963504 0.01094891 0.83941606]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.45      0.51       358
         1.0       0.12      0.01      0.02       109
         2.0       0.62      0.84      0.72       548

    accuracy                           0.61      1015
   macro avg       0.45      0.43      0.41      1015
weighted avg       0.56      0.61      0.57      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6000, Recall: 0.4136, Precision: 0.4440, F1 Score: 0.4004
Confusion Matrix: 
 [[0.38888889 0.01960784 0.59150327]
 [0.24166667 0.025      0.73333333]
 [0.16298812 0.01018676 0.82682513]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.39      0.43       306
         1.0       0.20      0.03      0.04       120
         2.0       0.64      0.83      0.72       589

    accuracy                           0.60      1015
   macro avg       0.44      0.41      0.40      1015
weighted avg       0.54      0.60      0.56      1015

Average metrics:
 Accuracy: 0.5706, Precision: 0.4344, Recall: 0.4115, F1: 0.3896
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0    rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0    ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0    ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0    ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0    gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
Model: gb, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Error
Model: gb, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5665, Recall: 0.4122, Precision: 0.4470, F1 Score: 0.3894
Confusion Matrix: 
 [[0.38484848 0.01212121 0.6030303 ]
 [0.20666667 0.02       0.77333333]
 [0.15700935 0.01121495 0.8317757 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.38      0.44       330
         1.0       0.23      0.02      0.04       150
         2.0       0.59      0.83      0.69       535

    accuracy                           0.57      1015
   macro avg       0.45      0.41      0.39      1015
weighted avg       0.51      0.57      0.51      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5882, Recall: 0.4247, Precision: 0.4808, F1 Score: 0.4105
Confusion Matrix: 
 [[0.40752351 0.01880878 0.57366771]
 [0.17142857 0.03571429 0.79285714]
 [0.15827338 0.01079137 0.83093525]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.41      0.46       319
         1.0       0.29      0.04      0.06       140
         2.0       0.61      0.83      0.70       556

    accuracy                           0.59      1015
   macro avg       0.48      0.42      0.41      1015
weighted avg       0.54      0.59      0.54      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5458, Recall: 0.3936, Precision: 0.3867, F1 Score: 0.3735
Confusion Matrix: 
 [[0.37572254 0.02023121 0.60404624]
 [0.25925926 0.01481481 0.72592593]
 [0.1835206  0.02621723 0.79026217]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.38      0.43       346
         1.0       0.09      0.01      0.03       135
         2.0       0.58      0.79      0.67       534

    accuracy                           0.55      1015
   macro avg       0.39      0.39      0.37      1015
weighted avg       0.48      0.55      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3960, Precision: 0.4305, F1 Score: 0.3711
Confusion Matrix: 
 [[0.34357542 0.00837989 0.64804469]
 [0.27464789 0.02112676 0.70422535]
 [0.1631068  0.01359223 0.82330097]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.34      0.41       358
         1.0       0.23      0.02      0.04       142
         2.0       0.56      0.82      0.67       515

    accuracy                           0.54      1015
   macro avg       0.43      0.40      0.37      1015
weighted avg       0.49      0.54      0.49      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.4006, Precision: 0.4019, F1 Score: 0.3751
Confusion Matrix: 
 [[0.36619718 0.03380282 0.6       ]
 [0.23376623 0.01948052 0.74675325]
 [0.16798419 0.01581028 0.81620553]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.52      0.37      0.43       355
         1.0       0.13      0.02      0.03       154
         2.0       0.56      0.82      0.66       506

    accuracy                           0.54      1015
   macro avg       0.40      0.40      0.38      1015
weighted avg       0.48      0.54      0.49      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5783, Recall: 0.4311, Precision: 0.4975, F1 Score: 0.4071
Confusion Matrix: 
 [[0.43333333 0.00833333 0.55833333]
 [0.24137931 0.02068966 0.73793103]
 [0.15490196 0.00588235 0.83921569]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.43      0.50       360
         1.0       0.33      0.02      0.04       145
         2.0       0.58      0.84      0.69       510

    accuracy                           0.58      1015
   macro avg       0.50      0.43      0.41      1015
weighted avg       0.54      0.58      0.53      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5606, Recall: 0.4078, Precision: 0.5125, F1 Score: 0.3901
Confusion Matrix: 
 [[0.37048193 0.0060241  0.62349398]
 [0.19444444 0.03472222 0.77083333]
 [0.17439703 0.00742115 0.81818182]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.37      0.43       332
         1.0       0.45      0.03      0.06       144
         2.0       0.58      0.82      0.68       539

    accuracy                           0.56      1015
   macro avg       0.51      0.41      0.39      1015
weighted avg       0.54      0.56      0.51      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.4048, Precision: 0.4360, F1 Score: 0.3831
Confusion Matrix: 
 [[0.35802469 0.01234568 0.62962963]
 [0.21428571 0.02597403 0.75974026]
 [0.15083799 0.01862197 0.83054004]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.36      0.42       324
         1.0       0.22      0.03      0.05       154
         2.0       0.58      0.83      0.68       537

    accuracy                           0.56      1015
   macro avg       0.44      0.40      0.38      1015
weighted avg       0.50      0.56      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.6039, Recall: 0.4239, Precision: 0.4043, F1 Score: 0.4060
Confusion Matrix: 
 [[0.44134078 0.02793296 0.53072626]
 [0.26605505 0.         0.73394495]
 [0.15145985 0.01824818 0.83029197]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.59      0.44      0.50       358
         1.0       0.00      0.00      0.00       109
         2.0       0.63      0.83      0.71       548

    accuracy                           0.60      1015
   macro avg       0.40      0.42      0.41      1015
weighted avg       0.55      0.60      0.56      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5980, Recall: 0.4075, Precision: 0.4377, F1 Score: 0.3879
Confusion Matrix: 
 [[0.38562092 0.00653595 0.60784314]
 [0.28333333 0.00833333 0.70833333]
 [0.16808149 0.00339559 0.82852292]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.39      0.42       306
         1.0       0.20      0.01      0.02       120
         2.0       0.64      0.83      0.72       589

    accuracy                           0.60      1015
   macro avg       0.44      0.41      0.39      1015
weighted avg       0.54      0.60      0.55      1015

Average metrics:
 Accuracy: 0.5679, Precision: 0.4435, Recall: 0.4102, F1: 0.3894
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0    rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0    ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0    ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0    ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0    gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0    gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
Model: gb, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Error
Model: gb, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4404, Recall: 0.4156, Precision: 0.4180, F1 Score: 0.4028
Confusion Matrix: 
 [[0.38484848 0.26060606 0.35454545]
 [0.27333333 0.36666667 0.36      ]
 [0.19439252 0.31028037 0.4953271 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.38      0.42       330
         1.0       0.18      0.37      0.24       150
         2.0       0.61      0.50      0.55       535

    accuracy                           0.44      1015
   macro avg       0.42      0.42      0.40      1015
weighted avg       0.50      0.44      0.46      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4118, Recall: 0.3896, Precision: 0.4012, F1 Score: 0.3773
Confusion Matrix: 
 [[0.40125392 0.29153605 0.30721003]
 [0.23571429 0.32857143 0.43571429]
 [0.21043165 0.35071942 0.43884892]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.40      0.43       319
         1.0       0.14      0.33      0.19       140
         2.0       0.61      0.44      0.51       556

    accuracy                           0.41      1015
   macro avg       0.40      0.39      0.38      1015
weighted avg       0.50      0.41      0.44      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4099, Recall: 0.3908, Precision: 0.4051, F1 Score: 0.3764
Confusion Matrix: 
 [[0.37861272 0.33815029 0.28323699]
 [0.28888889 0.34814815 0.36296296]
 [0.21348315 0.34082397 0.44569288]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.38      0.42       346
         1.0       0.14      0.35      0.20       135
         2.0       0.62      0.45      0.52       534

    accuracy                           0.41      1015
   macro avg       0.41      0.39      0.38      1015
weighted avg       0.50      0.41      0.44      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4099, Recall: 0.4002, Precision: 0.4131, F1 Score: 0.3837
Confusion Matrix: 
 [[0.38547486 0.32960894 0.2849162 ]
 [0.26056338 0.38028169 0.35915493]
 [0.20194175 0.3631068  0.43495146]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.39      0.43       358
         1.0       0.15      0.38      0.22       142
         2.0       0.59      0.43      0.50       515

    accuracy                           0.41      1015
   macro avg       0.41      0.40      0.38      1015
weighted avg       0.50      0.41      0.44      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4246, Recall: 0.4042, Precision: 0.4108, F1 Score: 0.3939
Confusion Matrix: 
 [[0.3915493  0.28450704 0.32394366]
 [0.22727273 0.35064935 0.42207792]
 [0.21541502 0.31422925 0.47035573]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.39      0.44       355
         1.0       0.17      0.35      0.23       154
         2.0       0.57      0.47      0.52       506

    accuracy                           0.42      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.48      0.42      0.44      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4187, Recall: 0.3971, Precision: 0.4135, F1 Score: 0.3878
Confusion Matrix: 
 [[0.41111111 0.30277778 0.28611111]
 [0.33793103 0.33103448 0.33103448]
 [0.2        0.35098039 0.44901961]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.41      0.45       360
         1.0       0.14      0.33      0.20       145
         2.0       0.60      0.45      0.51       510

    accuracy                           0.42      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.50      0.42      0.45      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4246, Recall: 0.4038, Precision: 0.4144, F1 Score: 0.3908
Confusion Matrix: 
 [[0.40963855 0.30722892 0.28313253]
 [0.3125     0.34722222 0.34027778]
 [0.21150278 0.33395176 0.45454545]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.41      0.43       332
         1.0       0.15      0.35      0.21       144
         2.0       0.63      0.45      0.53       539

    accuracy                           0.42      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.51      0.42      0.45      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4276, Recall: 0.4118, Precision: 0.4102, F1 Score: 0.3952
Confusion Matrix: 
 [[0.37654321 0.2962963  0.32716049]
 [0.31168831 0.38961039 0.2987013 ]
 [0.22532588 0.30540037 0.46927374]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.38      0.40       324
         1.0       0.19      0.39      0.25       154
         2.0       0.62      0.47      0.54       537

    accuracy                           0.43      1015
   macro avg       0.41      0.41      0.40      1015
weighted avg       0.49      0.43      0.45      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4286, Recall: 0.3870, Precision: 0.4146, F1 Score: 0.3790
Confusion Matrix: 
 [[0.40223464 0.31005587 0.2877095 ]
 [0.28440367 0.28440367 0.43119266]
 [0.19160584 0.33394161 0.47445255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.40      0.45       358
         1.0       0.10      0.28      0.14       109
         2.0       0.63      0.47      0.54       548

    accuracy                           0.43      1015
   macro avg       0.41      0.39      0.38      1015
weighted avg       0.53      0.43      0.47      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4433, Recall: 0.4160, Precision: 0.4177, F1 Score: 0.3933
Confusion Matrix: 
 [[0.38562092 0.29738562 0.31699346]
 [0.31666667 0.375      0.30833333]
 [0.20033956 0.31239389 0.48726655]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.39      0.41       306
         1.0       0.14      0.38      0.20       120
         2.0       0.68      0.49      0.57       589

    accuracy                           0.44      1015
   macro avg       0.42      0.42      0.39      1015
weighted avg       0.54      0.44      0.48      1015

Average metrics:
 Accuracy: 0.4239, Precision: 0.4118, Recall: 0.4016, F1: 0.3880
  model    pca standard tune  accuracy  precision    recall        f1
0    dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0    dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0    dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0   knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0   knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0   knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0    rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0    rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0    rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0    ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0    ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0    ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0    gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0    gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0    gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
Model: kmeans, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Error
Model: kmeans, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.2650, Recall: 0.2964, Precision: 0.2509, F1 Score: 0.2177
Confusion Matrix: 
 [[0.64545455 0.20909091 0.14545455]
 [0.74666667 0.19333333 0.06      ]
 [0.71962617 0.22990654 0.05046729]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.30      0.65      0.41       330
         1.0       0.13      0.19      0.16       150
         2.0       0.32      0.05      0.09       535

    accuracy                           0.27      1015
   macro avg       0.25      0.30      0.22      1015
weighted avg       0.29      0.27      0.20      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.2660, Recall: 0.3124, Precision: 0.2556, F1 Score: 0.2276
Confusion Matrix: 
 [[0.64576803 0.17554859 0.17868339]
 [0.70714286 0.23571429 0.05714286]
 [0.70323741 0.24100719 0.0557554 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.30      0.65      0.41       319
         1.0       0.15      0.24      0.18       140
         2.0       0.32      0.06      0.10       556

    accuracy                           0.27      1015
   macro avg       0.26      0.31      0.23      1015
weighted avg       0.29      0.27      0.20      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.2897, Recall: 0.3316, Precision: 0.2806, F1 Score: 0.2511
Confusion Matrix: 
 [[0.63294798 0.21098266 0.15606936]
 [0.62222222 0.2962963  0.08148148]
 [0.70224719 0.23220974 0.06554307]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.32      0.63      0.43       346
         1.0       0.17      0.30      0.22       135
         2.0       0.35      0.07      0.11       534

    accuracy                           0.29      1015
   macro avg       0.28      0.33      0.25      1015
weighted avg       0.32      0.29      0.23      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.1980, Recall: 0.3225, Precision: 0.2517, F1 Score: 0.1936
Confusion Matrix: 
 [[0.20391061 0.6424581  0.15363128]
 [0.19014085 0.71126761 0.09859155]
 [0.2368932  0.71067961 0.05242718]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.33      0.20      0.25       358
         1.0       0.14      0.71      0.24       142
         2.0       0.28      0.05      0.09       515

    accuracy                           0.20      1015
   macro avg       0.25      0.32      0.19      1015
weighted avg       0.28      0.20      0.17      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.3438, Recall: 0.3031, Precision: 0.3083, F1 Score: 0.2742
Confusion Matrix: 
 [[0.6        0.15211268 0.24788732]
 [0.7012987  0.05844156 0.24025974]
 [0.70750988 0.04150198 0.25098814]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.31      0.60      0.41       355
         1.0       0.11      0.06      0.08       154
         2.0       0.50      0.25      0.34       506

    accuracy                           0.34      1015
   macro avg       0.31      0.30      0.27      1015
weighted avg       0.38      0.34      0.32      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.2660, Recall: 0.2879, Precision: 0.2090, F1 Score: 0.2154
Confusion Matrix: 
 [[0.61666667 0.19722222 0.18611111]
 [0.66896552 0.2137931  0.11724138]
 [0.7        0.26666667 0.03333333]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.33      0.62      0.43       360
         1.0       0.13      0.21      0.16       145
         2.0       0.17      0.03      0.06       510

    accuracy                           0.27      1015
   macro avg       0.21      0.29      0.22      1015
weighted avg       0.22      0.27      0.20      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.2828, Recall: 0.3265, Precision: 0.2705, F1 Score: 0.2342
Confusion Matrix: 
 [[0.68674699 0.21084337 0.10240964]
 [0.67361111 0.25       0.07638889]
 [0.716141   0.24118738 0.04267161]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.32      0.69      0.44       332
         1.0       0.15      0.25      0.19       144
         2.0       0.34      0.04      0.08       539

    accuracy                           0.28      1015
   macro avg       0.27      0.33      0.23      1015
weighted avg       0.31      0.28      0.21      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.2818, Recall: 0.3634, Precision: 0.4330, F1 Score: 0.2748
Confusion Matrix: 
 [[0.14506173 0.60802469 0.24691358]
 [0.07142857 0.7012987  0.22727273]
 [0.03538175 0.72067039 0.24394786]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.15      0.23       324
         1.0       0.16      0.70      0.26       154
         2.0       0.53      0.24      0.33       537

    accuracy                           0.28      1015
   macro avg       0.43      0.36      0.27      1015
weighted avg       0.50      0.28      0.29      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.2522, Recall: 0.2774, Precision: 0.2151, F1 Score: 0.2022
Confusion Matrix: 
 [[0.58659218 0.22625698 0.18715084]
 [0.72477064 0.20183486 0.0733945 ]
 [0.69343066 0.26277372 0.04379562]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.31      0.59      0.41       358
         1.0       0.09      0.20      0.12       109
         2.0       0.24      0.04      0.07       548

    accuracy                           0.25      1015
   macro avg       0.22      0.28      0.20      1015
weighted avg       0.25      0.25      0.20      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.2404, Recall: 0.3034, Precision: 0.2371, F1 Score: 0.2067
Confusion Matrix: 
 [[0.61764706 0.2254902  0.15686275]
 [0.69166667 0.25       0.05833333]
 [0.73684211 0.22071307 0.04244482]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.27      0.62      0.37       306
         1.0       0.13      0.25      0.17       120
         2.0       0.31      0.04      0.07       589

    accuracy                           0.24      1015
   macro avg       0.24      0.30      0.21      1015
weighted avg       0.28      0.24      0.18      1015

Average metrics:
 Accuracy: 0.2686, Precision: 0.2712, Recall: 0.3125, F1: 0.2298
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
Model: kmeans, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Error
Model: kmeans, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.2650, Recall: 0.3395, Precision: 0.2523, F1 Score: 0.2396
Confusion Matrix: 
 [[0.56969697 0.28787879 0.14242424]
 [0.53333333 0.41333333 0.05333333]
 [0.52897196 0.43551402 0.03551402]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.34      0.57      0.43       330
         1.0       0.16      0.41      0.23       150
         2.0       0.26      0.04      0.06       535

    accuracy                           0.27      1015
   macro avg       0.25      0.34      0.24      1015
weighted avg       0.27      0.27      0.21      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.2414, Recall: 0.3103, Precision: 0.2531, F1 Score: 0.2234
Confusion Matrix: 
 [[0.51097179 0.31661442 0.17241379]
 [0.57142857 0.36428571 0.06428571]
 [0.56654676 0.37769784 0.0557554 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.29      0.51      0.37       319
         1.0       0.14      0.36      0.20       140
         2.0       0.33      0.06      0.10       556

    accuracy                           0.24      1015
   macro avg       0.25      0.31      0.22      1015
weighted avg       0.29      0.24      0.20      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.4049, Recall: 0.3520, Precision: 0.4117, F1 Score: 0.3277
Confusion Matrix: 
 [[0.15317919 0.27745665 0.56936416]
 [0.08148148 0.31111111 0.60740741]
 [0.05243446 0.35580524 0.5917603 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.15      0.24       346
         1.0       0.13      0.31      0.18       135
         2.0       0.53      0.59      0.56       534

    accuracy                           0.40      1015
   macro avg       0.41      0.35      0.33      1015
weighted avg       0.49      0.40      0.40      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.4197, Recall: 0.3577, Precision: 0.3635, F1 Score: 0.3439
Confusion Matrix: 
 [[0.58938547 0.15642458 0.25418994]
 [0.54929577 0.0915493  0.35915493]
 [0.55728155 0.05048544 0.39223301]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.37      0.59      0.45       358
         1.0       0.14      0.09      0.11       142
         2.0       0.59      0.39      0.47       515

    accuracy                           0.42      1015
   macro avg       0.36      0.36      0.34      1015
weighted avg       0.45      0.42      0.41      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.4236, Recall: 0.3591, Precision: 0.3611, F1 Score: 0.3406
Confusion Matrix: 
 [[0.61126761 0.13802817 0.25070423]
 [0.5974026  0.06493506 0.33766234]
 [0.55928854 0.03952569 0.40118577]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.37      0.61      0.46       355
         1.0       0.13      0.06      0.09       154
         2.0       0.59      0.40      0.48       506

    accuracy                           0.42      1015
   macro avg       0.36      0.36      0.34      1015
weighted avg       0.44      0.42      0.41      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.2709, Recall: 0.3258, Precision: 0.2256, F1 Score: 0.2385
Confusion Matrix: 
 [[0.56666667 0.24444444 0.18888889]
 [0.52413793 0.37931034 0.09655172]
 [0.61960784 0.34901961 0.03137255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.34      0.57      0.43       360
         1.0       0.17      0.38      0.24       145
         2.0       0.16      0.03      0.05       510

    accuracy                           0.27      1015
   macro avg       0.23      0.33      0.24      1015
weighted avg       0.23      0.27      0.21      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.4246, Recall: 0.3200, Precision: 0.3242, F1 Score: 0.3145
Confusion Matrix: 
 [[0.29819277 0.09939759 0.60240964]
 [0.38888889 0.0625     0.54861111]
 [0.3729128  0.02782931 0.59925788]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.30      0.29       332
         1.0       0.16      0.06      0.09       144
         2.0       0.54      0.60      0.57       539

    accuracy                           0.42      1015
   macro avg       0.32      0.32      0.31      1015
weighted avg       0.40      0.42      0.41      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.3409, Recall: 0.3725, Precision: 0.4568, F1 Score: 0.3156
Confusion Matrix: 
 [[0.14197531 0.59567901 0.26234568]
 [0.07792208 0.58441558 0.33766234]
 [0.03165736 0.57728119 0.39106145]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.14      0.23       324
         1.0       0.15      0.58      0.24       154
         2.0       0.61      0.39      0.48       537

    accuracy                           0.34      1015
   macro avg       0.46      0.37      0.32      1015
weighted avg       0.54      0.34      0.36      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.4138, Recall: 0.3067, Precision: 0.3051, F1 Score: 0.3056
Confusion Matrix: 
 [[0.27374302 0.17877095 0.54748603]
 [0.34862385 0.0733945  0.57798165]
 [0.39416058 0.03284672 0.5729927 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.27      0.28       358
         1.0       0.09      0.07      0.08       109
         2.0       0.55      0.57      0.56       548

    accuracy                           0.41      1015
   macro avg       0.31      0.31      0.31      1015
weighted avg       0.40      0.41      0.41      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.1803, Recall: 0.2954, Precision: 0.2244, F1 Score: 0.1791
Confusion Matrix: 
 [[0.31372549 0.53594771 0.1503268 ]
 [0.41666667 0.53333333 0.05      ]
 [0.39898132 0.56196944 0.03904924]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.25      0.31      0.28       306
         1.0       0.11      0.53      0.19       120
         2.0       0.31      0.04      0.07       589

    accuracy                           0.18      1015
   macro avg       0.22      0.30      0.18      1015
weighted avg       0.27      0.18      0.15      1015

Average metrics:
 Accuracy: 0.3385, Precision: 0.3178, Recall: 0.3339, F1: 0.2828
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
Model: kmeans, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Error
Model: kmeans, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
KMeans(n_clusters=3, random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3803, Recall: 0.2901, Precision: 0.2884, F1 Score: 0.2855
Confusion Matrix: 
 [[0.28787879 0.14242424 0.56969697]
 [0.41333333 0.05333333 0.53333333]
 [0.43551402 0.03551402 0.52897196]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.24      0.29      0.26       330
         1.0       0.11      0.05      0.07       150
         2.0       0.51      0.53      0.52       535

    accuracy                           0.38      1015
   macro avg       0.29      0.29      0.29      1015
weighted avg       0.37      0.38      0.37      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4158, Recall: 0.3683, Precision: 0.4285, F1 Score: 0.3454
Confusion Matrix: 
 [[0.17241379 0.31661442 0.51097179]
 [0.06428571 0.36428571 0.57142857]
 [0.0557554  0.37589928 0.56834532]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.17      0.27       319
         1.0       0.14      0.36      0.20       140
         2.0       0.57      0.57      0.57       556

    accuracy                           0.42      1015
   macro avg       0.43      0.37      0.35      1015
weighted avg       0.51      0.42      0.42      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.2611, Recall: 0.3079, Precision: 0.2516, F1 Score: 0.2271
Confusion Matrix: 
 [[0.56936416 0.27745665 0.15317919]
 [0.62222222 0.3037037  0.07407407]
 [0.59363296 0.35580524 0.0505618 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.33      0.57      0.42       346
         1.0       0.13      0.30      0.18       135
         2.0       0.30      0.05      0.09       534

    accuracy                           0.26      1015
   macro avg       0.25      0.31      0.23      1015
weighted avg       0.29      0.26      0.21      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4187, Recall: 0.3571, Precision: 0.3628, F1 Score: 0.3432
Confusion Matrix: 
 [[0.58938547 0.15642458 0.25418994]
 [0.54929577 0.0915493  0.35915493]
 [0.5592233  0.05048544 0.39029126]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.37      0.59      0.45       358
         1.0       0.14      0.09      0.11       142
         2.0       0.59      0.39      0.47       515

    accuracy                           0.42      1015
   macro avg       0.36      0.36      0.34      1015
weighted avg       0.45      0.42      0.41      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.2837, Recall: 0.3285, Precision: 0.2565, F1 Score: 0.2445
Confusion Matrix: 
 [[0.6084507  0.25352113 0.13802817]
 [0.5974026  0.33766234 0.06493506]
 [0.55928854 0.40118577 0.03952569]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.37      0.61      0.46       355
         1.0       0.15      0.34      0.21       154
         2.0       0.25      0.04      0.07       506

    accuracy                           0.28      1015
   macro avg       0.26      0.33      0.24      1015
weighted avg       0.28      0.28      0.23      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.2709, Recall: 0.3258, Precision: 0.2256, F1 Score: 0.2385
Confusion Matrix: 
 [[0.56666667 0.24444444 0.18888889]
 [0.52413793 0.37931034 0.09655172]
 [0.61960784 0.34901961 0.03137255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.34      0.57      0.43       360
         1.0       0.17      0.38      0.24       145
         2.0       0.16      0.03      0.05       510

    accuracy                           0.27      1015
   macro avg       0.23      0.33      0.24      1015
weighted avg       0.23      0.27      0.21      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4236, Recall: 0.3194, Precision: 0.3237, F1 Score: 0.3139
Confusion Matrix: 
 [[0.29819277 0.09939759 0.60240964]
 [0.38888889 0.0625     0.54861111]
 [0.37476809 0.02782931 0.5974026 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.30      0.29       332
         1.0       0.16      0.06      0.09       144
         2.0       0.54      0.60      0.56       539

    accuracy                           0.42      1015
   macro avg       0.32      0.32      0.31      1015
weighted avg       0.40      0.42      0.41      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.2581, Recall: 0.3217, Precision: 0.2340, F1 Score: 0.2280
Confusion Matrix: 
 [[0.59567901 0.26234568 0.14197531]
 [0.58441558 0.33766234 0.07792208]
 [0.57728119 0.39106145 0.03165736]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.33      0.60      0.42       324
         1.0       0.15      0.34      0.21       154
         2.0       0.23      0.03      0.06       537

    accuracy                           0.26      1015
   macro avg       0.23      0.32      0.23      1015
weighted avg       0.25      0.26      0.20      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4138, Recall: 0.3067, Precision: 0.3051, F1 Score: 0.3056
Confusion Matrix: 
 [[0.27374302 0.17877095 0.54748603]
 [0.34862385 0.0733945  0.57798165]
 [0.39416058 0.03284672 0.5729927 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.28      0.27      0.28       358
         1.0       0.09      0.07      0.08       109
         2.0       0.55      0.57      0.56       548

    accuracy                           0.41      1015
   macro avg       0.31      0.31      0.31      1015
weighted avg       0.40      0.41      0.41      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4197, Recall: 0.3735, Precision: 0.4445, F1 Score: 0.3379
Confusion Matrix: 
 [[0.1503268  0.31372549 0.53594771]
 [0.05       0.40833333 0.54166667]
 [0.03904924 0.39898132 0.56196944]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.15      0.24       306
         1.0       0.13      0.41      0.20       120
         2.0       0.59      0.56      0.58       589

    accuracy                           0.42      1015
   macro avg       0.44      0.37      0.34      1015
weighted avg       0.54      0.42      0.43      1015

Average metrics:
 Accuracy: 0.3546, Precision: 0.3121, Recall: 0.3299, F1: 0.2870
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
0  kmeans   True     True  NaN  0.354581   0.312068  0.329898  0.286957
Model: bag, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Error
Model: bag, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5576, Recall: 0.3701, Precision: 0.4071, F1 Score: 0.3098
Confusion Matrix: 
 [[0.13636364 0.         0.86363636]
 [0.05333333 0.         0.94666667]
 [0.02616822 0.         0.97383178]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.67      0.14      0.23       330
         1.0       0.00      0.00      0.00       150
         2.0       0.55      0.97      0.70       535

    accuracy                           0.56      1015
   macro avg       0.41      0.37      0.31      1015
weighted avg       0.51      0.56      0.44      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5764, Recall: 0.3752, Precision: 0.3968, F1 Score: 0.3283
Confusion Matrix: 
 [[0.17241379 0.         0.82758621]
 [0.05714286 0.         0.94285714]
 [0.04676259 0.         0.95323741]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.17      0.27       319
         1.0       0.00      0.00      0.00       140
         2.0       0.57      0.95      0.72       556

    accuracy                           0.58      1015
   macro avg       0.40      0.38      0.33      1015
weighted avg       0.51      0.58      0.48      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5251, Recall: 0.3717, Precision: 0.3304, F1 Score: 0.3425
Confusion Matrix: 
 [[0.33236994 0.         0.66763006]
 [0.25185185 0.         0.74814815]
 [0.21722846 0.         0.78277154]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.33      0.38       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.78      0.65       534

    accuracy                           0.53      1015
   macro avg       0.33      0.37      0.34      1015
weighted avg       0.44      0.53      0.47      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.4877, Recall: 0.3819, Precision: 0.4425, F1 Score: 0.3563
Confusion Matrix: 
 [[0.15363128 0.22346369 0.62290503]
 [0.08450704 0.19014085 0.72535211]
 [0.0407767  0.15728155 0.80194175]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.15      0.25       358
         1.0       0.14      0.19      0.16       142
         2.0       0.56      0.80      0.66       515

    accuracy                           0.49      1015
   macro avg       0.44      0.38      0.36      1015
weighted avg       0.52      0.49      0.44      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.4936, Recall: 0.3962, Precision: 0.4662, F1 Score: 0.3642
Confusion Matrix: 
 [[0.13521127 0.22535211 0.63943662]
 [0.05194805 0.22727273 0.72077922]
 [0.03359684 0.14031621 0.82608696]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.14      0.22       355
         1.0       0.19      0.23      0.21       154
         2.0       0.55      0.83      0.66       506

    accuracy                           0.49      1015
   macro avg       0.47      0.40      0.36      1015
weighted avg       0.53      0.49      0.44      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5557, Recall: 0.3861, Precision: 0.4222, F1 Score: 0.3272
Confusion Matrix: 
 [[0.17777778 0.         0.82222222]
 [0.09655172 0.         0.90344828]
 [0.01960784 0.         0.98039216]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.73      0.18      0.29       360
         1.0       0.00      0.00      0.00       145
         2.0       0.54      0.98      0.70       510

    accuracy                           0.56      1015
   macro avg       0.42      0.39      0.33      1015
weighted avg       0.53      0.56      0.45      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5084, Recall: 0.3658, Precision: 0.4367, F1 Score: 0.3309
Confusion Matrix: 
 [[0.09939759 0.15361446 0.74698795]
 [0.05555556 0.13888889 0.80555556]
 [0.02597403 0.11502783 0.85899814]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.60      0.10      0.17       332
         1.0       0.15      0.14      0.14       144
         2.0       0.56      0.86      0.68       539

    accuracy                           0.51      1015
   macro avg       0.44      0.37      0.33      1015
weighted avg       0.51      0.51      0.44      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5300, Recall: 0.3662, Precision: 0.4317, F1 Score: 0.3322
Confusion Matrix: 
 [[0.13888889 0.11728395 0.74382716]
 [0.07792208 0.05844156 0.86363636]
 [0.02793296 0.0707635  0.90130354]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.14      0.23       324
         1.0       0.11      0.06      0.08       154
         2.0       0.56      0.90      0.69       537

    accuracy                           0.53      1015
   macro avg       0.43      0.37      0.33      1015
weighted avg       0.51      0.53      0.45      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5872, Recall: 0.3819, Precision: 0.4471, F1 Score: 0.3324
Confusion Matrix: 
 [[0.16759777 0.         0.83240223]
 [0.05504587 0.         0.94495413]
 [0.02189781 0.         0.97810219]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.77      0.17      0.28       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.98      0.72       548

    accuracy                           0.59      1015
   macro avg       0.45      0.38      0.33      1015
weighted avg       0.58      0.59      0.49      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6020, Recall: 0.3824, Precision: 0.3844, F1 Score: 0.3518
Confusion Matrix: 
 [[0.22875817 0.         0.77124183]
 [0.09166667 0.         0.90833333]
 [0.08149406 0.         0.91850594]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.23      0.32       306
         1.0       0.00      0.00      0.00       120
         2.0       0.61      0.92      0.73       589

    accuracy                           0.60      1015
   macro avg       0.38      0.38      0.35      1015
weighted avg       0.52      0.60      0.52      1015

Average metrics:
 Accuracy: 0.5424, Precision: 0.4165, Recall: 0.3777, F1: 0.3376
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
0  kmeans   True     True  NaN  0.354581   0.312068  0.329898  0.286957
0     bag  False    False  NaN  0.542365   0.416511  0.377744  0.337558
Model: bag, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Error
Model: bag, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5567, Recall: 0.3702, Precision: 0.4007, F1 Score: 0.3116
Confusion Matrix: 
 [[0.14242424 0.         0.85757576]
 [0.05333333 0.         0.94666667]
 [0.0317757  0.         0.9682243 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.14      0.23       330
         1.0       0.00      0.00      0.00       150
         2.0       0.55      0.97      0.70       535

    accuracy                           0.56      1015
   macro avg       0.40      0.37      0.31      1015
weighted avg       0.50      0.56      0.45      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5783, Recall: 0.3755, Precision: 0.4062, F1 Score: 0.3272
Confusion Matrix: 
 [[0.1661442  0.         0.8338558 ]
 [0.05       0.         0.95      ]
 [0.03956835 0.         0.96043165]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.65      0.17      0.26       319
         1.0       0.00      0.00      0.00       140
         2.0       0.57      0.96      0.72       556

    accuracy                           0.58      1015
   macro avg       0.41      0.38      0.33      1015
weighted avg       0.52      0.58      0.48      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5369, Recall: 0.3707, Precision: 0.3382, F1 Score: 0.3349
Confusion Matrix: 
 [[0.26011561 0.         0.73988439]
 [0.2        0.         0.8       ]
 [0.14794007 0.         0.85205993]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.26      0.33       346
         1.0       0.00      0.00      0.00       135
         2.0       0.56      0.85      0.67       534

    accuracy                           0.54      1015
   macro avg       0.34      0.37      0.33      1015
weighted avg       0.45      0.54      0.47      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5389, Recall: 0.3680, Precision: 0.3891, F1 Score: 0.3036
Confusion Matrix: 
 [[0.13687151 0.         0.86312849]
 [0.07746479 0.         0.92253521]
 [0.03300971 0.         0.96699029]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.14      0.23       358
         1.0       0.00      0.00      0.00       142
         2.0       0.53      0.97      0.69       515

    accuracy                           0.54      1015
   macro avg       0.39      0.37      0.30      1015
weighted avg       0.49      0.54      0.43      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5281, Recall: 0.3668, Precision: 0.3852, F1 Score: 0.3005
Confusion Matrix: 
 [[0.13802817 0.         0.86197183]
 [0.05844156 0.         0.94155844]
 [0.03754941 0.         0.96245059]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.14      0.23       355
         1.0       0.00      0.00      0.00       154
         2.0       0.52      0.96      0.67       506

    accuracy                           0.53      1015
   macro avg       0.39      0.37      0.30      1015
weighted avg       0.48      0.53      0.42      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5685, Recall: 0.4093, Precision: 0.3859, F1 Score: 0.3716
Confusion Matrix: 
 [[0.32777778 0.         0.67222222]
 [0.2        0.         0.8       ]
 [0.1        0.         0.9       ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.60      0.33      0.42       360
         1.0       0.00      0.00      0.00       145
         2.0       0.56      0.90      0.69       510

    accuracy                           0.57      1015
   macro avg       0.39      0.41      0.37      1015
weighted avg       0.49      0.57      0.50      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5084, Recall: 0.3658, Precision: 0.4401, F1 Score: 0.3309
Confusion Matrix: 
 [[0.09939759 0.15361446 0.74698795]
 [0.05555556 0.13888889 0.80555556]
 [0.02411874 0.11688312 0.85899814]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.61      0.10      0.17       332
         1.0       0.15      0.14      0.14       144
         2.0       0.56      0.86      0.68       539

    accuracy                           0.51      1015
   macro avg       0.44      0.37      0.33      1015
weighted avg       0.52      0.51      0.44      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5586, Recall: 0.3703, Precision: 0.3929, F1 Score: 0.3109
Confusion Matrix: 
 [[0.13888889 0.         0.86111111]
 [0.07792208 0.         0.92207792]
 [0.02793296 0.         0.97206704]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.14      0.23       324
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.97      0.71       537

    accuracy                           0.56      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.49      0.56      0.45      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5862, Recall: 0.3816, Precision: 0.4416, F1 Score: 0.3329
Confusion Matrix: 
 [[0.17039106 0.         0.82960894]
 [0.05504587 0.         0.94495413]
 [0.02554745 0.         0.97445255]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.75      0.17      0.28       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.97      0.72       548

    accuracy                           0.59      1015
   macro avg       0.44      0.38      0.33      1015
weighted avg       0.57      0.59      0.49      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.6049, Recall: 0.3721, Precision: 0.4152, F1 Score: 0.3296
Confusion Matrix: 
 [[0.15359477 0.         0.84640523]
 [0.03333333 0.         0.96666667]
 [0.03735144 0.         0.96264856]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.15      0.25       306
         1.0       0.00      0.00      0.00       120
         2.0       0.60      0.96      0.74       589

    accuracy                           0.60      1015
   macro avg       0.42      0.37      0.33      1015
weighted avg       0.54      0.60      0.50      1015

Average metrics:
 Accuracy: 0.5566, Precision: 0.3995, Recall: 0.3750, F1: 0.3254
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
0  kmeans   True     True  NaN  0.354581   0.312068  0.329898  0.286957
0     bag  False    False  NaN  0.542365   0.416511  0.377744  0.337558
0     bag  False     True  NaN  0.556552   0.399515  0.375028  0.325354
Model: bag, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Error
Model: bag, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Not Found Hyperparameters File
BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),
                  random_state=64)
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5507, Recall: 0.3630, Precision: 0.3963, F1 Score: 0.2981
Confusion Matrix: 
 [[0.11515152 0.         0.88484848]
 [0.04666667 0.         0.95333333]
 [0.02616822 0.         0.97383178]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.12      0.20       330
         1.0       0.00      0.00      0.00       150
         2.0       0.54      0.97      0.70       535

    accuracy                           0.55      1015
   macro avg       0.40      0.36      0.30      1015
weighted avg       0.50      0.55      0.43      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5764, Recall: 0.3743, Precision: 0.4008, F1 Score: 0.3262
Confusion Matrix: 
 [[0.1661442  0.         0.8338558 ]
 [0.05       0.         0.95      ]
 [0.04316547 0.         0.95683453]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.17      0.26       319
         1.0       0.00      0.00      0.00       140
         2.0       0.57      0.96      0.72       556

    accuracy                           0.58      1015
   macro avg       0.40      0.37      0.33      1015
weighted avg       0.51      0.58      0.47      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.3687, Precision: 0.3926, F1 Score: 0.3121
Confusion Matrix: 
 [[0.14739884 0.         0.85260116]
 [0.05925926 0.         0.94074074]
 [0.0411985  0.         0.9588015 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.15      0.24       346
         1.0       0.00      0.00      0.00       135
         2.0       0.55      0.96      0.70       534

    accuracy                           0.55      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.50      0.55      0.45      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5419, Recall: 0.3710, Precision: 0.3906, F1 Score: 0.3091
Confusion Matrix: 
 [[0.14804469 0.         0.85195531]
 [0.08450704 0.         0.91549296]
 [0.03495146 0.         0.96504854]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.64      0.15      0.24       358
         1.0       0.00      0.00      0.00       142
         2.0       0.53      0.97      0.69       515

    accuracy                           0.54      1015
   macro avg       0.39      0.37      0.31      1015
weighted avg       0.50      0.54      0.43      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5291, Recall: 0.3672, Precision: 0.3922, F1 Score: 0.2999
Confusion Matrix: 
 [[0.13521127 0.         0.86478873]
 [0.05194805 0.         0.94805195]
 [0.03359684 0.         0.96640316]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.14      0.22       355
         1.0       0.00      0.00      0.00       154
         2.0       0.52      0.97      0.68       506

    accuracy                           0.53      1015
   macro avg       0.39      0.37      0.30      1015
weighted avg       0.49      0.53      0.42      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5537, Recall: 0.3839, Precision: 0.4242, F1 Score: 0.3234
Confusion Matrix: 
 [[0.16944444 0.         0.83055556]
 [0.08965517 0.         0.91034483]
 [0.01764706 0.         0.98235294]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.73      0.17      0.28       360
         1.0       0.00      0.00      0.00       145
         2.0       0.54      0.98      0.69       510

    accuracy                           0.55      1015
   macro avg       0.42      0.38      0.32      1015
weighted avg       0.53      0.55      0.45      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5498, Recall: 0.3570, Precision: 0.3927, F1 Score: 0.2877
Confusion Matrix: 
 [[0.09337349 0.         0.90662651]
 [0.04166667 0.         0.95833333]
 [0.02226345 0.         0.97773655]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.63      0.09      0.16       332
         1.0       0.00      0.00      0.00       144
         2.0       0.55      0.98      0.70       539

    accuracy                           0.55      1015
   macro avg       0.39      0.36      0.29      1015
weighted avg       0.50      0.55      0.43      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5596, Recall: 0.3705, Precision: 0.4032, F1 Score: 0.3103
Confusion Matrix: 
 [[0.13580247 0.         0.86419753]
 [0.06493506 0.         0.93506494]
 [0.02420857 0.         0.97579143]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.66      0.14      0.23       324
         1.0       0.00      0.00      0.00       154
         2.0       0.55      0.98      0.71       537

    accuracy                           0.56      1015
   macro avg       0.40      0.37      0.31      1015
weighted avg       0.50      0.56      0.45      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.5803, Recall: 0.3764, Precision: 0.4348, F1 Score: 0.3250
Confusion Matrix: 
 [[0.15642458 0.         0.84357542]
 [0.04587156 0.         0.95412844]
 [0.02737226 0.         0.97262774]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.74      0.16      0.26       358
         1.0       0.00      0.00      0.00       109
         2.0       0.57      0.97      0.72       548

    accuracy                           0.58      1015
   macro avg       0.43      0.38      0.32      1015
weighted avg       0.57      0.58      0.48      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.6089, Recall: 0.3728, Precision: 0.4338, F1 Score: 0.3278
Confusion Matrix: 
 [[0.14379085 0.         0.85620915]
 [0.03333333 0.         0.96666667]
 [0.02546689 0.         0.97453311]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.70      0.14      0.24       306
         1.0       0.00      0.00      0.00       120
         2.0       0.60      0.97      0.74       589

    accuracy                           0.61      1015
   macro avg       0.43      0.37      0.33      1015
weighted avg       0.56      0.61      0.50      1015

Average metrics:
 Accuracy: 0.5605, Precision: 0.4061, Recall: 0.3705, F1: 0.3120
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
0  kmeans   True     True  NaN  0.354581   0.312068  0.329898  0.286957
0     bag  False    False  NaN  0.542365   0.416511  0.377744  0.337558
0     bag  False     True  NaN  0.556552   0.399515  0.375028  0.325354
0     bag   True     True  NaN  0.560493   0.406122  0.370492  0.311958
Model: voting, PCA: False, Standard: False, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'voting': ['soft', 'hard']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'voting': 'hard'}
 Best Score : 0.5536945812807883
Tunning - Saved Hyperparameters [./models/config]
Model: voting, PCA: False, Standard: False, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'voting': 'hard'}
VotingClassifier(estimators=[('dt',
                              DecisionTreeClassifier(criterion='entropy',
                                                     max_depth=5,
                                                     min_samples_leaf=7,
                                                     random_state=64)),
                             ('knn', KNeighborsClassifier(n_neighbors=30)),
                             ('rf',
                              RandomForestClassifier(max_depth=8,
                                                     max_features='auto',
                                                     n_estimators=500,
                                                     random_state=64)),
                             ('ab',
                              AdaBoostClassifier(learning_rate=1.04,
                                                 n_estimators=20,
                                                 random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.3966, Precision: 0.4151, F1 Score: 0.3826
Confusion Matrix: 
 [[0.33939394 0.03636364 0.62424242]
 [0.18       0.04666667 0.77333333]
 [0.15327103 0.04299065 0.80373832]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.34      0.41       330
         1.0       0.17      0.05      0.07       150
         2.0       0.57      0.80      0.67       535

    accuracy                           0.54      1015
   macro avg       0.42      0.40      0.38      1015
weighted avg       0.49      0.54      0.50      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.4090, Precision: 0.4236, F1 Score: 0.3987
Confusion Matrix: 
 [[0.36050157 0.05956113 0.5799373 ]
 [0.17142857 0.04285714 0.78571429]
 [0.13129496 0.04496403 0.82374101]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.36      0.43       319
         1.0       0.12      0.04      0.06       140
         2.0       0.61      0.82      0.70       556

    accuracy                           0.57      1015
   macro avg       0.42      0.41      0.40      1015
weighted avg       0.52      0.57      0.53      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5251, Recall: 0.3919, Precision: 0.4041, F1 Score: 0.3863
Confusion Matrix: 
 [[0.34682081 0.07225434 0.58092486]
 [0.2        0.07407407 0.72592593]
 [0.16666667 0.07865169 0.75468165]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.51      0.35      0.41       346
         1.0       0.13      0.07      0.09       135
         2.0       0.57      0.75      0.65       534

    accuracy                           0.53      1015
   macro avg       0.40      0.39      0.39      1015
weighted avg       0.49      0.53      0.50      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5409, Recall: 0.4033, Precision: 0.4338, F1 Score: 0.3891
Confusion Matrix: 
 [[0.32122905 0.04189944 0.63687151]
 [0.20422535 0.06338028 0.73239437]
 [0.13398058 0.0407767  0.82524272]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.32      0.40       358
         1.0       0.20      0.06      0.10       142
         2.0       0.56      0.83      0.67       515

    accuracy                           0.54      1015
   macro avg       0.43      0.40      0.39      1015
weighted avg       0.50      0.54      0.49      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5222, Recall: 0.3864, Precision: 0.3807, F1 Score: 0.3635
Confusion Matrix: 
 [[0.32957746 0.06760563 0.6028169 ]
 [0.18181818 0.01948052 0.7987013 ]
 [0.15019763 0.03952569 0.81027668]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.33      0.41       355
         1.0       0.06      0.02      0.03       154
         2.0       0.55      0.81      0.65       506

    accuracy                           0.52      1015
   macro avg       0.38      0.39      0.36      1015
weighted avg       0.47      0.52      0.47      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5675, Recall: 0.4231, Precision: 0.4293, F1 Score: 0.4062
Confusion Matrix: 
 [[0.40833333 0.025      0.56666667]
 [0.26206897 0.02758621 0.71034483]
 [0.10196078 0.06470588 0.83333333]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.62      0.41      0.49       360
         1.0       0.09      0.03      0.04       145
         2.0       0.58      0.83      0.68       510

    accuracy                           0.57      1015
   macro avg       0.43      0.42      0.41      1015
weighted avg       0.52      0.57      0.52      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5379, Recall: 0.3870, Precision: 0.4016, F1 Score: 0.3700
Confusion Matrix: 
 [[0.31927711 0.03915663 0.64156627]
 [0.15972222 0.03472222 0.80555556]
 [0.16326531 0.0296846  0.80705009]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.32      0.39       332
         1.0       0.15      0.03      0.06       144
         2.0       0.57      0.81      0.67       539

    accuracy                           0.54      1015
   macro avg       0.40      0.39      0.37      1015
weighted avg       0.48      0.54      0.49      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5448, Recall: 0.3984, Precision: 0.4140, F1 Score: 0.3849
Confusion Matrix: 
 [[0.3117284  0.08333333 0.60493827]
 [0.18831169 0.05844156 0.75324675]
 [0.13407821 0.04096834 0.82495345]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.31      0.38       324
         1.0       0.16      0.06      0.08       154
         2.0       0.59      0.82      0.69       537

    accuracy                           0.54      1015
   macro avg       0.41      0.40      0.38      1015
weighted avg       0.49      0.54      0.50      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.5872, Recall: 0.4231, Precision: 0.4448, F1 Score: 0.4183
Confusion Matrix: 
 [[0.39664804 0.04748603 0.55586592]
 [0.20183486 0.05504587 0.74311927]
 [0.13321168 0.04927007 0.81751825]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.60      0.40      0.48       358
         1.0       0.12      0.06      0.08       109
         2.0       0.62      0.82      0.70       548

    accuracy                           0.59      1015
   macro avg       0.44      0.42      0.42      1015
weighted avg       0.56      0.59      0.56      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5852, Recall: 0.4030, Precision: 0.4033, F1 Score: 0.3920
Confusion Matrix: 
 [[0.37581699 0.03921569 0.58496732]
 [0.25833333 0.025      0.71666667]
 [0.15959253 0.03225806 0.80814941]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.38      0.42       306
         1.0       0.09      0.03      0.04       120
         2.0       0.64      0.81      0.72       589

    accuracy                           0.59      1015
   macro avg       0.40      0.40      0.39      1015
weighted avg       0.53      0.59      0.55      1015

Average metrics:
 Accuracy: 0.5522, Precision: 0.4150, Recall: 0.4022, F1: 0.3892
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
0  kmeans   True     True  NaN  0.354581   0.312068  0.329898  0.286957
0     bag  False    False  NaN  0.542365   0.416511  0.377744  0.337558
0     bag  False     True  NaN  0.556552   0.399515  0.375028  0.325354
0     bag   True     True  NaN  0.560493   0.406122  0.370492  0.311958
0  voting  False    False  NaN  0.552217   0.415026  0.402176  0.389160
Model: voting, PCA: False, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'voting': ['soft', 'hard']}
------------------------------------------------------------
GridSearchCV
Best Parameter
  {'voting': 'hard'}
 Best Score : 0.5557635467980295
Tunning - Saved Hyperparameters [./models/config]
Model: voting, PCA: False, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'voting': 'hard'}
VotingClassifier(estimators=[('dt',
                              DecisionTreeClassifier(criterion='entropy',
                                                     max_depth=5,
                                                     min_samples_leaf=7,
                                                     random_state=64)),
                             ('knn', KNeighborsClassifier(n_neighbors=30)),
                             ('rf',
                              RandomForestClassifier(max_depth=8,
                                                     max_features='auto',
                                                     n_estimators=500,
                                                     random_state=64)),
                             ('ab',
                              AdaBoostClassifier(learning_rate=1.04,
                                                 n_estimators=20,
                                                 random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
Evaluation on test set, 
 Accuracy: 0.4729, Recall: 0.4178, Precision: 0.4202, F1 Score: 0.4144
Confusion Matrix: 
 [[0.39090909 0.18484848 0.42424242]
 [0.24       0.28666667 0.47333333]
 [0.19813084 0.22616822 0.57570093]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.39      0.43       330
         1.0       0.19      0.29      0.23       150
         2.0       0.59      0.58      0.58       535

    accuracy                           0.47      1015
   macro avg       0.42      0.42      0.41      1015
weighted avg       0.50      0.47      0.48      1015

Fold 1
Evaluation on test set, 
 Accuracy: 0.5458, Recall: 0.4221, Precision: 0.4329, F1 Score: 0.4197
Confusion Matrix: 
 [[0.45768025 0.06583072 0.47648903]
 [0.25       0.1        0.65      ]
 [0.23561151 0.0557554  0.70863309]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.46      0.46       319
         1.0       0.21      0.10      0.14       140
         2.0       0.62      0.71      0.66       556

    accuracy                           0.55      1015
   macro avg       0.43      0.42      0.42      1015
weighted avg       0.52      0.55      0.53      1015

Fold 2
Evaluation on test set, 
 Accuracy: 0.5005, Recall: 0.3969, Precision: 0.4080, F1 Score: 0.3970
Confusion Matrix: 
 [[0.34971098 0.10982659 0.54046243]
 [0.24444444 0.15555556 0.6       ]
 [0.1741573  0.14044944 0.68539326]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.35      0.41       346
         1.0       0.16      0.16      0.16       135
         2.0       0.58      0.69      0.63       534

    accuracy                           0.50      1015
   macro avg       0.41      0.40      0.40      1015
weighted avg       0.49      0.50      0.49      1015

Fold 3
Evaluation on test set, 
 Accuracy: 0.5212, Recall: 0.4040, Precision: 0.4104, F1 Score: 0.3993
Confusion Matrix: 
 [[0.38826816 0.08659218 0.52513966]
 [0.29577465 0.0915493  0.61267606]
 [0.18640777 0.0815534  0.73203883]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.39      0.44       358
         1.0       0.15      0.09      0.11       142
         2.0       0.58      0.73      0.65       515

    accuracy                           0.52      1015
   macro avg       0.41      0.40      0.40      1015
weighted avg       0.49      0.52      0.50      1015

Fold 4
Evaluation on test set, 
 Accuracy: 0.5232, Recall: 0.4010, Precision: 0.4064, F1 Score: 0.3917
Confusion Matrix: 
 [[0.36338028 0.12394366 0.51267606]
 [0.24675325 0.06493506 0.68831169]
 [0.14426877 0.08102767 0.77470356]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.54      0.36      0.43       355
         1.0       0.11      0.06      0.08       154
         2.0       0.58      0.77      0.66       506

    accuracy                           0.52      1015
   macro avg       0.41      0.40      0.39      1015
weighted avg       0.49      0.52      0.49      1015

Fold 5
Evaluation on test set, 
 Accuracy: 0.5547, Recall: 0.4444, Precision: 0.4487, F1 Score: 0.4431
Confusion Matrix: 
 [[0.51111111 0.08055556 0.40833333]
 [0.29655172 0.11034483 0.59310345]
 [0.17843137 0.10980392 0.71176471]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.51      0.54       360
         1.0       0.16      0.11      0.13       145
         2.0       0.61      0.71      0.66       510

    accuracy                           0.55      1015
   macro avg       0.45      0.44      0.44      1015
weighted avg       0.53      0.55      0.54      1015

Fold 6
Evaluation on test set, 
 Accuracy: 0.5429, Recall: 0.4156, Precision: 0.4391, F1 Score: 0.4139
Confusion Matrix: 
 [[0.34638554 0.09036145 0.56325301]
 [0.1875     0.125      0.6875    ]
 [0.16697588 0.05751391 0.7755102 ]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.35      0.41       332
         1.0       0.23      0.12      0.16       144
         2.0       0.59      0.78      0.67       539

    accuracy                           0.54      1015
   macro avg       0.44      0.42      0.41      1015
weighted avg       0.51      0.54      0.51      1015

Fold 7
Evaluation on test set, 
 Accuracy: 0.5123, Recall: 0.3929, Precision: 0.3895, F1 Score: 0.3852
Confusion Matrix: 
 [[0.41358025 0.06790123 0.51851852]
 [0.30519481 0.06493506 0.62987013]
 [0.22160149 0.07821229 0.70018622]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.45      0.41      0.43       324
         1.0       0.14      0.06      0.09       154
         2.0       0.59      0.70      0.64       537

    accuracy                           0.51      1015
   macro avg       0.39      0.39      0.39      1015
weighted avg       0.47      0.51      0.49      1015

Fold 8
Evaluation on test set, 
 Accuracy: 0.4887, Recall: 0.4019, Precision: 0.4312, F1 Score: 0.4059
Confusion Matrix: 
 [[0.42178771 0.2150838  0.36312849]
 [0.24770642 0.19266055 0.55963303]
 [0.15328467 0.25547445 0.59124088]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.58      0.42      0.49       358
         1.0       0.09      0.19      0.12       109
         2.0       0.63      0.59      0.61       548

    accuracy                           0.49      1015
   macro avg       0.43      0.40      0.41      1015
weighted avg       0.55      0.49      0.51      1015

Fold 9
Evaluation on test set, 
 Accuracy: 0.5704, Recall: 0.4164, Precision: 0.4250, F1 Score: 0.4161
Confusion Matrix: 
 [[0.40196078 0.07189542 0.52614379]
 [0.29166667 0.09166667 0.61666667]
 [0.17826825 0.06621392 0.75551783]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.40      0.43       306
         1.0       0.15      0.09      0.11       120
         2.0       0.65      0.76      0.70       589

    accuracy                           0.57      1015
   macro avg       0.42      0.42      0.42      1015
weighted avg       0.54      0.57      0.55      1015

Average metrics:
 Accuracy: 0.5233, Precision: 0.4211, Recall: 0.4113, F1: 0.4086
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
0  kmeans   True     True  NaN  0.354581   0.312068  0.329898  0.286957
0     bag  False    False  NaN  0.542365   0.416511  0.377744  0.337558
0     bag  False     True  NaN  0.556552   0.399515  0.375028  0.325354
0     bag   True     True  NaN  0.560493   0.406122  0.370492  0.311958
0  voting  False    False  NaN  0.552217   0.415026  0.402176  0.389160
0  voting  False     True  NaN  0.523251   0.421127  0.411293  0.408625
Model: voting, PCA: True, Standard: True, SMOTE: True, Tune: grid, Param_load: False
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
DecisionTreeClassifier(random_state=64)
------------------------------------------------------------
KNeighborsClassifier()
------------------------------------------------------------
RandomForestClassifier(random_state=64)
------------------------------------------------------------
AdaBoostClassifier(random_state=64)
------------------------------------------------------------
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
VotingClassifier(estimators=[('dt', DecisionTreeClassifier(random_state=64)),
                             ('knn', KNeighborsClassifier()),
                             ('rf', RandomForestClassifier(random_state=64)),
                             ('ab', AdaBoostClassifier(random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Tunning - Loaded Hyperparameters Range
{'voting': ['soft', 'hard']}
------------------------------------------------------------
<< PCA: 11 -> 10 >>
GridSearchCV
Best Parameter
  {'voting': 'hard'}
 Best Score : 0.5544827586206897
Tunning - Saved Hyperparameters [./models/config]
Model: voting, PCA: True, Standard: True, SMOTE: True, Tune: None, Param_load: True
Dataset size: 10150
Features name : ['diravg', 'humidrel', 'ocurcause', 'ocurdo', 'rainamount', 'raindays', 'tempavg', 'windavg', 'within_30km', 'within_30km_fact', 'height']
Target name : ['scale_damage']
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 7, 'min_samples_split': 2}
DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=7,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'n_neighbors': 30}
KNeighborsClassifier(n_neighbors=30)
------------------------------------------------------------
Loaded Hyperparameters
{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 500}
RandomForestClassifier(max_depth=8, max_features='auto', n_estimators=500,
                       random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'algorithm': 'SAMME.R', 'learning_rate': 1.04, 'n_estimators': 20}
AdaBoostClassifier(learning_rate=1.04, n_estimators=20, random_state=64)
------------------------------------------------------------
Not Found Hyperparameters File
GradientBoostingClassifier(random_state=64)
------------------------------------------------------------
Loaded Hyperparameters
{'voting': 'hard'}
VotingClassifier(estimators=[('dt',
                              DecisionTreeClassifier(criterion='entropy',
                                                     max_depth=5,
                                                     min_samples_leaf=7,
                                                     random_state=64)),
                             ('knn', KNeighborsClassifier(n_neighbors=30)),
                             ('rf',
                              RandomForestClassifier(max_depth=8,
                                                     max_features='auto',
                                                     n_estimators=500,
                                                     random_state=64)),
                             ('ab',
                              AdaBoostClassifier(learning_rate=1.04,
                                                 n_estimators=20,
                                                 random_state=64)),
                             ('gb',
                              GradientBoostingClassifier(random_state=64))])
------------------------------------------------------------
Fold 0
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4099, Recall: 0.4098, Precision: 0.4189, F1 Score: 0.3887
Confusion Matrix: 
 [[0.4030303  0.32424242 0.27272727]
 [0.28       0.41333333 0.30666667]
 [0.19813084 0.38878505 0.41308411]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.40      0.44       330
         1.0       0.16      0.41      0.24       150
         2.0       0.62      0.41      0.50       535

    accuracy                           0.41      1015
   macro avg       0.42      0.41      0.39      1015
weighted avg       0.50      0.41      0.44      1015

Fold 1
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4167, Recall: 0.3939, Precision: 0.4073, F1 Score: 0.3822
Confusion Matrix: 
 [[0.42319749 0.28213166 0.29467085]
 [0.28571429 0.32142857 0.39285714]
 [0.20503597 0.35791367 0.43705036]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.47      0.42      0.44       319
         1.0       0.13      0.32      0.19       140
         2.0       0.62      0.44      0.51       556

    accuracy                           0.42      1015
   macro avg       0.41      0.39      0.38      1015
weighted avg       0.50      0.42      0.45      1015

Fold 2
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3980, Recall: 0.3832, Precision: 0.4133, F1 Score: 0.3711
Confusion Matrix: 
 [[0.39306358 0.39017341 0.21676301]
 [0.2962963  0.34074074 0.36296296]
 [0.20224719 0.38202247 0.41573034]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.48      0.39      0.43       346
         1.0       0.12      0.34      0.18       135
         2.0       0.64      0.42      0.50       534

    accuracy                           0.40      1015
   macro avg       0.41      0.38      0.37      1015
weighted avg       0.52      0.40      0.44      1015

Fold 3
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3813, Recall: 0.3936, Precision: 0.4149, F1 Score: 0.3671
Confusion Matrix: 
 [[0.3547486  0.40223464 0.24301676]
 [0.23943662 0.44366197 0.31690141]
 [0.18058252 0.4368932  0.38252427]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.35      0.42       358
         1.0       0.15      0.44      0.22       142
         2.0       0.60      0.38      0.47       515

    accuracy                           0.38      1015
   macro avg       0.41      0.39      0.37      1015
weighted avg       0.50      0.38      0.41      1015

Fold 4
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4128, Recall: 0.4086, Precision: 0.4204, F1 Score: 0.3920
Confusion Matrix: 
 [[0.3943662  0.33802817 0.26760563]
 [0.23376623 0.4025974  0.36363636]
 [0.20158103 0.36956522 0.42885375]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.50      0.39      0.44       355
         1.0       0.17      0.40      0.24       154
         2.0       0.59      0.43      0.50       506

    accuracy                           0.41      1015
   macro avg       0.42      0.41      0.39      1015
weighted avg       0.50      0.41      0.44      1015

Fold 5
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.3931, Recall: 0.4017, Precision: 0.4268, F1 Score: 0.3801
Confusion Matrix: 
 [[0.41388889 0.36666667 0.21944444]
 [0.26206897 0.42068966 0.31724138]
 [0.18039216 0.44901961 0.37058824]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.53      0.41      0.47       360
         1.0       0.14      0.42      0.22       145
         2.0       0.60      0.37      0.46       510

    accuracy                           0.39      1015
   macro avg       0.43      0.40      0.38      1015
weighted avg       0.51      0.39      0.43      1015

Fold 6
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4158, Recall: 0.4252, Precision: 0.4274, F1 Score: 0.3931
Confusion Matrix: 
 [[0.35542169 0.37650602 0.26807229]
 [0.25       0.48611111 0.26388889]
 [0.19294991 0.3729128  0.43413729]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.46      0.36      0.40       332
         1.0       0.18      0.49      0.26       144
         2.0       0.65      0.43      0.52       539

    accuracy                           0.42      1015
   macro avg       0.43      0.43      0.39      1015
weighted avg       0.52      0.42      0.44      1015

Fold 7
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4099, Recall: 0.4074, Precision: 0.4065, F1 Score: 0.3863
Confusion Matrix: 
 [[0.40432099 0.2962963  0.29938272]
 [0.32467532 0.4025974  0.27272727]
 [0.24022346 0.34450652 0.41527002]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.42      0.40      0.41       324
         1.0       0.18      0.40      0.25       154
         2.0       0.62      0.42      0.50       537

    accuracy                           0.41      1015
   macro avg       0.41      0.41      0.39      1015
weighted avg       0.49      0.41      0.43      1015

Fold 8
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4000, Recall: 0.3898, Precision: 0.4133, F1 Score: 0.3671
Confusion Matrix: 
 [[0.38826816 0.36592179 0.24581006]
 [0.30275229 0.36697248 0.33027523]
 [0.20620438 0.37956204 0.41423358]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.49      0.39      0.43       358
         1.0       0.11      0.37      0.16       109
         2.0       0.65      0.41      0.51       548

    accuracy                           0.40      1015
   macro avg       0.41      0.39      0.37      1015
weighted avg       0.53      0.40      0.44      1015

Fold 9
<< PCA: 11 -> 10 >>
Evaluation on test set, 
 Accuracy: 0.4256, Recall: 0.4084, Precision: 0.4140, F1 Score: 0.3838
Confusion Matrix: 
 [[0.40196078 0.31699346 0.28104575]
 [0.29166667 0.375      0.33333333]
 [0.2139219  0.33786078 0.44821732]]
Classification Report: 
               precision    recall  f1-score   support

         0.0       0.43      0.40      0.42       306
         1.0       0.13      0.38      0.20       120
         2.0       0.68      0.45      0.54       589

    accuracy                           0.43      1015
   macro avg       0.41      0.41      0.38      1015
weighted avg       0.54      0.43      0.46      1015

Average metrics:
 Accuracy: 0.4063, Precision: 0.4163, Recall: 0.4022, F1: 0.3812
    model    pca standard tune  accuracy  precision    recall        f1
0      dt  False    False  NaN  0.552611   0.392309  0.370768  0.321500
0      dt  False     True  NaN  0.479901   0.431174  0.374575  0.335412
0      dt   True     True  NaN  0.352808   0.411480  0.382178  0.339906
0     knn  False    False  NaN  0.348966   0.383389  0.370171  0.336771
0     knn  False     True  NaN  0.358325   0.388372  0.371002  0.342967
0     knn   True     True  NaN  0.363941   0.390519  0.375737  0.347714
0      rf  False    False  NaN  0.538916   0.429154  0.401435  0.395398
0      rf  False     True  NaN  0.513695   0.429347  0.411061  0.411630
0      rf   True     True  NaN  0.440493   0.423775  0.409519  0.398129
0      ab  False    False  NaN  0.490837   0.405498  0.391111  0.389728
0      ab  False     True  NaN  0.465123   0.410079  0.397283  0.393383
0      ab   True     True  NaN  0.396256   0.402702  0.391442  0.370812
0      gb  False    False  NaN  0.570640   0.434398  0.411490  0.389603
0      gb  False     True  NaN  0.567882   0.443504  0.410225  0.389374
0      gb   True     True  NaN  0.423941   0.411845  0.401607  0.388013
0  kmeans  False    False  NaN  0.268571   0.271170  0.312472  0.229753
0  kmeans  False     True  NaN  0.338522   0.317774  0.333905  0.282845
0  kmeans   True     True  NaN  0.354581   0.312068  0.329898  0.286957
0     bag  False    False  NaN  0.542365   0.416511  0.377744  0.337558
0     bag  False     True  NaN  0.556552   0.399515  0.375028  0.325354
0     bag   True     True  NaN  0.560493   0.406122  0.370492  0.311958
0  voting  False    False  NaN  0.552217   0.415026  0.402176  0.389160
0  voting  False     True  NaN  0.523251   0.421127  0.411293  0.408625
0  voting   True     True  NaN  0.406305   0.416288  0.402170  0.381151
