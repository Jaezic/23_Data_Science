2023-06-03 14:31:36,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:31:36,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:31:36,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:31:36,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:31:37,112:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-03 14:32:18,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:32:18,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:32:18,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:32:18,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 14:32:18,680:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-03 14:32:18,731:INFO:PyCaret ClassificationExperiment
2023-06-03 14:32:18,731:INFO:Logging name: clf-default-name
2023-06-03 14:32:18,731:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:32:18,731:INFO:version 3.0.2
2023-06-03 14:32:18,731:INFO:Initializing setup()
2023-06-03 14:32:18,731:INFO:self.USI: 4812
2023-06-03 14:32:18,731:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:32:18,731:INFO:Checking environment
2023-06-03 14:32:18,731:INFO:python_version: 3.8.16
2023-06-03 14:32:18,731:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:32:18,731:INFO:machine: x86_64
2023-06-03 14:32:18,731:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:32:18,732:INFO:Memory: svmem(total=134737395712, available=92066848768, percent=31.7, used=41370759168, free=2182553600, active=29659832320, inactive=93309669376, buffers=2426806272, cached=88757276672, shared=28536832, slab=4928589824)
2023-06-03 14:32:18,732:INFO:Physical Core: 10
2023-06-03 14:32:18,732:INFO:Logical Core: 20
2023-06-03 14:32:18,732:INFO:Checking libraries
2023-06-03 14:32:18,732:INFO:System:
2023-06-03 14:32:18,732:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:32:18,732:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:32:18,732:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:32:18,733:INFO:PyCaret required dependencies:
2023-06-03 14:32:18,733:INFO:                 pip: 23.0.1
2023-06-03 14:32:18,733:INFO:          setuptools: 67.8.0
2023-06-03 14:32:18,733:INFO:             pycaret: 3.0.2
2023-06-03 14:32:18,733:INFO:             IPython: 8.12.2
2023-06-03 14:32:18,733:INFO:          ipywidgets: 8.0.6
2023-06-03 14:32:18,733:INFO:                tqdm: 4.65.0
2023-06-03 14:32:18,733:INFO:               numpy: 1.23.5
2023-06-03 14:32:18,733:INFO:              pandas: 1.5.3
2023-06-03 14:32:18,733:INFO:              jinja2: 3.1.2
2023-06-03 14:32:18,733:INFO:               scipy: 1.10.1
2023-06-03 14:32:18,733:INFO:              joblib: 1.2.0
2023-06-03 14:32:18,733:INFO:             sklearn: 1.2.2
2023-06-03 14:32:18,733:INFO:                pyod: 1.0.9
2023-06-03 14:32:18,733:INFO:            imblearn: 0.10.1
2023-06-03 14:32:18,733:INFO:   category_encoders: 2.6.1
2023-06-03 14:32:18,733:INFO:            lightgbm: 3.3.5
2023-06-03 14:32:18,733:INFO:               numba: 0.57.0
2023-06-03 14:32:18,733:INFO:            requests: 2.31.0
2023-06-03 14:32:18,733:INFO:          matplotlib: 3.7.1
2023-06-03 14:32:18,733:INFO:          scikitplot: 0.3.7
2023-06-03 14:32:18,733:INFO:         yellowbrick: 1.5
2023-06-03 14:32:18,733:INFO:              plotly: 5.14.1
2023-06-03 14:32:18,733:INFO:             kaleido: 0.2.1
2023-06-03 14:32:18,733:INFO:         statsmodels: 0.14.0
2023-06-03 14:32:18,733:INFO:              sktime: 0.17.0
2023-06-03 14:32:18,733:INFO:               tbats: 1.1.3
2023-06-03 14:32:18,733:INFO:            pmdarima: 2.0.3
2023-06-03 14:32:18,733:INFO:              psutil: 5.9.5
2023-06-03 14:32:18,733:INFO:PyCaret optional dependencies:
2023-06-03 14:32:18,755:INFO:                shap: Not installed
2023-06-03 14:32:18,755:INFO:           interpret: Not installed
2023-06-03 14:32:18,755:INFO:                umap: Not installed
2023-06-03 14:32:18,755:INFO:    pandas_profiling: Not installed
2023-06-03 14:32:18,755:INFO:  explainerdashboard: Not installed
2023-06-03 14:32:18,755:INFO:             autoviz: Not installed
2023-06-03 14:32:18,755:INFO:           fairlearn: Not installed
2023-06-03 14:32:18,756:INFO:             xgboost: Not installed
2023-06-03 14:32:18,756:INFO:            catboost: Not installed
2023-06-03 14:32:18,756:INFO:              kmodes: Not installed
2023-06-03 14:32:18,756:INFO:             mlxtend: Not installed
2023-06-03 14:32:18,756:INFO:       statsforecast: Not installed
2023-06-03 14:32:18,756:INFO:        tune_sklearn: Not installed
2023-06-03 14:32:18,756:INFO:                 ray: Not installed
2023-06-03 14:32:18,756:INFO:            hyperopt: Not installed
2023-06-03 14:32:18,756:INFO:              optuna: Not installed
2023-06-03 14:32:18,756:INFO:               skopt: Not installed
2023-06-03 14:32:18,756:INFO:              mlflow: Not installed
2023-06-03 14:32:18,756:INFO:              gradio: Not installed
2023-06-03 14:32:18,756:INFO:             fastapi: Not installed
2023-06-03 14:32:18,756:INFO:             uvicorn: Not installed
2023-06-03 14:32:18,756:INFO:              m2cgen: Not installed
2023-06-03 14:32:18,756:INFO:           evidently: Not installed
2023-06-03 14:32:18,756:INFO:               fugue: Not installed
2023-06-03 14:32:18,756:INFO:           streamlit: Not installed
2023-06-03 14:32:18,756:INFO:             prophet: Not installed
2023-06-03 14:32:18,756:INFO:None
2023-06-03 14:32:18,756:INFO:Set up data.
2023-06-03 14:32:26,560:INFO:PyCaret ClassificationExperiment
2023-06-03 14:32:26,560:INFO:Logging name: clf-default-name
2023-06-03 14:32:26,560:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:32:26,560:INFO:version 3.0.2
2023-06-03 14:32:26,560:INFO:Initializing setup()
2023-06-03 14:32:26,560:INFO:self.USI: a8f5
2023-06-03 14:32:26,560:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:32:26,560:INFO:Checking environment
2023-06-03 14:32:26,560:INFO:python_version: 3.8.16
2023-06-03 14:32:26,560:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:32:26,560:INFO:machine: x86_64
2023-06-03 14:32:26,560:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:32:26,561:INFO:Memory: svmem(total=134737395712, available=92034301952, percent=31.7, used=41403301888, free=2150211584, active=29660516352, inactive=93323247616, buffers=2426810368, cached=88757071872, shared=28536832, slab=4928528384)
2023-06-03 14:32:26,562:INFO:Physical Core: 10
2023-06-03 14:32:26,562:INFO:Logical Core: 20
2023-06-03 14:32:26,562:INFO:Checking libraries
2023-06-03 14:32:26,562:INFO:System:
2023-06-03 14:32:26,562:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:32:26,562:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:32:26,562:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:32:26,562:INFO:PyCaret required dependencies:
2023-06-03 14:32:26,562:INFO:                 pip: 23.0.1
2023-06-03 14:32:26,562:INFO:          setuptools: 67.8.0
2023-06-03 14:32:26,562:INFO:             pycaret: 3.0.2
2023-06-03 14:32:26,562:INFO:             IPython: 8.12.2
2023-06-03 14:32:26,562:INFO:          ipywidgets: 8.0.6
2023-06-03 14:32:26,562:INFO:                tqdm: 4.65.0
2023-06-03 14:32:26,562:INFO:               numpy: 1.23.5
2023-06-03 14:32:26,562:INFO:              pandas: 1.5.3
2023-06-03 14:32:26,562:INFO:              jinja2: 3.1.2
2023-06-03 14:32:26,562:INFO:               scipy: 1.10.1
2023-06-03 14:32:26,562:INFO:              joblib: 1.2.0
2023-06-03 14:32:26,562:INFO:             sklearn: 1.2.2
2023-06-03 14:32:26,562:INFO:                pyod: 1.0.9
2023-06-03 14:32:26,562:INFO:            imblearn: 0.10.1
2023-06-03 14:32:26,562:INFO:   category_encoders: 2.6.1
2023-06-03 14:32:26,562:INFO:            lightgbm: 3.3.5
2023-06-03 14:32:26,563:INFO:               numba: 0.57.0
2023-06-03 14:32:26,563:INFO:            requests: 2.31.0
2023-06-03 14:32:26,563:INFO:          matplotlib: 3.7.1
2023-06-03 14:32:26,563:INFO:          scikitplot: 0.3.7
2023-06-03 14:32:26,563:INFO:         yellowbrick: 1.5
2023-06-03 14:32:26,563:INFO:              plotly: 5.14.1
2023-06-03 14:32:26,563:INFO:             kaleido: 0.2.1
2023-06-03 14:32:26,563:INFO:         statsmodels: 0.14.0
2023-06-03 14:32:26,563:INFO:              sktime: 0.17.0
2023-06-03 14:32:26,563:INFO:               tbats: 1.1.3
2023-06-03 14:32:26,563:INFO:            pmdarima: 2.0.3
2023-06-03 14:32:26,563:INFO:              psutil: 5.9.5
2023-06-03 14:32:26,563:INFO:PyCaret optional dependencies:
2023-06-03 14:32:26,563:INFO:                shap: Not installed
2023-06-03 14:32:26,563:INFO:           interpret: Not installed
2023-06-03 14:32:26,563:INFO:                umap: Not installed
2023-06-03 14:32:26,563:INFO:    pandas_profiling: Not installed
2023-06-03 14:32:26,563:INFO:  explainerdashboard: Not installed
2023-06-03 14:32:26,563:INFO:             autoviz: Not installed
2023-06-03 14:32:26,563:INFO:           fairlearn: Not installed
2023-06-03 14:32:26,563:INFO:             xgboost: Not installed
2023-06-03 14:32:26,563:INFO:            catboost: Not installed
2023-06-03 14:32:26,563:INFO:              kmodes: Not installed
2023-06-03 14:32:26,563:INFO:             mlxtend: Not installed
2023-06-03 14:32:26,563:INFO:       statsforecast: Not installed
2023-06-03 14:32:26,563:INFO:        tune_sklearn: Not installed
2023-06-03 14:32:26,563:INFO:                 ray: Not installed
2023-06-03 14:32:26,563:INFO:            hyperopt: Not installed
2023-06-03 14:32:26,563:INFO:              optuna: Not installed
2023-06-03 14:32:26,563:INFO:               skopt: Not installed
2023-06-03 14:32:26,563:INFO:              mlflow: Not installed
2023-06-03 14:32:26,563:INFO:              gradio: Not installed
2023-06-03 14:32:26,563:INFO:             fastapi: Not installed
2023-06-03 14:32:26,563:INFO:             uvicorn: Not installed
2023-06-03 14:32:26,564:INFO:              m2cgen: Not installed
2023-06-03 14:32:26,564:INFO:           evidently: Not installed
2023-06-03 14:32:26,564:INFO:               fugue: Not installed
2023-06-03 14:32:26,564:INFO:           streamlit: Not installed
2023-06-03 14:32:26,564:INFO:             prophet: Not installed
2023-06-03 14:32:26,564:INFO:None
2023-06-03 14:32:26,564:INFO:Set up data.
2023-06-03 14:32:26,573:INFO:Set up train/test split.
2023-06-03 14:32:26,580:INFO:Set up index.
2023-06-03 14:32:26,580:INFO:Set up folding strategy.
2023-06-03 14:32:26,580:INFO:Assigning column types.
2023-06-03 14:32:26,584:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:32:26,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:32:26,617:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:26,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:32:26,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:26,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,704:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:32:26,735:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:26,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:26,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,806:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:32:26,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:26,909:INFO:Preparing preprocessing pipeline...
2023-06-03 14:32:26,910:INFO:Set up simple imputation.
2023-06-03 14:32:26,923:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:32:26,926:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-03 14:32:26,926:INFO:Creating final display dataframe.
2023-06-03 14:32:26,969:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              a8f5
2023-06-03 14:32:27,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:27,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:27,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:27,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:27,081:INFO:setup() successfully completed in 0.52s...............
2023-06-03 14:32:56,289:INFO:PyCaret ClassificationExperiment
2023-06-03 14:32:56,290:INFO:Logging name: clf-default-name
2023-06-03 14:32:56,290:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:32:56,290:INFO:version 3.0.2
2023-06-03 14:32:56,290:INFO:Initializing setup()
2023-06-03 14:32:56,290:INFO:self.USI: 166d
2023-06-03 14:32:56,290:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:32:56,290:INFO:Checking environment
2023-06-03 14:32:56,290:INFO:python_version: 3.8.16
2023-06-03 14:32:56,290:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:32:56,290:INFO:machine: x86_64
2023-06-03 14:32:56,290:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:32:56,291:INFO:Memory: svmem(total=134737395712, available=92070404096, percent=31.7, used=41367203840, free=2186186752, active=29660794880, inactive=93267165184, buffers=2426834944, cached=88757170176, shared=28536832, slab=4928491520)
2023-06-03 14:32:56,292:INFO:Physical Core: 10
2023-06-03 14:32:56,292:INFO:Logical Core: 20
2023-06-03 14:32:56,293:INFO:Checking libraries
2023-06-03 14:32:56,293:INFO:System:
2023-06-03 14:32:56,293:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:32:56,293:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:32:56,293:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:32:56,293:INFO:PyCaret required dependencies:
2023-06-03 14:32:56,293:INFO:                 pip: 23.0.1
2023-06-03 14:32:56,293:INFO:          setuptools: 67.8.0
2023-06-03 14:32:56,293:INFO:             pycaret: 3.0.2
2023-06-03 14:32:56,293:INFO:             IPython: 8.12.2
2023-06-03 14:32:56,293:INFO:          ipywidgets: 8.0.6
2023-06-03 14:32:56,293:INFO:                tqdm: 4.65.0
2023-06-03 14:32:56,293:INFO:               numpy: 1.23.5
2023-06-03 14:32:56,293:INFO:              pandas: 1.5.3
2023-06-03 14:32:56,294:INFO:              jinja2: 3.1.2
2023-06-03 14:32:56,294:INFO:               scipy: 1.10.1
2023-06-03 14:32:56,294:INFO:              joblib: 1.2.0
2023-06-03 14:32:56,294:INFO:             sklearn: 1.2.2
2023-06-03 14:32:56,294:INFO:                pyod: 1.0.9
2023-06-03 14:32:56,294:INFO:            imblearn: 0.10.1
2023-06-03 14:32:56,294:INFO:   category_encoders: 2.6.1
2023-06-03 14:32:56,294:INFO:            lightgbm: 3.3.5
2023-06-03 14:32:56,294:INFO:               numba: 0.57.0
2023-06-03 14:32:56,294:INFO:            requests: 2.31.0
2023-06-03 14:32:56,294:INFO:          matplotlib: 3.7.1
2023-06-03 14:32:56,294:INFO:          scikitplot: 0.3.7
2023-06-03 14:32:56,294:INFO:         yellowbrick: 1.5
2023-06-03 14:32:56,294:INFO:              plotly: 5.14.1
2023-06-03 14:32:56,294:INFO:             kaleido: 0.2.1
2023-06-03 14:32:56,294:INFO:         statsmodels: 0.14.0
2023-06-03 14:32:56,294:INFO:              sktime: 0.17.0
2023-06-03 14:32:56,295:INFO:               tbats: 1.1.3
2023-06-03 14:32:56,295:INFO:            pmdarima: 2.0.3
2023-06-03 14:32:56,295:INFO:              psutil: 5.9.5
2023-06-03 14:32:56,295:INFO:PyCaret optional dependencies:
2023-06-03 14:32:56,295:INFO:                shap: Not installed
2023-06-03 14:32:56,295:INFO:           interpret: Not installed
2023-06-03 14:32:56,295:INFO:                umap: Not installed
2023-06-03 14:32:56,295:INFO:    pandas_profiling: Not installed
2023-06-03 14:32:56,295:INFO:  explainerdashboard: Not installed
2023-06-03 14:32:56,295:INFO:             autoviz: Not installed
2023-06-03 14:32:56,295:INFO:           fairlearn: Not installed
2023-06-03 14:32:56,295:INFO:             xgboost: Not installed
2023-06-03 14:32:56,295:INFO:            catboost: Not installed
2023-06-03 14:32:56,295:INFO:              kmodes: Not installed
2023-06-03 14:32:56,295:INFO:             mlxtend: Not installed
2023-06-03 14:32:56,296:INFO:       statsforecast: Not installed
2023-06-03 14:32:56,296:INFO:        tune_sklearn: Not installed
2023-06-03 14:32:56,296:INFO:                 ray: Not installed
2023-06-03 14:32:56,296:INFO:            hyperopt: Not installed
2023-06-03 14:32:56,296:INFO:              optuna: Not installed
2023-06-03 14:32:56,296:INFO:               skopt: Not installed
2023-06-03 14:32:56,296:INFO:              mlflow: Not installed
2023-06-03 14:32:56,296:INFO:              gradio: Not installed
2023-06-03 14:32:56,296:INFO:             fastapi: Not installed
2023-06-03 14:32:56,296:INFO:             uvicorn: Not installed
2023-06-03 14:32:56,296:INFO:              m2cgen: Not installed
2023-06-03 14:32:56,296:INFO:           evidently: Not installed
2023-06-03 14:32:56,296:INFO:               fugue: Not installed
2023-06-03 14:32:56,296:INFO:           streamlit: Not installed
2023-06-03 14:32:56,296:INFO:             prophet: Not installed
2023-06-03 14:32:56,296:INFO:None
2023-06-03 14:32:56,296:INFO:Set up data.
2023-06-03 14:32:56,309:INFO:Set up train/test split.
2023-06-03 14:32:56,318:INFO:Set up index.
2023-06-03 14:32:56,318:INFO:Set up folding strategy.
2023-06-03 14:32:56,318:INFO:Assigning column types.
2023-06-03 14:32:56,322:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:32:56,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:32:56,355:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:56,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:32:56,405:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:56,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,422:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:32:56,449:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:56,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:32:56,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,511:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:32:56,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,556:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,601:INFO:Preparing preprocessing pipeline...
2023-06-03 14:32:56,602:INFO:Set up simple imputation.
2023-06-03 14:32:56,613:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:32:56,615:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-03 14:32:56,615:INFO:Creating final display dataframe.
2023-06-03 14:32:56,658:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              166d
2023-06-03 14:32:56,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:32:56,777:INFO:setup() successfully completed in 0.49s...............
2023-06-03 14:33:03,853:INFO:Initializing compare_models()
2023-06-03 14:33:03,853:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:33:03,853:INFO:Checking exceptions
2023-06-03 14:33:03,863:INFO:Preparing display monitor
2023-06-03 14:33:03,894:INFO:Initializing Logistic Regression
2023-06-03 14:33:03,894:INFO:Total runtime is 5.471706390380859e-06 minutes
2023-06-03 14:33:03,898:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:03,898:INFO:Initializing create_model()
2023-06-03 14:33:03,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:03,898:INFO:Checking exceptions
2023-06-03 14:33:03,898:INFO:Importing libraries
2023-06-03 14:33:03,898:INFO:Copying training dataset
2023-06-03 14:33:03,903:INFO:Defining folds
2023-06-03 14:33:03,903:INFO:Declaring metric variables
2023-06-03 14:33:03,906:INFO:Importing untrained model
2023-06-03 14:33:03,909:INFO:Logistic Regression Imported successfully
2023-06-03 14:33:03,915:INFO:Starting cross validation
2023-06-03 14:33:03,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:06,013:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,027:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,080:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,091:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,120:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,131:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,182:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,188:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,222:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,240:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:33:06,284:INFO:Calculating mean and std
2023-06-03 14:33:06,286:INFO:Creating metrics dataframe
2023-06-03 14:33:06,295:INFO:Uploading results into container
2023-06-03 14:33:06,295:INFO:Uploading model into container now
2023-06-03 14:33:06,296:INFO:_master_model_container: 1
2023-06-03 14:33:06,296:INFO:_display_container: 2
2023-06-03 14:33:06,297:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:33:06,297:INFO:create_model() successfully completed......................................
2023-06-03 14:33:06,407:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:06,407:INFO:Creating metrics dataframe
2023-06-03 14:33:06,415:INFO:Initializing K Neighbors Classifier
2023-06-03 14:33:06,415:INFO:Total runtime is 0.04202899932861329 minutes
2023-06-03 14:33:06,419:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:06,419:INFO:Initializing create_model()
2023-06-03 14:33:06,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:06,419:INFO:Checking exceptions
2023-06-03 14:33:06,419:INFO:Importing libraries
2023-06-03 14:33:06,419:INFO:Copying training dataset
2023-06-03 14:33:06,424:INFO:Defining folds
2023-06-03 14:33:06,424:INFO:Declaring metric variables
2023-06-03 14:33:06,428:INFO:Importing untrained model
2023-06-03 14:33:06,431:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:33:06,436:INFO:Starting cross validation
2023-06-03 14:33:06,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:07,615:INFO:Calculating mean and std
2023-06-03 14:33:07,618:INFO:Creating metrics dataframe
2023-06-03 14:33:07,629:INFO:Uploading results into container
2023-06-03 14:33:07,630:INFO:Uploading model into container now
2023-06-03 14:33:07,630:INFO:_master_model_container: 2
2023-06-03 14:33:07,630:INFO:_display_container: 2
2023-06-03 14:33:07,631:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:33:07,631:INFO:create_model() successfully completed......................................
2023-06-03 14:33:07,722:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:07,722:INFO:Creating metrics dataframe
2023-06-03 14:33:07,730:INFO:Initializing Naive Bayes
2023-06-03 14:33:07,730:INFO:Total runtime is 0.06394535303115845 minutes
2023-06-03 14:33:07,734:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:07,734:INFO:Initializing create_model()
2023-06-03 14:33:07,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:07,734:INFO:Checking exceptions
2023-06-03 14:33:07,734:INFO:Importing libraries
2023-06-03 14:33:07,734:INFO:Copying training dataset
2023-06-03 14:33:07,739:INFO:Defining folds
2023-06-03 14:33:07,739:INFO:Declaring metric variables
2023-06-03 14:33:07,742:INFO:Importing untrained model
2023-06-03 14:33:07,745:INFO:Naive Bayes Imported successfully
2023-06-03 14:33:07,756:INFO:Starting cross validation
2023-06-03 14:33:07,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:07,891:INFO:Calculating mean and std
2023-06-03 14:33:07,892:INFO:Creating metrics dataframe
2023-06-03 14:33:07,898:INFO:Uploading results into container
2023-06-03 14:33:07,899:INFO:Uploading model into container now
2023-06-03 14:33:07,899:INFO:_master_model_container: 3
2023-06-03 14:33:07,899:INFO:_display_container: 2
2023-06-03 14:33:07,899:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:33:07,899:INFO:create_model() successfully completed......................................
2023-06-03 14:33:07,985:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:07,985:INFO:Creating metrics dataframe
2023-06-03 14:33:07,993:INFO:Initializing Decision Tree Classifier
2023-06-03 14:33:07,993:INFO:Total runtime is 0.06832726001739502 minutes
2023-06-03 14:33:07,996:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:07,996:INFO:Initializing create_model()
2023-06-03 14:33:07,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:07,997:INFO:Checking exceptions
2023-06-03 14:33:07,997:INFO:Importing libraries
2023-06-03 14:33:07,997:INFO:Copying training dataset
2023-06-03 14:33:08,001:INFO:Defining folds
2023-06-03 14:33:08,001:INFO:Declaring metric variables
2023-06-03 14:33:08,004:INFO:Importing untrained model
2023-06-03 14:33:08,007:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:33:08,011:INFO:Starting cross validation
2023-06-03 14:33:08,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:08,184:INFO:Calculating mean and std
2023-06-03 14:33:08,185:INFO:Creating metrics dataframe
2023-06-03 14:33:08,197:INFO:Uploading results into container
2023-06-03 14:33:08,198:INFO:Uploading model into container now
2023-06-03 14:33:08,199:INFO:_master_model_container: 4
2023-06-03 14:33:08,199:INFO:_display_container: 2
2023-06-03 14:33:08,200:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:33:08,200:INFO:create_model() successfully completed......................................
2023-06-03 14:33:08,288:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:08,288:INFO:Creating metrics dataframe
2023-06-03 14:33:08,297:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:33:08,297:INFO:Total runtime is 0.07338687181472778 minutes
2023-06-03 14:33:08,303:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:08,303:INFO:Initializing create_model()
2023-06-03 14:33:08,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:08,304:INFO:Checking exceptions
2023-06-03 14:33:08,304:INFO:Importing libraries
2023-06-03 14:33:08,304:INFO:Copying training dataset
2023-06-03 14:33:08,314:INFO:Defining folds
2023-06-03 14:33:08,314:INFO:Declaring metric variables
2023-06-03 14:33:08,319:INFO:Importing untrained model
2023-06-03 14:33:08,326:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:33:08,338:INFO:Starting cross validation
2023-06-03 14:33:08,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:08,617:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,621:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,630:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,635:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,647:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,651:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,651:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,656:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,664:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,667:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,668:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,670:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,674:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,675:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,680:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,705:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,709:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,727:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:33:08,730:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:08,735:INFO:Calculating mean and std
2023-06-03 14:33:08,738:INFO:Creating metrics dataframe
2023-06-03 14:33:08,753:INFO:Uploading results into container
2023-06-03 14:33:08,754:INFO:Uploading model into container now
2023-06-03 14:33:08,754:INFO:_master_model_container: 5
2023-06-03 14:33:08,754:INFO:_display_container: 2
2023-06-03 14:33:08,755:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:33:08,755:INFO:create_model() successfully completed......................................
2023-06-03 14:33:08,846:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:08,846:INFO:Creating metrics dataframe
2023-06-03 14:33:08,858:INFO:Initializing Ridge Classifier
2023-06-03 14:33:08,858:INFO:Total runtime is 0.082744296391805 minutes
2023-06-03 14:33:08,862:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:08,862:INFO:Initializing create_model()
2023-06-03 14:33:08,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:08,862:INFO:Checking exceptions
2023-06-03 14:33:08,862:INFO:Importing libraries
2023-06-03 14:33:08,862:INFO:Copying training dataset
2023-06-03 14:33:08,866:INFO:Defining folds
2023-06-03 14:33:08,867:INFO:Declaring metric variables
2023-06-03 14:33:08,870:INFO:Importing untrained model
2023-06-03 14:33:08,873:INFO:Ridge Classifier Imported successfully
2023-06-03 14:33:08,879:INFO:Starting cross validation
2023-06-03 14:33:08,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:08,942:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,943:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,957:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,964:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,966:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,968:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,970:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,972:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,976:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,983:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:33:08,992:INFO:Calculating mean and std
2023-06-03 14:33:08,994:INFO:Creating metrics dataframe
2023-06-03 14:33:09,003:INFO:Uploading results into container
2023-06-03 14:33:09,003:INFO:Uploading model into container now
2023-06-03 14:33:09,004:INFO:_master_model_container: 6
2023-06-03 14:33:09,004:INFO:_display_container: 2
2023-06-03 14:33:09,004:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:33:09,004:INFO:create_model() successfully completed......................................
2023-06-03 14:33:09,089:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:09,089:INFO:Creating metrics dataframe
2023-06-03 14:33:09,098:INFO:Initializing Random Forest Classifier
2023-06-03 14:33:09,098:INFO:Total runtime is 0.08674169381459552 minutes
2023-06-03 14:33:09,101:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:09,102:INFO:Initializing create_model()
2023-06-03 14:33:09,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:09,102:INFO:Checking exceptions
2023-06-03 14:33:09,102:INFO:Importing libraries
2023-06-03 14:33:09,102:INFO:Copying training dataset
2023-06-03 14:33:09,106:INFO:Defining folds
2023-06-03 14:33:09,106:INFO:Declaring metric variables
2023-06-03 14:33:09,109:INFO:Importing untrained model
2023-06-03 14:33:09,113:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:33:09,126:INFO:Starting cross validation
2023-06-03 14:33:09,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:10,740:INFO:Calculating mean and std
2023-06-03 14:33:10,741:INFO:Creating metrics dataframe
2023-06-03 14:33:10,756:INFO:Uploading results into container
2023-06-03 14:33:10,757:INFO:Uploading model into container now
2023-06-03 14:33:10,757:INFO:_master_model_container: 7
2023-06-03 14:33:10,757:INFO:_display_container: 2
2023-06-03 14:33:10,758:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:33:10,758:INFO:create_model() successfully completed......................................
2023-06-03 14:33:10,846:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:10,847:INFO:Creating metrics dataframe
2023-06-03 14:33:10,856:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:33:10,856:INFO:Total runtime is 0.11603649059931435 minutes
2023-06-03 14:33:10,859:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:10,860:INFO:Initializing create_model()
2023-06-03 14:33:10,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:10,860:INFO:Checking exceptions
2023-06-03 14:33:10,860:INFO:Importing libraries
2023-06-03 14:33:10,860:INFO:Copying training dataset
2023-06-03 14:33:10,864:INFO:Defining folds
2023-06-03 14:33:10,864:INFO:Declaring metric variables
2023-06-03 14:33:10,868:INFO:Importing untrained model
2023-06-03 14:33:10,871:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:33:10,877:INFO:Starting cross validation
2023-06-03 14:33:10,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:11,015:INFO:Calculating mean and std
2023-06-03 14:33:11,016:INFO:Creating metrics dataframe
2023-06-03 14:33:11,028:INFO:Uploading results into container
2023-06-03 14:33:11,029:INFO:Uploading model into container now
2023-06-03 14:33:11,029:INFO:_master_model_container: 8
2023-06-03 14:33:11,029:INFO:_display_container: 2
2023-06-03 14:33:11,029:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:33:11,029:INFO:create_model() successfully completed......................................
2023-06-03 14:33:11,127:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:11,127:INFO:Creating metrics dataframe
2023-06-03 14:33:11,136:INFO:Initializing Ada Boost Classifier
2023-06-03 14:33:11,136:INFO:Total runtime is 0.12070830663045246 minutes
2023-06-03 14:33:11,139:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:11,139:INFO:Initializing create_model()
2023-06-03 14:33:11,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:11,139:INFO:Checking exceptions
2023-06-03 14:33:11,139:INFO:Importing libraries
2023-06-03 14:33:11,139:INFO:Copying training dataset
2023-06-03 14:33:11,143:INFO:Defining folds
2023-06-03 14:33:11,144:INFO:Declaring metric variables
2023-06-03 14:33:11,146:INFO:Importing untrained model
2023-06-03 14:33:11,149:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:33:11,154:INFO:Starting cross validation
2023-06-03 14:33:11,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:11,720:INFO:Calculating mean and std
2023-06-03 14:33:11,722:INFO:Creating metrics dataframe
2023-06-03 14:33:11,733:INFO:Uploading results into container
2023-06-03 14:33:11,733:INFO:Uploading model into container now
2023-06-03 14:33:11,734:INFO:_master_model_container: 9
2023-06-03 14:33:11,734:INFO:_display_container: 2
2023-06-03 14:33:11,734:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:33:11,734:INFO:create_model() successfully completed......................................
2023-06-03 14:33:11,820:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:11,820:INFO:Creating metrics dataframe
2023-06-03 14:33:11,829:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:33:11,830:INFO:Total runtime is 0.13226571877797444 minutes
2023-06-03 14:33:11,833:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:11,834:INFO:Initializing create_model()
2023-06-03 14:33:11,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:11,834:INFO:Checking exceptions
2023-06-03 14:33:11,834:INFO:Importing libraries
2023-06-03 14:33:11,834:INFO:Copying training dataset
2023-06-03 14:33:11,846:INFO:Defining folds
2023-06-03 14:33:11,846:INFO:Declaring metric variables
2023-06-03 14:33:11,853:INFO:Importing untrained model
2023-06-03 14:33:11,859:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:33:11,872:INFO:Starting cross validation
2023-06-03 14:33:11,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:16,576:INFO:Calculating mean and std
2023-06-03 14:33:16,579:INFO:Creating metrics dataframe
2023-06-03 14:33:16,602:INFO:Uploading results into container
2023-06-03 14:33:16,603:INFO:Uploading model into container now
2023-06-03 14:33:16,604:INFO:_master_model_container: 10
2023-06-03 14:33:16,604:INFO:_display_container: 2
2023-06-03 14:33:16,604:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:33:16,604:INFO:create_model() successfully completed......................................
2023-06-03 14:33:16,700:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:16,700:INFO:Creating metrics dataframe
2023-06-03 14:33:16,714:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:33:16,714:INFO:Total runtime is 0.21367090940475464 minutes
2023-06-03 14:33:16,717:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:16,718:INFO:Initializing create_model()
2023-06-03 14:33:16,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:16,718:INFO:Checking exceptions
2023-06-03 14:33:16,718:INFO:Importing libraries
2023-06-03 14:33:16,718:INFO:Copying training dataset
2023-06-03 14:33:16,722:INFO:Defining folds
2023-06-03 14:33:16,723:INFO:Declaring metric variables
2023-06-03 14:33:16,725:INFO:Importing untrained model
2023-06-03 14:33:16,728:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:33:16,732:INFO:Starting cross validation
2023-06-03 14:33:16,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:16,860:INFO:Calculating mean and std
2023-06-03 14:33:16,863:INFO:Creating metrics dataframe
2023-06-03 14:33:16,882:INFO:Uploading results into container
2023-06-03 14:33:16,883:INFO:Uploading model into container now
2023-06-03 14:33:16,883:INFO:_master_model_container: 11
2023-06-03 14:33:16,883:INFO:_display_container: 2
2023-06-03 14:33:16,884:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:33:16,884:INFO:create_model() successfully completed......................................
2023-06-03 14:33:16,971:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:16,971:INFO:Creating metrics dataframe
2023-06-03 14:33:16,981:INFO:Initializing Extra Trees Classifier
2023-06-03 14:33:16,981:INFO:Total runtime is 0.21812455654144286 minutes
2023-06-03 14:33:16,985:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:16,986:INFO:Initializing create_model()
2023-06-03 14:33:16,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:16,986:INFO:Checking exceptions
2023-06-03 14:33:16,986:INFO:Importing libraries
2023-06-03 14:33:16,986:INFO:Copying training dataset
2023-06-03 14:33:16,998:INFO:Defining folds
2023-06-03 14:33:16,998:INFO:Declaring metric variables
2023-06-03 14:33:17,002:INFO:Importing untrained model
2023-06-03 14:33:17,007:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:33:17,014:INFO:Starting cross validation
2023-06-03 14:33:17,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:18,323:INFO:Calculating mean and std
2023-06-03 14:33:18,326:INFO:Creating metrics dataframe
2023-06-03 14:33:18,340:INFO:Uploading results into container
2023-06-03 14:33:18,340:INFO:Uploading model into container now
2023-06-03 14:33:18,341:INFO:_master_model_container: 12
2023-06-03 14:33:18,341:INFO:_display_container: 2
2023-06-03 14:33:18,341:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:33:18,341:INFO:create_model() successfully completed......................................
2023-06-03 14:33:18,426:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:18,426:INFO:Creating metrics dataframe
2023-06-03 14:33:18,436:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:33:18,437:INFO:Total runtime is 0.24238181511561074 minutes
2023-06-03 14:33:18,440:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:18,440:INFO:Initializing create_model()
2023-06-03 14:33:18,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:18,440:INFO:Checking exceptions
2023-06-03 14:33:18,440:INFO:Importing libraries
2023-06-03 14:33:18,440:INFO:Copying training dataset
2023-06-03 14:33:18,445:INFO:Defining folds
2023-06-03 14:33:18,445:INFO:Declaring metric variables
2023-06-03 14:33:18,448:INFO:Importing untrained model
2023-06-03 14:33:18,451:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:33:18,457:INFO:Starting cross validation
2023-06-03 14:33:18,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:19,389:INFO:Calculating mean and std
2023-06-03 14:33:19,392:INFO:Creating metrics dataframe
2023-06-03 14:33:19,416:INFO:Uploading results into container
2023-06-03 14:33:19,417:INFO:Uploading model into container now
2023-06-03 14:33:19,417:INFO:_master_model_container: 13
2023-06-03 14:33:19,417:INFO:_display_container: 2
2023-06-03 14:33:19,418:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:33:19,418:INFO:create_model() successfully completed......................................
2023-06-03 14:33:19,504:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:19,505:INFO:Creating metrics dataframe
2023-06-03 14:33:19,514:INFO:Initializing Dummy Classifier
2023-06-03 14:33:19,515:INFO:Total runtime is 0.2603497823079427 minutes
2023-06-03 14:33:19,517:INFO:SubProcess create_model() called ==================================
2023-06-03 14:33:19,518:INFO:Initializing create_model()
2023-06-03 14:33:19,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d5a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:19,518:INFO:Checking exceptions
2023-06-03 14:33:19,518:INFO:Importing libraries
2023-06-03 14:33:19,518:INFO:Copying training dataset
2023-06-03 14:33:19,522:INFO:Defining folds
2023-06-03 14:33:19,522:INFO:Declaring metric variables
2023-06-03 14:33:19,526:INFO:Importing untrained model
2023-06-03 14:33:19,529:INFO:Dummy Classifier Imported successfully
2023-06-03 14:33:19,542:INFO:Starting cross validation
2023-06-03 14:33:19,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:33:19,634:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,636:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,639:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,640:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,641:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,642:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,642:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,646:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,651:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,655:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:33:19,678:INFO:Calculating mean and std
2023-06-03 14:33:19,680:INFO:Creating metrics dataframe
2023-06-03 14:33:19,707:INFO:Uploading results into container
2023-06-03 14:33:19,708:INFO:Uploading model into container now
2023-06-03 14:33:19,708:INFO:_master_model_container: 14
2023-06-03 14:33:19,708:INFO:_display_container: 2
2023-06-03 14:33:19,708:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:33:19,708:INFO:create_model() successfully completed......................................
2023-06-03 14:33:19,802:INFO:SubProcess create_model() end ==================================
2023-06-03 14:33:19,802:INFO:Creating metrics dataframe
2023-06-03 14:33:19,824:INFO:Initializing create_model()
2023-06-03 14:33:19,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:33:19,824:INFO:Checking exceptions
2023-06-03 14:33:19,827:INFO:Importing libraries
2023-06-03 14:33:19,828:INFO:Copying training dataset
2023-06-03 14:33:19,836:INFO:Defining folds
2023-06-03 14:33:19,836:INFO:Declaring metric variables
2023-06-03 14:33:19,836:INFO:Importing untrained model
2023-06-03 14:33:19,836:INFO:Declaring custom model
2023-06-03 14:33:19,837:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:33:19,838:INFO:Cross validation set to False
2023-06-03 14:33:19,838:INFO:Fitting Model
2023-06-03 14:33:20,399:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:33:20,400:INFO:create_model() successfully completed......................................
2023-06-03 14:33:20,524:INFO:_master_model_container: 14
2023-06-03 14:33:20,524:INFO:_display_container: 2
2023-06-03 14:33:20,525:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:33:20,525:INFO:compare_models() successfully completed......................................
2023-06-03 14:35:11,509:INFO:gpu_param set to False
2023-06-03 14:35:11,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:35:11,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:35:11,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:35:11,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:35:15,704:INFO:Initializing compare_models()
2023-06-03 14:35:15,704:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:35:15,704:INFO:Checking exceptions
2023-06-03 14:35:15,710:INFO:Preparing display monitor
2023-06-03 14:35:15,740:INFO:Initializing Logistic Regression
2023-06-03 14:35:15,740:INFO:Total runtime is 3.981590270996094e-06 minutes
2023-06-03 14:35:15,743:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:15,744:INFO:Initializing create_model()
2023-06-03 14:35:15,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:15,744:INFO:Checking exceptions
2023-06-03 14:35:15,744:INFO:Importing libraries
2023-06-03 14:35:15,744:INFO:Copying training dataset
2023-06-03 14:35:15,749:INFO:Defining folds
2023-06-03 14:35:15,749:INFO:Declaring metric variables
2023-06-03 14:35:15,752:INFO:Importing untrained model
2023-06-03 14:35:15,755:INFO:Logistic Regression Imported successfully
2023-06-03 14:35:15,761:INFO:Starting cross validation
2023-06-03 14:35:15,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:15,903:INFO:Calculating mean and std
2023-06-03 14:35:15,903:INFO:Creating metrics dataframe
2023-06-03 14:35:15,922:INFO:Uploading results into container
2023-06-03 14:35:15,923:INFO:Uploading model into container now
2023-06-03 14:35:15,923:INFO:_master_model_container: 15
2023-06-03 14:35:15,923:INFO:_display_container: 3
2023-06-03 14:35:15,924:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:35:15,924:INFO:create_model() successfully completed......................................
2023-06-03 14:35:16,021:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:16,021:INFO:Creating metrics dataframe
2023-06-03 14:35:16,028:INFO:Initializing K Neighbors Classifier
2023-06-03 14:35:16,028:INFO:Total runtime is 0.004814207553863525 minutes
2023-06-03 14:35:16,031:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:16,031:INFO:Initializing create_model()
2023-06-03 14:35:16,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:16,031:INFO:Checking exceptions
2023-06-03 14:35:16,031:INFO:Importing libraries
2023-06-03 14:35:16,031:INFO:Copying training dataset
2023-06-03 14:35:16,035:INFO:Defining folds
2023-06-03 14:35:16,035:INFO:Declaring metric variables
2023-06-03 14:35:16,037:INFO:Importing untrained model
2023-06-03 14:35:16,040:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:35:16,046:INFO:Starting cross validation
2023-06-03 14:35:16,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:16,245:INFO:Calculating mean and std
2023-06-03 14:35:16,245:INFO:Creating metrics dataframe
2023-06-03 14:35:16,259:INFO:Uploading results into container
2023-06-03 14:35:16,260:INFO:Uploading model into container now
2023-06-03 14:35:16,260:INFO:_master_model_container: 16
2023-06-03 14:35:16,260:INFO:_display_container: 3
2023-06-03 14:35:16,261:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:35:16,261:INFO:create_model() successfully completed......................................
2023-06-03 14:35:16,346:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:16,346:INFO:Creating metrics dataframe
2023-06-03 14:35:16,354:INFO:Initializing Naive Bayes
2023-06-03 14:35:16,354:INFO:Total runtime is 0.010249463717142741 minutes
2023-06-03 14:35:16,358:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:16,358:INFO:Initializing create_model()
2023-06-03 14:35:16,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:16,358:INFO:Checking exceptions
2023-06-03 14:35:16,358:INFO:Importing libraries
2023-06-03 14:35:16,358:INFO:Copying training dataset
2023-06-03 14:35:16,362:INFO:Defining folds
2023-06-03 14:35:16,362:INFO:Declaring metric variables
2023-06-03 14:35:16,365:INFO:Importing untrained model
2023-06-03 14:35:16,368:INFO:Naive Bayes Imported successfully
2023-06-03 14:35:16,375:INFO:Starting cross validation
2023-06-03 14:35:16,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:16,518:INFO:Calculating mean and std
2023-06-03 14:35:16,518:INFO:Creating metrics dataframe
2023-06-03 14:35:16,542:INFO:Uploading results into container
2023-06-03 14:35:16,543:INFO:Uploading model into container now
2023-06-03 14:35:16,543:INFO:_master_model_container: 17
2023-06-03 14:35:16,543:INFO:_display_container: 3
2023-06-03 14:35:16,544:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:35:16,544:INFO:create_model() successfully completed......................................
2023-06-03 14:35:16,638:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:16,638:INFO:Creating metrics dataframe
2023-06-03 14:35:16,646:INFO:Initializing Decision Tree Classifier
2023-06-03 14:35:16,646:INFO:Total runtime is 0.015111172199249269 minutes
2023-06-03 14:35:16,649:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:16,649:INFO:Initializing create_model()
2023-06-03 14:35:16,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:16,649:INFO:Checking exceptions
2023-06-03 14:35:16,649:INFO:Importing libraries
2023-06-03 14:35:16,649:INFO:Copying training dataset
2023-06-03 14:35:16,653:INFO:Defining folds
2023-06-03 14:35:16,653:INFO:Declaring metric variables
2023-06-03 14:35:16,656:INFO:Importing untrained model
2023-06-03 14:35:16,658:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:35:16,663:INFO:Starting cross validation
2023-06-03 14:35:16,664:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:16,811:INFO:Calculating mean and std
2023-06-03 14:35:16,812:INFO:Creating metrics dataframe
2023-06-03 14:35:16,829:INFO:Uploading results into container
2023-06-03 14:35:16,829:INFO:Uploading model into container now
2023-06-03 14:35:16,830:INFO:_master_model_container: 18
2023-06-03 14:35:16,830:INFO:_display_container: 3
2023-06-03 14:35:16,830:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:35:16,830:INFO:create_model() successfully completed......................................
2023-06-03 14:35:16,914:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:16,914:INFO:Creating metrics dataframe
2023-06-03 14:35:16,922:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:35:16,922:INFO:Total runtime is 0.01970675786336263 minutes
2023-06-03 14:35:16,925:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:16,925:INFO:Initializing create_model()
2023-06-03 14:35:16,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:16,925:INFO:Checking exceptions
2023-06-03 14:35:16,925:INFO:Importing libraries
2023-06-03 14:35:16,925:INFO:Copying training dataset
2023-06-03 14:35:16,929:INFO:Defining folds
2023-06-03 14:35:16,930:INFO:Declaring metric variables
2023-06-03 14:35:16,932:INFO:Importing untrained model
2023-06-03 14:35:16,935:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:35:16,940:INFO:Starting cross validation
2023-06-03 14:35:16,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:16,993:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:16,996:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:16,996:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:16,997:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:16,998:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:16,999:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,001:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,003:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:17,007:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:17,007:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,008:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:17,010:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,011:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,013:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:17,017:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,020:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:17,023:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:35:17,025:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,028:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:17,034:INFO:Calculating mean and std
2023-06-03 14:35:17,036:INFO:Creating metrics dataframe
2023-06-03 14:35:17,051:INFO:Uploading results into container
2023-06-03 14:35:17,052:INFO:Uploading model into container now
2023-06-03 14:35:17,052:INFO:_master_model_container: 19
2023-06-03 14:35:17,052:INFO:_display_container: 3
2023-06-03 14:35:17,052:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:35:17,052:INFO:create_model() successfully completed......................................
2023-06-03 14:35:17,137:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:17,137:INFO:Creating metrics dataframe
2023-06-03 14:35:17,146:INFO:Initializing Ridge Classifier
2023-06-03 14:35:17,146:INFO:Total runtime is 0.023445761203765868 minutes
2023-06-03 14:35:17,149:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:17,150:INFO:Initializing create_model()
2023-06-03 14:35:17,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:17,150:INFO:Checking exceptions
2023-06-03 14:35:17,150:INFO:Importing libraries
2023-06-03 14:35:17,150:INFO:Copying training dataset
2023-06-03 14:35:17,154:INFO:Defining folds
2023-06-03 14:35:17,155:INFO:Declaring metric variables
2023-06-03 14:35:17,158:INFO:Importing untrained model
2023-06-03 14:35:17,161:INFO:Ridge Classifier Imported successfully
2023-06-03 14:35:17,167:INFO:Starting cross validation
2023-06-03 14:35:17,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:17,230:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,231:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,233:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,238:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,239:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,242:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,244:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,244:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,245:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,250:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:35:17,273:INFO:Calculating mean and std
2023-06-03 14:35:17,274:INFO:Creating metrics dataframe
2023-06-03 14:35:17,298:INFO:Uploading results into container
2023-06-03 14:35:17,299:INFO:Uploading model into container now
2023-06-03 14:35:17,299:INFO:_master_model_container: 20
2023-06-03 14:35:17,299:INFO:_display_container: 3
2023-06-03 14:35:17,299:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:35:17,299:INFO:create_model() successfully completed......................................
2023-06-03 14:35:17,386:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:17,386:INFO:Creating metrics dataframe
2023-06-03 14:35:17,394:INFO:Initializing Random Forest Classifier
2023-06-03 14:35:17,394:INFO:Total runtime is 0.02757825454076131 minutes
2023-06-03 14:35:17,397:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:17,397:INFO:Initializing create_model()
2023-06-03 14:35:17,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:17,397:INFO:Checking exceptions
2023-06-03 14:35:17,397:INFO:Importing libraries
2023-06-03 14:35:17,397:INFO:Copying training dataset
2023-06-03 14:35:17,402:INFO:Defining folds
2023-06-03 14:35:17,402:INFO:Declaring metric variables
2023-06-03 14:35:17,405:INFO:Importing untrained model
2023-06-03 14:35:17,411:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:35:17,423:INFO:Starting cross validation
2023-06-03 14:35:17,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:17,828:INFO:Calculating mean and std
2023-06-03 14:35:17,830:INFO:Creating metrics dataframe
2023-06-03 14:35:17,856:INFO:Uploading results into container
2023-06-03 14:35:17,857:INFO:Uploading model into container now
2023-06-03 14:35:17,857:INFO:_master_model_container: 21
2023-06-03 14:35:17,857:INFO:_display_container: 3
2023-06-03 14:35:17,857:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:35:17,858:INFO:create_model() successfully completed......................................
2023-06-03 14:35:17,956:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:17,956:INFO:Creating metrics dataframe
2023-06-03 14:35:17,964:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:35:17,965:INFO:Total runtime is 0.03708448807398478 minutes
2023-06-03 14:35:17,968:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:17,969:INFO:Initializing create_model()
2023-06-03 14:35:17,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:17,969:INFO:Checking exceptions
2023-06-03 14:35:17,969:INFO:Importing libraries
2023-06-03 14:35:17,969:INFO:Copying training dataset
2023-06-03 14:35:17,980:INFO:Defining folds
2023-06-03 14:35:17,980:INFO:Declaring metric variables
2023-06-03 14:35:17,986:INFO:Importing untrained model
2023-06-03 14:35:17,990:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:35:17,998:INFO:Starting cross validation
2023-06-03 14:35:17,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:18,146:INFO:Calculating mean and std
2023-06-03 14:35:18,148:INFO:Creating metrics dataframe
2023-06-03 14:35:18,177:INFO:Uploading results into container
2023-06-03 14:35:18,177:INFO:Uploading model into container now
2023-06-03 14:35:18,178:INFO:_master_model_container: 22
2023-06-03 14:35:18,178:INFO:_display_container: 3
2023-06-03 14:35:18,178:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:35:18,178:INFO:create_model() successfully completed......................................
2023-06-03 14:35:18,268:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:18,268:INFO:Creating metrics dataframe
2023-06-03 14:35:18,277:INFO:Initializing Ada Boost Classifier
2023-06-03 14:35:18,277:INFO:Total runtime is 0.04229272603988647 minutes
2023-06-03 14:35:18,280:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:18,280:INFO:Initializing create_model()
2023-06-03 14:35:18,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:18,280:INFO:Checking exceptions
2023-06-03 14:35:18,280:INFO:Importing libraries
2023-06-03 14:35:18,280:INFO:Copying training dataset
2023-06-03 14:35:18,284:INFO:Defining folds
2023-06-03 14:35:18,285:INFO:Declaring metric variables
2023-06-03 14:35:18,287:INFO:Importing untrained model
2023-06-03 14:35:18,290:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:35:18,295:INFO:Starting cross validation
2023-06-03 14:35:18,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:18,496:INFO:Calculating mean and std
2023-06-03 14:35:18,498:INFO:Creating metrics dataframe
2023-06-03 14:35:18,515:INFO:Uploading results into container
2023-06-03 14:35:18,515:INFO:Uploading model into container now
2023-06-03 14:35:18,516:INFO:_master_model_container: 23
2023-06-03 14:35:18,516:INFO:_display_container: 3
2023-06-03 14:35:18,516:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:35:18,516:INFO:create_model() successfully completed......................................
2023-06-03 14:35:18,600:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:18,601:INFO:Creating metrics dataframe
2023-06-03 14:35:18,610:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:35:18,610:INFO:Total runtime is 0.0478419820467631 minutes
2023-06-03 14:35:18,613:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:18,613:INFO:Initializing create_model()
2023-06-03 14:35:18,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:18,613:INFO:Checking exceptions
2023-06-03 14:35:18,613:INFO:Importing libraries
2023-06-03 14:35:18,613:INFO:Copying training dataset
2023-06-03 14:35:18,618:INFO:Defining folds
2023-06-03 14:35:18,618:INFO:Declaring metric variables
2023-06-03 14:35:18,621:INFO:Importing untrained model
2023-06-03 14:35:18,625:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:35:18,631:INFO:Starting cross validation
2023-06-03 14:35:18,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:19,033:INFO:Calculating mean and std
2023-06-03 14:35:19,036:INFO:Creating metrics dataframe
2023-06-03 14:35:19,053:INFO:Uploading results into container
2023-06-03 14:35:19,053:INFO:Uploading model into container now
2023-06-03 14:35:19,054:INFO:_master_model_container: 24
2023-06-03 14:35:19,054:INFO:_display_container: 3
2023-06-03 14:35:19,054:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:35:19,054:INFO:create_model() successfully completed......................................
2023-06-03 14:35:19,139:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:19,139:INFO:Creating metrics dataframe
2023-06-03 14:35:19,148:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:35:19,148:INFO:Total runtime is 0.056814587116241454 minutes
2023-06-03 14:35:19,152:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:19,152:INFO:Initializing create_model()
2023-06-03 14:35:19,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:19,152:INFO:Checking exceptions
2023-06-03 14:35:19,152:INFO:Importing libraries
2023-06-03 14:35:19,152:INFO:Copying training dataset
2023-06-03 14:35:19,157:INFO:Defining folds
2023-06-03 14:35:19,157:INFO:Declaring metric variables
2023-06-03 14:35:19,162:INFO:Importing untrained model
2023-06-03 14:35:19,169:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:35:19,182:INFO:Starting cross validation
2023-06-03 14:35:19,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:19,330:INFO:Calculating mean and std
2023-06-03 14:35:19,332:INFO:Creating metrics dataframe
2023-06-03 14:35:19,360:INFO:Uploading results into container
2023-06-03 14:35:19,361:INFO:Uploading model into container now
2023-06-03 14:35:19,361:INFO:_master_model_container: 25
2023-06-03 14:35:19,361:INFO:_display_container: 3
2023-06-03 14:35:19,362:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:35:19,362:INFO:create_model() successfully completed......................................
2023-06-03 14:35:19,448:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:19,449:INFO:Creating metrics dataframe
2023-06-03 14:35:19,458:INFO:Initializing Extra Trees Classifier
2023-06-03 14:35:19,458:INFO:Total runtime is 0.061977537473042806 minutes
2023-06-03 14:35:19,461:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:19,462:INFO:Initializing create_model()
2023-06-03 14:35:19,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:19,462:INFO:Checking exceptions
2023-06-03 14:35:19,462:INFO:Importing libraries
2023-06-03 14:35:19,462:INFO:Copying training dataset
2023-06-03 14:35:19,466:INFO:Defining folds
2023-06-03 14:35:19,466:INFO:Declaring metric variables
2023-06-03 14:35:19,470:INFO:Importing untrained model
2023-06-03 14:35:19,473:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:35:19,478:INFO:Starting cross validation
2023-06-03 14:35:19,479:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:20,139:INFO:Calculating mean and std
2023-06-03 14:35:20,142:INFO:Creating metrics dataframe
2023-06-03 14:35:20,168:INFO:Uploading results into container
2023-06-03 14:35:20,169:INFO:Uploading model into container now
2023-06-03 14:35:20,169:INFO:_master_model_container: 26
2023-06-03 14:35:20,169:INFO:_display_container: 3
2023-06-03 14:35:20,170:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:35:20,170:INFO:create_model() successfully completed......................................
2023-06-03 14:35:20,267:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:20,267:INFO:Creating metrics dataframe
2023-06-03 14:35:20,278:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:35:20,278:INFO:Total runtime is 0.07563618818918864 minutes
2023-06-03 14:35:20,281:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:20,281:INFO:Initializing create_model()
2023-06-03 14:35:20,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:20,281:INFO:Checking exceptions
2023-06-03 14:35:20,282:INFO:Importing libraries
2023-06-03 14:35:20,282:INFO:Copying training dataset
2023-06-03 14:35:20,292:INFO:Defining folds
2023-06-03 14:35:20,293:INFO:Declaring metric variables
2023-06-03 14:35:20,298:INFO:Importing untrained model
2023-06-03 14:35:20,302:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:35:20,310:INFO:Starting cross validation
2023-06-03 14:35:20,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:20,653:INFO:Calculating mean and std
2023-06-03 14:35:20,655:INFO:Creating metrics dataframe
2023-06-03 14:35:20,681:INFO:Uploading results into container
2023-06-03 14:35:20,681:INFO:Uploading model into container now
2023-06-03 14:35:20,682:INFO:_master_model_container: 27
2023-06-03 14:35:20,682:INFO:_display_container: 3
2023-06-03 14:35:20,682:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:35:20,682:INFO:create_model() successfully completed......................................
2023-06-03 14:35:20,767:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:20,768:INFO:Creating metrics dataframe
2023-06-03 14:35:20,782:INFO:Initializing Dummy Classifier
2023-06-03 14:35:20,782:INFO:Total runtime is 0.08404070536295573 minutes
2023-06-03 14:35:20,785:INFO:SubProcess create_model() called ==================================
2023-06-03 14:35:20,785:INFO:Initializing create_model()
2023-06-03 14:35:20,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b7c4d9be0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:20,785:INFO:Checking exceptions
2023-06-03 14:35:20,785:INFO:Importing libraries
2023-06-03 14:35:20,786:INFO:Copying training dataset
2023-06-03 14:35:20,790:INFO:Defining folds
2023-06-03 14:35:20,790:INFO:Declaring metric variables
2023-06-03 14:35:20,793:INFO:Importing untrained model
2023-06-03 14:35:20,797:INFO:Dummy Classifier Imported successfully
2023-06-03 14:35:20,805:INFO:Starting cross validation
2023-06-03 14:35:20,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:35:20,882:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,892:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,904:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,911:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,914:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,916:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,921:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,921:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,927:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,931:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:35:20,941:INFO:Calculating mean and std
2023-06-03 14:35:20,943:INFO:Creating metrics dataframe
2023-06-03 14:35:20,969:INFO:Uploading results into container
2023-06-03 14:35:20,970:INFO:Uploading model into container now
2023-06-03 14:35:20,970:INFO:_master_model_container: 28
2023-06-03 14:35:20,970:INFO:_display_container: 3
2023-06-03 14:35:20,971:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:35:20,971:INFO:create_model() successfully completed......................................
2023-06-03 14:35:21,058:INFO:SubProcess create_model() end ==================================
2023-06-03 14:35:21,058:INFO:Creating metrics dataframe
2023-06-03 14:35:21,079:INFO:Initializing create_model()
2023-06-03 14:35:21,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:35:21,079:INFO:Checking exceptions
2023-06-03 14:35:21,082:INFO:Importing libraries
2023-06-03 14:35:21,082:INFO:Copying training dataset
2023-06-03 14:35:21,091:INFO:Defining folds
2023-06-03 14:35:21,091:INFO:Declaring metric variables
2023-06-03 14:35:21,091:INFO:Importing untrained model
2023-06-03 14:35:21,091:INFO:Declaring custom model
2023-06-03 14:35:21,092:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:35:21,093:INFO:Cross validation set to False
2023-06-03 14:35:21,093:INFO:Fitting Model
2023-06-03 14:35:21,279:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:35:21,279:INFO:create_model() successfully completed......................................
2023-06-03 14:35:21,387:INFO:_master_model_container: 28
2023-06-03 14:35:21,387:INFO:_display_container: 3
2023-06-03 14:35:21,388:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:35:21,388:INFO:compare_models() successfully completed......................................
2023-06-03 14:36:00,295:INFO:Initializing compare_models()
2023-06-03 14:36:00,295:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, include=None, fold=5, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:36:00,296:INFO:Checking exceptions
2023-06-03 14:36:00,302:INFO:Preparing display monitor
2023-06-03 14:36:00,336:INFO:Initializing Logistic Regression
2023-06-03 14:36:00,336:INFO:Total runtime is 4.287560780843099e-06 minutes
2023-06-03 14:36:00,340:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:00,341:INFO:Initializing create_model()
2023-06-03 14:36:00,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:00,341:INFO:Checking exceptions
2023-06-03 14:36:00,341:INFO:Importing libraries
2023-06-03 14:36:00,341:INFO:Copying training dataset
2023-06-03 14:36:00,347:INFO:Defining folds
2023-06-03 14:36:00,347:INFO:Declaring metric variables
2023-06-03 14:36:00,350:INFO:Importing untrained model
2023-06-03 14:36:00,353:INFO:Logistic Regression Imported successfully
2023-06-03 14:36:00,359:INFO:Starting cross validation
2023-06-03 14:36:00,360:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:01,217:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:36:01,217:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:36:01,235:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:36:01,261:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:36:01,278:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:36:01,320:INFO:Calculating mean and std
2023-06-03 14:36:01,323:INFO:Creating metrics dataframe
2023-06-03 14:36:01,339:INFO:Uploading results into container
2023-06-03 14:36:01,339:INFO:Uploading model into container now
2023-06-03 14:36:01,339:INFO:_master_model_container: 29
2023-06-03 14:36:01,339:INFO:_display_container: 4
2023-06-03 14:36:01,340:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:36:01,340:INFO:create_model() successfully completed......................................
2023-06-03 14:36:01,427:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:01,427:INFO:Creating metrics dataframe
2023-06-03 14:36:01,435:INFO:Initializing K Neighbors Classifier
2023-06-03 14:36:01,435:INFO:Total runtime is 0.018315895398457845 minutes
2023-06-03 14:36:01,438:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:01,438:INFO:Initializing create_model()
2023-06-03 14:36:01,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:01,438:INFO:Checking exceptions
2023-06-03 14:36:01,438:INFO:Importing libraries
2023-06-03 14:36:01,438:INFO:Copying training dataset
2023-06-03 14:36:01,443:INFO:Defining folds
2023-06-03 14:36:01,443:INFO:Declaring metric variables
2023-06-03 14:36:01,446:INFO:Importing untrained model
2023-06-03 14:36:01,449:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:36:01,460:INFO:Starting cross validation
2023-06-03 14:36:01,461:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:01,678:INFO:Calculating mean and std
2023-06-03 14:36:01,679:INFO:Creating metrics dataframe
2023-06-03 14:36:01,699:INFO:Uploading results into container
2023-06-03 14:36:01,700:INFO:Uploading model into container now
2023-06-03 14:36:01,700:INFO:_master_model_container: 30
2023-06-03 14:36:01,700:INFO:_display_container: 4
2023-06-03 14:36:01,701:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:36:01,701:INFO:create_model() successfully completed......................................
2023-06-03 14:36:01,795:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:01,795:INFO:Creating metrics dataframe
2023-06-03 14:36:01,803:INFO:Initializing Naive Bayes
2023-06-03 14:36:01,803:INFO:Total runtime is 0.024448533852895103 minutes
2023-06-03 14:36:01,806:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:01,807:INFO:Initializing create_model()
2023-06-03 14:36:01,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:01,807:INFO:Checking exceptions
2023-06-03 14:36:01,807:INFO:Importing libraries
2023-06-03 14:36:01,808:INFO:Copying training dataset
2023-06-03 14:36:01,815:INFO:Defining folds
2023-06-03 14:36:01,815:INFO:Declaring metric variables
2023-06-03 14:36:01,818:INFO:Importing untrained model
2023-06-03 14:36:01,822:INFO:Naive Bayes Imported successfully
2023-06-03 14:36:01,828:INFO:Starting cross validation
2023-06-03 14:36:01,829:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:01,932:INFO:Calculating mean and std
2023-06-03 14:36:01,933:INFO:Creating metrics dataframe
2023-06-03 14:36:01,949:INFO:Uploading results into container
2023-06-03 14:36:01,950:INFO:Uploading model into container now
2023-06-03 14:36:01,951:INFO:_master_model_container: 31
2023-06-03 14:36:01,951:INFO:_display_container: 4
2023-06-03 14:36:01,951:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:36:01,951:INFO:create_model() successfully completed......................................
2023-06-03 14:36:02,043:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:02,043:INFO:Creating metrics dataframe
2023-06-03 14:36:02,052:INFO:Initializing Decision Tree Classifier
2023-06-03 14:36:02,052:INFO:Total runtime is 0.028599536418914797 minutes
2023-06-03 14:36:02,055:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:02,055:INFO:Initializing create_model()
2023-06-03 14:36:02,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:02,056:INFO:Checking exceptions
2023-06-03 14:36:02,056:INFO:Importing libraries
2023-06-03 14:36:02,056:INFO:Copying training dataset
2023-06-03 14:36:02,063:INFO:Defining folds
2023-06-03 14:36:02,063:INFO:Declaring metric variables
2023-06-03 14:36:02,068:INFO:Importing untrained model
2023-06-03 14:36:02,072:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:36:02,079:INFO:Starting cross validation
2023-06-03 14:36:02,080:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:02,224:INFO:Calculating mean and std
2023-06-03 14:36:02,226:INFO:Creating metrics dataframe
2023-06-03 14:36:02,250:INFO:Uploading results into container
2023-06-03 14:36:02,250:INFO:Uploading model into container now
2023-06-03 14:36:02,250:INFO:_master_model_container: 32
2023-06-03 14:36:02,250:INFO:_display_container: 4
2023-06-03 14:36:02,251:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:36:02,251:INFO:create_model() successfully completed......................................
2023-06-03 14:36:02,337:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:02,337:INFO:Creating metrics dataframe
2023-06-03 14:36:02,346:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:36:02,346:INFO:Total runtime is 0.03349889914194743 minutes
2023-06-03 14:36:02,349:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:02,349:INFO:Initializing create_model()
2023-06-03 14:36:02,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:02,349:INFO:Checking exceptions
2023-06-03 14:36:02,349:INFO:Importing libraries
2023-06-03 14:36:02,349:INFO:Copying training dataset
2023-06-03 14:36:02,354:INFO:Defining folds
2023-06-03 14:36:02,354:INFO:Declaring metric variables
2023-06-03 14:36:02,357:INFO:Importing untrained model
2023-06-03 14:36:02,364:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:36:02,374:INFO:Starting cross validation
2023-06-03 14:36:02,375:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:02,569:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:02,574:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:02,575:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:02,578:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:02,583:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:02,586:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:02,588:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:02,593:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:02,603:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:02,606:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:02,612:INFO:Calculating mean and std
2023-06-03 14:36:02,614:INFO:Creating metrics dataframe
2023-06-03 14:36:02,642:INFO:Uploading results into container
2023-06-03 14:36:02,642:INFO:Uploading model into container now
2023-06-03 14:36:02,643:INFO:_master_model_container: 33
2023-06-03 14:36:02,643:INFO:_display_container: 4
2023-06-03 14:36:02,643:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:36:02,643:INFO:create_model() successfully completed......................................
2023-06-03 14:36:02,737:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:02,738:INFO:Creating metrics dataframe
2023-06-03 14:36:02,746:INFO:Initializing Ridge Classifier
2023-06-03 14:36:02,746:INFO:Total runtime is 0.04016824960708618 minutes
2023-06-03 14:36:02,749:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:02,749:INFO:Initializing create_model()
2023-06-03 14:36:02,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:02,749:INFO:Checking exceptions
2023-06-03 14:36:02,749:INFO:Importing libraries
2023-06-03 14:36:02,749:INFO:Copying training dataset
2023-06-03 14:36:02,753:INFO:Defining folds
2023-06-03 14:36:02,753:INFO:Declaring metric variables
2023-06-03 14:36:02,757:INFO:Importing untrained model
2023-06-03 14:36:02,763:INFO:Ridge Classifier Imported successfully
2023-06-03 14:36:02,776:INFO:Starting cross validation
2023-06-03 14:36:02,777:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:02,843:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:02,852:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:02,857:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:02,862:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:02,865:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:02,888:INFO:Calculating mean and std
2023-06-03 14:36:02,890:INFO:Creating metrics dataframe
2023-06-03 14:36:02,921:INFO:Uploading results into container
2023-06-03 14:36:02,922:INFO:Uploading model into container now
2023-06-03 14:36:02,923:INFO:_master_model_container: 34
2023-06-03 14:36:02,923:INFO:_display_container: 4
2023-06-03 14:36:02,923:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:36:02,923:INFO:create_model() successfully completed......................................
2023-06-03 14:36:03,015:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:03,015:INFO:Creating metrics dataframe
2023-06-03 14:36:03,024:INFO:Initializing Random Forest Classifier
2023-06-03 14:36:03,024:INFO:Total runtime is 0.044800941149393717 minutes
2023-06-03 14:36:03,027:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:03,027:INFO:Initializing create_model()
2023-06-03 14:36:03,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:03,027:INFO:Checking exceptions
2023-06-03 14:36:03,027:INFO:Importing libraries
2023-06-03 14:36:03,027:INFO:Copying training dataset
2023-06-03 14:36:03,031:INFO:Defining folds
2023-06-03 14:36:03,031:INFO:Declaring metric variables
2023-06-03 14:36:03,034:INFO:Importing untrained model
2023-06-03 14:36:03,037:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:36:03,042:INFO:Starting cross validation
2023-06-03 14:36:03,042:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:04,044:INFO:Calculating mean and std
2023-06-03 14:36:04,046:INFO:Creating metrics dataframe
2023-06-03 14:36:04,087:INFO:Uploading results into container
2023-06-03 14:36:04,087:INFO:Uploading model into container now
2023-06-03 14:36:04,088:INFO:_master_model_container: 35
2023-06-03 14:36:04,088:INFO:_display_container: 4
2023-06-03 14:36:04,088:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:04,088:INFO:create_model() successfully completed......................................
2023-06-03 14:36:04,175:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:04,175:INFO:Creating metrics dataframe
2023-06-03 14:36:04,184:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:36:04,184:INFO:Total runtime is 0.0641384760538737 minutes
2023-06-03 14:36:04,187:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:04,187:INFO:Initializing create_model()
2023-06-03 14:36:04,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:04,187:INFO:Checking exceptions
2023-06-03 14:36:04,187:INFO:Importing libraries
2023-06-03 14:36:04,187:INFO:Copying training dataset
2023-06-03 14:36:04,191:INFO:Defining folds
2023-06-03 14:36:04,192:INFO:Declaring metric variables
2023-06-03 14:36:04,194:INFO:Importing untrained model
2023-06-03 14:36:04,197:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:36:04,202:INFO:Starting cross validation
2023-06-03 14:36:04,202:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:04,300:INFO:Calculating mean and std
2023-06-03 14:36:04,302:INFO:Creating metrics dataframe
2023-06-03 14:36:04,328:INFO:Uploading results into container
2023-06-03 14:36:04,329:INFO:Uploading model into container now
2023-06-03 14:36:04,330:INFO:_master_model_container: 36
2023-06-03 14:36:04,330:INFO:_display_container: 4
2023-06-03 14:36:04,330:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:36:04,330:INFO:create_model() successfully completed......................................
2023-06-03 14:36:04,419:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:04,419:INFO:Creating metrics dataframe
2023-06-03 14:36:04,428:INFO:Initializing Ada Boost Classifier
2023-06-03 14:36:04,428:INFO:Total runtime is 0.06820785601933797 minutes
2023-06-03 14:36:04,434:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:04,434:INFO:Initializing create_model()
2023-06-03 14:36:04,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:04,434:INFO:Checking exceptions
2023-06-03 14:36:04,434:INFO:Importing libraries
2023-06-03 14:36:04,435:INFO:Copying training dataset
2023-06-03 14:36:04,445:INFO:Defining folds
2023-06-03 14:36:04,445:INFO:Declaring metric variables
2023-06-03 14:36:04,450:INFO:Importing untrained model
2023-06-03 14:36:04,455:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:36:04,461:INFO:Starting cross validation
2023-06-03 14:36:04,462:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:04,853:INFO:Calculating mean and std
2023-06-03 14:36:04,853:INFO:Creating metrics dataframe
2023-06-03 14:36:04,871:INFO:Uploading results into container
2023-06-03 14:36:04,872:INFO:Uploading model into container now
2023-06-03 14:36:04,872:INFO:_master_model_container: 37
2023-06-03 14:36:04,872:INFO:_display_container: 4
2023-06-03 14:36:04,872:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:36:04,872:INFO:create_model() successfully completed......................................
2023-06-03 14:36:04,956:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:04,956:INFO:Creating metrics dataframe
2023-06-03 14:36:04,965:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:36:04,965:INFO:Total runtime is 0.07715662717819213 minutes
2023-06-03 14:36:04,968:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:04,968:INFO:Initializing create_model()
2023-06-03 14:36:04,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:04,968:INFO:Checking exceptions
2023-06-03 14:36:04,968:INFO:Importing libraries
2023-06-03 14:36:04,968:INFO:Copying training dataset
2023-06-03 14:36:04,973:INFO:Defining folds
2023-06-03 14:36:04,973:INFO:Declaring metric variables
2023-06-03 14:36:04,975:INFO:Importing untrained model
2023-06-03 14:36:04,978:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:36:04,983:INFO:Starting cross validation
2023-06-03 14:36:04,984:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:09,186:INFO:Calculating mean and std
2023-06-03 14:36:09,187:INFO:Creating metrics dataframe
2023-06-03 14:36:09,210:INFO:Uploading results into container
2023-06-03 14:36:09,211:INFO:Uploading model into container now
2023-06-03 14:36:09,211:INFO:_master_model_container: 38
2023-06-03 14:36:09,211:INFO:_display_container: 4
2023-06-03 14:36:09,211:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:36:09,212:INFO:create_model() successfully completed......................................
2023-06-03 14:36:09,305:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:09,306:INFO:Creating metrics dataframe
2023-06-03 14:36:09,315:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:36:09,315:INFO:Total runtime is 0.14965394735336301 minutes
2023-06-03 14:36:09,319:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:09,319:INFO:Initializing create_model()
2023-06-03 14:36:09,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:09,320:INFO:Checking exceptions
2023-06-03 14:36:09,320:INFO:Importing libraries
2023-06-03 14:36:09,320:INFO:Copying training dataset
2023-06-03 14:36:09,331:INFO:Defining folds
2023-06-03 14:36:09,331:INFO:Declaring metric variables
2023-06-03 14:36:09,338:INFO:Importing untrained model
2023-06-03 14:36:09,343:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:36:09,353:INFO:Starting cross validation
2023-06-03 14:36:09,354:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:09,472:INFO:Calculating mean and std
2023-06-03 14:36:09,473:INFO:Creating metrics dataframe
2023-06-03 14:36:09,491:INFO:Uploading results into container
2023-06-03 14:36:09,491:INFO:Uploading model into container now
2023-06-03 14:36:09,491:INFO:_master_model_container: 39
2023-06-03 14:36:09,491:INFO:_display_container: 4
2023-06-03 14:36:09,492:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:36:09,492:INFO:create_model() successfully completed......................................
2023-06-03 14:36:09,582:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:09,582:INFO:Creating metrics dataframe
2023-06-03 14:36:09,591:INFO:Initializing Extra Trees Classifier
2023-06-03 14:36:09,591:INFO:Total runtime is 0.15425349871317542 minutes
2023-06-03 14:36:09,594:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:09,594:INFO:Initializing create_model()
2023-06-03 14:36:09,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:09,594:INFO:Checking exceptions
2023-06-03 14:36:09,594:INFO:Importing libraries
2023-06-03 14:36:09,594:INFO:Copying training dataset
2023-06-03 14:36:09,598:INFO:Defining folds
2023-06-03 14:36:09,599:INFO:Declaring metric variables
2023-06-03 14:36:09,601:INFO:Importing untrained model
2023-06-03 14:36:09,604:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:36:09,608:INFO:Starting cross validation
2023-06-03 14:36:09,609:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:10,503:INFO:Calculating mean and std
2023-06-03 14:36:10,505:INFO:Creating metrics dataframe
2023-06-03 14:36:10,534:INFO:Uploading results into container
2023-06-03 14:36:10,534:INFO:Uploading model into container now
2023-06-03 14:36:10,535:INFO:_master_model_container: 40
2023-06-03 14:36:10,535:INFO:_display_container: 4
2023-06-03 14:36:10,535:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:10,535:INFO:create_model() successfully completed......................................
2023-06-03 14:36:10,621:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:10,621:INFO:Creating metrics dataframe
2023-06-03 14:36:10,631:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:36:10,631:INFO:Total runtime is 0.17157911459604896 minutes
2023-06-03 14:36:10,634:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:10,634:INFO:Initializing create_model()
2023-06-03 14:36:10,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:10,634:INFO:Checking exceptions
2023-06-03 14:36:10,634:INFO:Importing libraries
2023-06-03 14:36:10,634:INFO:Copying training dataset
2023-06-03 14:36:10,639:INFO:Defining folds
2023-06-03 14:36:10,639:INFO:Declaring metric variables
2023-06-03 14:36:10,642:INFO:Importing untrained model
2023-06-03 14:36:10,645:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:36:10,656:INFO:Starting cross validation
2023-06-03 14:36:10,657:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:11,527:INFO:Calculating mean and std
2023-06-03 14:36:11,529:INFO:Creating metrics dataframe
2023-06-03 14:36:11,555:INFO:Uploading results into container
2023-06-03 14:36:11,556:INFO:Uploading model into container now
2023-06-03 14:36:11,556:INFO:_master_model_container: 41
2023-06-03 14:36:11,556:INFO:_display_container: 4
2023-06-03 14:36:11,557:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:36:11,557:INFO:create_model() successfully completed......................................
2023-06-03 14:36:11,645:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:11,645:INFO:Creating metrics dataframe
2023-06-03 14:36:11,654:INFO:Initializing Dummy Classifier
2023-06-03 14:36:11,654:INFO:Total runtime is 0.188642406463623 minutes
2023-06-03 14:36:11,657:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:11,657:INFO:Initializing create_model()
2023-06-03 14:36:11,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6d44a90>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:11,658:INFO:Checking exceptions
2023-06-03 14:36:11,658:INFO:Importing libraries
2023-06-03 14:36:11,658:INFO:Copying training dataset
2023-06-03 14:36:11,662:INFO:Defining folds
2023-06-03 14:36:11,662:INFO:Declaring metric variables
2023-06-03 14:36:11,665:INFO:Importing untrained model
2023-06-03 14:36:11,670:INFO:Dummy Classifier Imported successfully
2023-06-03 14:36:11,675:INFO:Starting cross validation
2023-06-03 14:36:11,676:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:11,749:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:11,756:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:11,760:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:11,764:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:11,769:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:11,786:INFO:Calculating mean and std
2023-06-03 14:36:11,789:INFO:Creating metrics dataframe
2023-06-03 14:36:11,812:INFO:Uploading results into container
2023-06-03 14:36:11,812:INFO:Uploading model into container now
2023-06-03 14:36:11,812:INFO:_master_model_container: 42
2023-06-03 14:36:11,812:INFO:_display_container: 4
2023-06-03 14:36:11,813:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:36:11,813:INFO:create_model() successfully completed......................................
2023-06-03 14:36:11,897:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:11,897:INFO:Creating metrics dataframe
2023-06-03 14:36:11,916:INFO:Initializing create_model()
2023-06-03 14:36:11,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:11,916:INFO:Checking exceptions
2023-06-03 14:36:11,917:INFO:Importing libraries
2023-06-03 14:36:11,917:INFO:Copying training dataset
2023-06-03 14:36:11,921:INFO:Defining folds
2023-06-03 14:36:11,921:INFO:Declaring metric variables
2023-06-03 14:36:11,922:INFO:Importing untrained model
2023-06-03 14:36:11,922:INFO:Declaring custom model
2023-06-03 14:36:11,922:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:36:11,923:INFO:Cross validation set to False
2023-06-03 14:36:11,923:INFO:Fitting Model
2023-06-03 14:36:12,458:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:12,458:INFO:create_model() successfully completed......................................
2023-06-03 14:36:12,564:INFO:_master_model_container: 42
2023-06-03 14:36:12,564:INFO:_display_container: 4
2023-06-03 14:36:12,565:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:12,565:INFO:compare_models() successfully completed......................................
2023-06-03 14:36:17,936:INFO:Initializing compare_models()
2023-06-03 14:36:17,936:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, include=None, fold=5, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:36:17,936:INFO:Checking exceptions
2023-06-03 14:36:17,943:INFO:Preparing display monitor
2023-06-03 14:36:17,985:INFO:Initializing Logistic Regression
2023-06-03 14:36:17,985:INFO:Total runtime is 4.633267720540365e-06 minutes
2023-06-03 14:36:17,991:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:17,991:INFO:Initializing create_model()
2023-06-03 14:36:17,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:17,992:INFO:Checking exceptions
2023-06-03 14:36:17,992:INFO:Importing libraries
2023-06-03 14:36:17,992:INFO:Copying training dataset
2023-06-03 14:36:17,998:INFO:Defining folds
2023-06-03 14:36:17,998:INFO:Declaring metric variables
2023-06-03 14:36:18,002:INFO:Importing untrained model
2023-06-03 14:36:18,006:INFO:Logistic Regression Imported successfully
2023-06-03 14:36:18,013:INFO:Starting cross validation
2023-06-03 14:36:18,014:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:18,128:INFO:Calculating mean and std
2023-06-03 14:36:18,129:INFO:Creating metrics dataframe
2023-06-03 14:36:18,157:INFO:Uploading results into container
2023-06-03 14:36:18,158:INFO:Uploading model into container now
2023-06-03 14:36:18,158:INFO:_master_model_container: 43
2023-06-03 14:36:18,158:INFO:_display_container: 5
2023-06-03 14:36:18,158:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:36:18,158:INFO:create_model() successfully completed......................................
2023-06-03 14:36:18,249:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:18,249:INFO:Creating metrics dataframe
2023-06-03 14:36:18,257:INFO:Initializing K Neighbors Classifier
2023-06-03 14:36:18,257:INFO:Total runtime is 0.004534236590067546 minutes
2023-06-03 14:36:18,260:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:18,261:INFO:Initializing create_model()
2023-06-03 14:36:18,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:18,261:INFO:Checking exceptions
2023-06-03 14:36:18,261:INFO:Importing libraries
2023-06-03 14:36:18,261:INFO:Copying training dataset
2023-06-03 14:36:18,271:INFO:Defining folds
2023-06-03 14:36:18,272:INFO:Declaring metric variables
2023-06-03 14:36:18,276:INFO:Importing untrained model
2023-06-03 14:36:18,281:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:36:18,287:INFO:Starting cross validation
2023-06-03 14:36:18,288:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:18,501:INFO:Calculating mean and std
2023-06-03 14:36:18,501:INFO:Creating metrics dataframe
2023-06-03 14:36:18,525:INFO:Uploading results into container
2023-06-03 14:36:18,525:INFO:Uploading model into container now
2023-06-03 14:36:18,526:INFO:_master_model_container: 44
2023-06-03 14:36:18,526:INFO:_display_container: 5
2023-06-03 14:36:18,526:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:36:18,526:INFO:create_model() successfully completed......................................
2023-06-03 14:36:18,610:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:18,611:INFO:Creating metrics dataframe
2023-06-03 14:36:18,618:INFO:Initializing Naive Bayes
2023-06-03 14:36:18,618:INFO:Total runtime is 0.010552696386973063 minutes
2023-06-03 14:36:18,621:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:18,621:INFO:Initializing create_model()
2023-06-03 14:36:18,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:18,621:INFO:Checking exceptions
2023-06-03 14:36:18,621:INFO:Importing libraries
2023-06-03 14:36:18,621:INFO:Copying training dataset
2023-06-03 14:36:18,625:INFO:Defining folds
2023-06-03 14:36:18,625:INFO:Declaring metric variables
2023-06-03 14:36:18,628:INFO:Importing untrained model
2023-06-03 14:36:18,630:INFO:Naive Bayes Imported successfully
2023-06-03 14:36:18,635:INFO:Starting cross validation
2023-06-03 14:36:18,636:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:18,730:INFO:Calculating mean and std
2023-06-03 14:36:18,731:INFO:Creating metrics dataframe
2023-06-03 14:36:18,753:INFO:Uploading results into container
2023-06-03 14:36:18,753:INFO:Uploading model into container now
2023-06-03 14:36:18,753:INFO:_master_model_container: 45
2023-06-03 14:36:18,754:INFO:_display_container: 5
2023-06-03 14:36:18,754:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:36:18,754:INFO:create_model() successfully completed......................................
2023-06-03 14:36:18,840:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:18,840:INFO:Creating metrics dataframe
2023-06-03 14:36:18,848:INFO:Initializing Decision Tree Classifier
2023-06-03 14:36:18,848:INFO:Total runtime is 0.014383061726888021 minutes
2023-06-03 14:36:18,851:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:18,851:INFO:Initializing create_model()
2023-06-03 14:36:18,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:18,851:INFO:Checking exceptions
2023-06-03 14:36:18,852:INFO:Importing libraries
2023-06-03 14:36:18,852:INFO:Copying training dataset
2023-06-03 14:36:18,855:INFO:Defining folds
2023-06-03 14:36:18,855:INFO:Declaring metric variables
2023-06-03 14:36:18,858:INFO:Importing untrained model
2023-06-03 14:36:18,861:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:36:18,867:INFO:Starting cross validation
2023-06-03 14:36:18,867:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:19,008:INFO:Calculating mean and std
2023-06-03 14:36:19,010:INFO:Creating metrics dataframe
2023-06-03 14:36:19,040:INFO:Uploading results into container
2023-06-03 14:36:19,041:INFO:Uploading model into container now
2023-06-03 14:36:19,041:INFO:_master_model_container: 46
2023-06-03 14:36:19,041:INFO:_display_container: 5
2023-06-03 14:36:19,042:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:36:19,042:INFO:create_model() successfully completed......................................
2023-06-03 14:36:19,127:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:19,127:INFO:Creating metrics dataframe
2023-06-03 14:36:19,136:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:36:19,136:INFO:Total runtime is 0.01918221314748128 minutes
2023-06-03 14:36:19,139:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:19,139:INFO:Initializing create_model()
2023-06-03 14:36:19,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:19,139:INFO:Checking exceptions
2023-06-03 14:36:19,139:INFO:Importing libraries
2023-06-03 14:36:19,139:INFO:Copying training dataset
2023-06-03 14:36:19,144:INFO:Defining folds
2023-06-03 14:36:19,144:INFO:Declaring metric variables
2023-06-03 14:36:19,147:INFO:Importing untrained model
2023-06-03 14:36:19,150:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:36:19,155:INFO:Starting cross validation
2023-06-03 14:36:19,156:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:19,202:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:19,206:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:19,208:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:19,211:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:19,217:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:19,219:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:19,220:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:19,222:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:19,226:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:36:19,230:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:19,246:INFO:Calculating mean and std
2023-06-03 14:36:19,247:INFO:Creating metrics dataframe
2023-06-03 14:36:19,271:INFO:Uploading results into container
2023-06-03 14:36:19,271:INFO:Uploading model into container now
2023-06-03 14:36:19,272:INFO:_master_model_container: 47
2023-06-03 14:36:19,272:INFO:_display_container: 5
2023-06-03 14:36:19,273:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:36:19,273:INFO:create_model() successfully completed......................................
2023-06-03 14:36:19,363:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:19,364:INFO:Creating metrics dataframe
2023-06-03 14:36:19,372:INFO:Initializing Ridge Classifier
2023-06-03 14:36:19,372:INFO:Total runtime is 0.023114887873331703 minutes
2023-06-03 14:36:19,375:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:19,376:INFO:Initializing create_model()
2023-06-03 14:36:19,376:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:19,376:INFO:Checking exceptions
2023-06-03 14:36:19,376:INFO:Importing libraries
2023-06-03 14:36:19,376:INFO:Copying training dataset
2023-06-03 14:36:19,386:INFO:Defining folds
2023-06-03 14:36:19,387:INFO:Declaring metric variables
2023-06-03 14:36:19,392:INFO:Importing untrained model
2023-06-03 14:36:19,396:INFO:Ridge Classifier Imported successfully
2023-06-03 14:36:19,406:INFO:Starting cross validation
2023-06-03 14:36:19,408:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:19,472:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:19,481:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:19,484:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:19,486:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:19,493:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:36:19,514:INFO:Calculating mean and std
2023-06-03 14:36:19,517:INFO:Creating metrics dataframe
2023-06-03 14:36:19,547:INFO:Uploading results into container
2023-06-03 14:36:19,548:INFO:Uploading model into container now
2023-06-03 14:36:19,548:INFO:_master_model_container: 48
2023-06-03 14:36:19,548:INFO:_display_container: 5
2023-06-03 14:36:19,549:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:36:19,549:INFO:create_model() successfully completed......................................
2023-06-03 14:36:19,640:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:19,640:INFO:Creating metrics dataframe
2023-06-03 14:36:19,649:INFO:Initializing Random Forest Classifier
2023-06-03 14:36:19,649:INFO:Total runtime is 0.02772911787033081 minutes
2023-06-03 14:36:19,651:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:19,652:INFO:Initializing create_model()
2023-06-03 14:36:19,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:19,652:INFO:Checking exceptions
2023-06-03 14:36:19,652:INFO:Importing libraries
2023-06-03 14:36:19,652:INFO:Copying training dataset
2023-06-03 14:36:19,656:INFO:Defining folds
2023-06-03 14:36:19,656:INFO:Declaring metric variables
2023-06-03 14:36:19,659:INFO:Importing untrained model
2023-06-03 14:36:19,662:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:36:19,667:INFO:Starting cross validation
2023-06-03 14:36:19,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:20,047:INFO:Calculating mean and std
2023-06-03 14:36:20,048:INFO:Creating metrics dataframe
2023-06-03 14:36:20,079:INFO:Uploading results into container
2023-06-03 14:36:20,079:INFO:Uploading model into container now
2023-06-03 14:36:20,080:INFO:_master_model_container: 49
2023-06-03 14:36:20,080:INFO:_display_container: 5
2023-06-03 14:36:20,080:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:20,080:INFO:create_model() successfully completed......................................
2023-06-03 14:36:20,165:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:20,165:INFO:Creating metrics dataframe
2023-06-03 14:36:20,173:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:36:20,174:INFO:Total runtime is 0.03647640546162923 minutes
2023-06-03 14:36:20,176:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:20,177:INFO:Initializing create_model()
2023-06-03 14:36:20,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:20,177:INFO:Checking exceptions
2023-06-03 14:36:20,177:INFO:Importing libraries
2023-06-03 14:36:20,177:INFO:Copying training dataset
2023-06-03 14:36:20,181:INFO:Defining folds
2023-06-03 14:36:20,181:INFO:Declaring metric variables
2023-06-03 14:36:20,184:INFO:Importing untrained model
2023-06-03 14:36:20,186:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:36:20,191:INFO:Starting cross validation
2023-06-03 14:36:20,191:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:20,289:INFO:Calculating mean and std
2023-06-03 14:36:20,290:INFO:Creating metrics dataframe
2023-06-03 14:36:20,313:INFO:Uploading results into container
2023-06-03 14:36:20,313:INFO:Uploading model into container now
2023-06-03 14:36:20,313:INFO:_master_model_container: 50
2023-06-03 14:36:20,313:INFO:_display_container: 5
2023-06-03 14:36:20,314:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:36:20,314:INFO:create_model() successfully completed......................................
2023-06-03 14:36:20,403:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:20,403:INFO:Creating metrics dataframe
2023-06-03 14:36:20,412:INFO:Initializing Ada Boost Classifier
2023-06-03 14:36:20,412:INFO:Total runtime is 0.04044481913248698 minutes
2023-06-03 14:36:20,414:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:20,415:INFO:Initializing create_model()
2023-06-03 14:36:20,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:20,415:INFO:Checking exceptions
2023-06-03 14:36:20,415:INFO:Importing libraries
2023-06-03 14:36:20,415:INFO:Copying training dataset
2023-06-03 14:36:20,419:INFO:Defining folds
2023-06-03 14:36:20,419:INFO:Declaring metric variables
2023-06-03 14:36:20,422:INFO:Importing untrained model
2023-06-03 14:36:20,424:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:36:20,429:INFO:Starting cross validation
2023-06-03 14:36:20,430:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:20,605:INFO:Calculating mean and std
2023-06-03 14:36:20,606:INFO:Creating metrics dataframe
2023-06-03 14:36:20,630:INFO:Uploading results into container
2023-06-03 14:36:20,630:INFO:Uploading model into container now
2023-06-03 14:36:20,631:INFO:_master_model_container: 51
2023-06-03 14:36:20,631:INFO:_display_container: 5
2023-06-03 14:36:20,631:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:36:20,631:INFO:create_model() successfully completed......................................
2023-06-03 14:36:20,720:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:20,720:INFO:Creating metrics dataframe
2023-06-03 14:36:20,729:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:36:20,729:INFO:Total runtime is 0.04572810331980388 minutes
2023-06-03 14:36:20,731:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:20,732:INFO:Initializing create_model()
2023-06-03 14:36:20,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:20,732:INFO:Checking exceptions
2023-06-03 14:36:20,732:INFO:Importing libraries
2023-06-03 14:36:20,732:INFO:Copying training dataset
2023-06-03 14:36:20,736:INFO:Defining folds
2023-06-03 14:36:20,736:INFO:Declaring metric variables
2023-06-03 14:36:20,739:INFO:Importing untrained model
2023-06-03 14:36:20,741:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:36:20,751:INFO:Starting cross validation
2023-06-03 14:36:20,751:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:21,119:INFO:Calculating mean and std
2023-06-03 14:36:21,120:INFO:Creating metrics dataframe
2023-06-03 14:36:21,150:INFO:Uploading results into container
2023-06-03 14:36:21,151:INFO:Uploading model into container now
2023-06-03 14:36:21,151:INFO:_master_model_container: 52
2023-06-03 14:36:21,151:INFO:_display_container: 5
2023-06-03 14:36:21,152:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:36:21,152:INFO:create_model() successfully completed......................................
2023-06-03 14:36:21,247:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:21,247:INFO:Creating metrics dataframe
2023-06-03 14:36:21,260:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:36:21,260:INFO:Total runtime is 0.0545883854230245 minutes
2023-06-03 14:36:21,264:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:21,264:INFO:Initializing create_model()
2023-06-03 14:36:21,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:21,264:INFO:Checking exceptions
2023-06-03 14:36:21,264:INFO:Importing libraries
2023-06-03 14:36:21,264:INFO:Copying training dataset
2023-06-03 14:36:21,269:INFO:Defining folds
2023-06-03 14:36:21,270:INFO:Declaring metric variables
2023-06-03 14:36:21,273:INFO:Importing untrained model
2023-06-03 14:36:21,276:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:36:21,282:INFO:Starting cross validation
2023-06-03 14:36:21,283:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:21,406:INFO:Calculating mean and std
2023-06-03 14:36:21,409:INFO:Creating metrics dataframe
2023-06-03 14:36:21,435:INFO:Uploading results into container
2023-06-03 14:36:21,435:INFO:Uploading model into container now
2023-06-03 14:36:21,435:INFO:_master_model_container: 53
2023-06-03 14:36:21,435:INFO:_display_container: 5
2023-06-03 14:36:21,436:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:36:21,436:INFO:create_model() successfully completed......................................
2023-06-03 14:36:21,524:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:21,524:INFO:Creating metrics dataframe
2023-06-03 14:36:21,534:INFO:Initializing Extra Trees Classifier
2023-06-03 14:36:21,534:INFO:Total runtime is 0.05914719104766846 minutes
2023-06-03 14:36:21,536:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:21,537:INFO:Initializing create_model()
2023-06-03 14:36:21,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:21,537:INFO:Checking exceptions
2023-06-03 14:36:21,537:INFO:Importing libraries
2023-06-03 14:36:21,537:INFO:Copying training dataset
2023-06-03 14:36:21,541:INFO:Defining folds
2023-06-03 14:36:21,541:INFO:Declaring metric variables
2023-06-03 14:36:21,544:INFO:Importing untrained model
2023-06-03 14:36:21,546:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:36:21,551:INFO:Starting cross validation
2023-06-03 14:36:21,552:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:22,033:INFO:Calculating mean and std
2023-06-03 14:36:22,035:INFO:Creating metrics dataframe
2023-06-03 14:36:22,063:INFO:Uploading results into container
2023-06-03 14:36:22,064:INFO:Uploading model into container now
2023-06-03 14:36:22,064:INFO:_master_model_container: 54
2023-06-03 14:36:22,064:INFO:_display_container: 5
2023-06-03 14:36:22,065:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:22,065:INFO:create_model() successfully completed......................................
2023-06-03 14:36:22,150:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:22,150:INFO:Creating metrics dataframe
2023-06-03 14:36:22,159:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:36:22,160:INFO:Total runtime is 0.0695771098136902 minutes
2023-06-03 14:36:22,163:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:22,163:INFO:Initializing create_model()
2023-06-03 14:36:22,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:22,163:INFO:Checking exceptions
2023-06-03 14:36:22,163:INFO:Importing libraries
2023-06-03 14:36:22,163:INFO:Copying training dataset
2023-06-03 14:36:22,167:INFO:Defining folds
2023-06-03 14:36:22,168:INFO:Declaring metric variables
2023-06-03 14:36:22,171:INFO:Importing untrained model
2023-06-03 14:36:22,174:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:36:22,180:INFO:Starting cross validation
2023-06-03 14:36:22,180:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:22,488:INFO:Calculating mean and std
2023-06-03 14:36:22,489:INFO:Creating metrics dataframe
2023-06-03 14:36:22,509:INFO:Uploading results into container
2023-06-03 14:36:22,509:INFO:Uploading model into container now
2023-06-03 14:36:22,510:INFO:_master_model_container: 55
2023-06-03 14:36:22,510:INFO:_display_container: 5
2023-06-03 14:36:22,510:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:36:22,510:INFO:create_model() successfully completed......................................
2023-06-03 14:36:22,595:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:22,595:INFO:Creating metrics dataframe
2023-06-03 14:36:22,605:INFO:Initializing Dummy Classifier
2023-06-03 14:36:22,605:INFO:Total runtime is 0.07700081268946331 minutes
2023-06-03 14:36:22,611:INFO:SubProcess create_model() called ==================================
2023-06-03 14:36:22,612:INFO:Initializing create_model()
2023-06-03 14:36:22,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6da1ee0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:22,612:INFO:Checking exceptions
2023-06-03 14:36:22,612:INFO:Importing libraries
2023-06-03 14:36:22,612:INFO:Copying training dataset
2023-06-03 14:36:22,622:INFO:Defining folds
2023-06-03 14:36:22,622:INFO:Declaring metric variables
2023-06-03 14:36:22,626:INFO:Importing untrained model
2023-06-03 14:36:22,630:INFO:Dummy Classifier Imported successfully
2023-06-03 14:36:22,637:INFO:Starting cross validation
2023-06-03 14:36:22,638:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:36:22,692:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:22,698:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:22,699:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:22,720:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:22,722:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:36:22,740:INFO:Calculating mean and std
2023-06-03 14:36:22,742:INFO:Creating metrics dataframe
2023-06-03 14:36:22,777:INFO:Uploading results into container
2023-06-03 14:36:22,777:INFO:Uploading model into container now
2023-06-03 14:36:22,778:INFO:_master_model_container: 56
2023-06-03 14:36:22,778:INFO:_display_container: 5
2023-06-03 14:36:22,778:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:36:22,778:INFO:create_model() successfully completed......................................
2023-06-03 14:36:22,873:INFO:SubProcess create_model() end ==================================
2023-06-03 14:36:22,873:INFO:Creating metrics dataframe
2023-06-03 14:36:22,892:INFO:Initializing create_model()
2023-06-03 14:36:22,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:22,892:INFO:Checking exceptions
2023-06-03 14:36:22,893:INFO:Importing libraries
2023-06-03 14:36:22,893:INFO:Copying training dataset
2023-06-03 14:36:22,897:INFO:Defining folds
2023-06-03 14:36:22,897:INFO:Declaring metric variables
2023-06-03 14:36:22,897:INFO:Importing untrained model
2023-06-03 14:36:22,897:INFO:Declaring custom model
2023-06-03 14:36:22,898:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:36:22,898:INFO:Cross validation set to False
2023-06-03 14:36:22,898:INFO:Fitting Model
2023-06-03 14:36:22,968:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:22,968:INFO:create_model() successfully completed......................................
2023-06-03 14:36:23,058:INFO:Initializing create_model()
2023-06-03 14:36:23,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:23,059:INFO:Checking exceptions
2023-06-03 14:36:23,060:INFO:Importing libraries
2023-06-03 14:36:23,060:INFO:Copying training dataset
2023-06-03 14:36:23,064:INFO:Defining folds
2023-06-03 14:36:23,064:INFO:Declaring metric variables
2023-06-03 14:36:23,064:INFO:Importing untrained model
2023-06-03 14:36:23,064:INFO:Declaring custom model
2023-06-03 14:36:23,065:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:36:23,065:INFO:Cross validation set to False
2023-06-03 14:36:23,065:INFO:Fitting Model
2023-06-03 14:36:23,245:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:36:23,245:INFO:create_model() successfully completed......................................
2023-06-03 14:36:23,334:INFO:Initializing create_model()
2023-06-03 14:36:23,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:23,335:INFO:Checking exceptions
2023-06-03 14:36:23,336:INFO:Importing libraries
2023-06-03 14:36:23,336:INFO:Copying training dataset
2023-06-03 14:36:23,340:INFO:Defining folds
2023-06-03 14:36:23,340:INFO:Declaring metric variables
2023-06-03 14:36:23,340:INFO:Importing untrained model
2023-06-03 14:36:23,340:INFO:Declaring custom model
2023-06-03 14:36:23,340:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:36:23,341:INFO:Cross validation set to False
2023-06-03 14:36:23,341:INFO:Fitting Model
2023-06-03 14:36:27,742:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:36:27,742:INFO:create_model() successfully completed......................................
2023-06-03 14:36:27,836:INFO:Initializing create_model()
2023-06-03 14:36:27,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:27,836:INFO:Checking exceptions
2023-06-03 14:36:27,839:INFO:Importing libraries
2023-06-03 14:36:27,840:INFO:Copying training dataset
2023-06-03 14:36:27,848:INFO:Defining folds
2023-06-03 14:36:27,848:INFO:Declaring metric variables
2023-06-03 14:36:27,848:INFO:Importing untrained model
2023-06-03 14:36:27,848:INFO:Declaring custom model
2023-06-03 14:36:27,849:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:36:27,850:INFO:Cross validation set to False
2023-06-03 14:36:27,850:INFO:Fitting Model
2023-06-03 14:36:28,401:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:36:28,401:INFO:create_model() successfully completed......................................
2023-06-03 14:36:28,490:INFO:Initializing create_model()
2023-06-03 14:36:28,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b7c54fee0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:36:28,490:INFO:Checking exceptions
2023-06-03 14:36:28,491:INFO:Importing libraries
2023-06-03 14:36:28,491:INFO:Copying training dataset
2023-06-03 14:36:28,496:INFO:Defining folds
2023-06-03 14:36:28,496:INFO:Declaring metric variables
2023-06-03 14:36:28,496:INFO:Importing untrained model
2023-06-03 14:36:28,496:INFO:Declaring custom model
2023-06-03 14:36:28,496:INFO:Logistic Regression Imported successfully
2023-06-03 14:36:28,497:INFO:Cross validation set to False
2023-06-03 14:36:28,497:INFO:Fitting Model
2023-06-03 14:36:29,465:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:36:29,478:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:36:29,479:INFO:create_model() successfully completed......................................
2023-06-03 14:36:29,585:INFO:_master_model_container: 56
2023-06-03 14:36:29,586:INFO:_display_container: 5
2023-06-03 14:36:29,589:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2023-06-03 14:36:29,589:INFO:compare_models() successfully completed......................................
2023-06-03 14:43:39,907:INFO:PyCaret ClassificationExperiment
2023-06-03 14:43:39,907:INFO:Logging name: clf-default-name
2023-06-03 14:43:39,907:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:43:39,907:INFO:version 3.0.2
2023-06-03 14:43:39,907:INFO:Initializing setup()
2023-06-03 14:43:39,907:INFO:self.USI: 657c
2023-06-03 14:43:39,907:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:43:39,907:INFO:Checking environment
2023-06-03 14:43:39,907:INFO:python_version: 3.8.16
2023-06-03 14:43:39,907:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:43:39,907:INFO:machine: x86_64
2023-06-03 14:43:39,907:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:43:39,908:INFO:Memory: svmem(total=134737395712, available=91399274496, percent=32.2, used=41912557568, free=4501078016, active=29267034112, inactive=91401879552, buffers=2420281344, cached=85903478784, shared=28483584, slab=4875411456)
2023-06-03 14:43:39,909:INFO:Physical Core: 10
2023-06-03 14:43:39,909:INFO:Logical Core: 20
2023-06-03 14:43:39,909:INFO:Checking libraries
2023-06-03 14:43:39,909:INFO:System:
2023-06-03 14:43:39,909:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:43:39,909:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:43:39,909:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:43:39,909:INFO:PyCaret required dependencies:
2023-06-03 14:43:39,909:INFO:                 pip: 23.0.1
2023-06-03 14:43:39,909:INFO:          setuptools: 67.8.0
2023-06-03 14:43:39,910:INFO:             pycaret: 3.0.2
2023-06-03 14:43:39,910:INFO:             IPython: 8.12.2
2023-06-03 14:43:39,910:INFO:          ipywidgets: 8.0.6
2023-06-03 14:43:39,910:INFO:                tqdm: 4.65.0
2023-06-03 14:43:39,910:INFO:               numpy: 1.23.5
2023-06-03 14:43:39,910:INFO:              pandas: 1.5.3
2023-06-03 14:43:39,910:INFO:              jinja2: 3.1.2
2023-06-03 14:43:39,910:INFO:               scipy: 1.10.1
2023-06-03 14:43:39,910:INFO:              joblib: 1.2.0
2023-06-03 14:43:39,910:INFO:             sklearn: 1.2.2
2023-06-03 14:43:39,910:INFO:                pyod: 1.0.9
2023-06-03 14:43:39,910:INFO:            imblearn: 0.10.1
2023-06-03 14:43:39,910:INFO:   category_encoders: 2.6.1
2023-06-03 14:43:39,910:INFO:            lightgbm: 3.3.5
2023-06-03 14:43:39,910:INFO:               numba: 0.57.0
2023-06-03 14:43:39,910:INFO:            requests: 2.31.0
2023-06-03 14:43:39,910:INFO:          matplotlib: 3.7.1
2023-06-03 14:43:39,910:INFO:          scikitplot: 0.3.7
2023-06-03 14:43:39,910:INFO:         yellowbrick: 1.5
2023-06-03 14:43:39,910:INFO:              plotly: 5.14.1
2023-06-03 14:43:39,910:INFO:             kaleido: 0.2.1
2023-06-03 14:43:39,910:INFO:         statsmodels: 0.14.0
2023-06-03 14:43:39,910:INFO:              sktime: 0.17.0
2023-06-03 14:43:39,910:INFO:               tbats: 1.1.3
2023-06-03 14:43:39,910:INFO:            pmdarima: 2.0.3
2023-06-03 14:43:39,910:INFO:              psutil: 5.9.5
2023-06-03 14:43:39,910:INFO:PyCaret optional dependencies:
2023-06-03 14:43:39,911:INFO:                shap: Not installed
2023-06-03 14:43:39,911:INFO:           interpret: Not installed
2023-06-03 14:43:39,911:INFO:                umap: Not installed
2023-06-03 14:43:39,911:INFO:    pandas_profiling: Not installed
2023-06-03 14:43:39,911:INFO:  explainerdashboard: Not installed
2023-06-03 14:43:39,911:INFO:             autoviz: Not installed
2023-06-03 14:43:39,911:INFO:           fairlearn: Not installed
2023-06-03 14:43:39,911:INFO:             xgboost: Not installed
2023-06-03 14:43:39,911:INFO:            catboost: Not installed
2023-06-03 14:43:39,911:INFO:              kmodes: Not installed
2023-06-03 14:43:39,911:INFO:             mlxtend: Not installed
2023-06-03 14:43:39,911:INFO:       statsforecast: Not installed
2023-06-03 14:43:39,911:INFO:        tune_sklearn: Not installed
2023-06-03 14:43:39,911:INFO:                 ray: Not installed
2023-06-03 14:43:39,911:INFO:            hyperopt: Not installed
2023-06-03 14:43:39,911:INFO:              optuna: Not installed
2023-06-03 14:43:39,911:INFO:               skopt: Not installed
2023-06-03 14:43:39,911:INFO:              mlflow: Not installed
2023-06-03 14:43:39,911:INFO:              gradio: Not installed
2023-06-03 14:43:39,911:INFO:             fastapi: Not installed
2023-06-03 14:43:39,911:INFO:             uvicorn: Not installed
2023-06-03 14:43:39,911:INFO:              m2cgen: Not installed
2023-06-03 14:43:39,911:INFO:           evidently: Not installed
2023-06-03 14:43:39,911:INFO:               fugue: Not installed
2023-06-03 14:43:39,911:INFO:           streamlit: Not installed
2023-06-03 14:43:39,911:INFO:             prophet: Not installed
2023-06-03 14:43:39,911:INFO:None
2023-06-03 14:43:39,911:INFO:Set up data.
2023-06-03 14:43:39,921:INFO:Set up train/test split.
2023-06-03 14:43:39,930:INFO:Set up index.
2023-06-03 14:43:39,930:INFO:Set up folding strategy.
2023-06-03 14:43:39,930:INFO:Assigning column types.
2023-06-03 14:43:39,939:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:43:39,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:43:39,978:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:39,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:39,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:43:40,025:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:40,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,043:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:43:40,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:40,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,118:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:40,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,135:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:43:40,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,227:INFO:Preparing preprocessing pipeline...
2023-06-03 14:43:40,228:INFO:Set up simple imputation.
2023-06-03 14:43:40,228:INFO:Set up feature normalization.
2023-06-03 14:43:40,243:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:43:40,247:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-06-03 14:43:40,247:INFO:Creating final display dataframe.
2023-06-03 14:43:40,304:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              657c
2023-06-03 14:43:40,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:40,415:INFO:setup() successfully completed in 0.53s...............
2023-06-03 14:43:47,110:INFO:PyCaret ClassificationExperiment
2023-06-03 14:43:47,110:INFO:Logging name: clf-default-name
2023-06-03 14:43:47,110:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:43:47,110:INFO:version 3.0.2
2023-06-03 14:43:47,110:INFO:Initializing setup()
2023-06-03 14:43:47,110:INFO:self.USI: d772
2023-06-03 14:43:47,110:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:43:47,110:INFO:Checking environment
2023-06-03 14:43:47,110:INFO:python_version: 3.8.16
2023-06-03 14:43:47,110:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:43:47,110:INFO:machine: x86_64
2023-06-03 14:43:47,110:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:43:47,110:INFO:Memory: svmem(total=134737395712, available=91419480064, percent=32.1, used=41892352000, free=4521267200, active=29267034112, inactive=91409104896, buffers=2420285440, cached=85903491072, shared=28483584, slab=4875366400)
2023-06-03 14:43:47,111:INFO:Physical Core: 10
2023-06-03 14:43:47,111:INFO:Logical Core: 20
2023-06-03 14:43:47,111:INFO:Checking libraries
2023-06-03 14:43:47,111:INFO:System:
2023-06-03 14:43:47,111:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:43:47,111:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:43:47,111:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:43:47,111:INFO:PyCaret required dependencies:
2023-06-03 14:43:47,111:INFO:                 pip: 23.0.1
2023-06-03 14:43:47,111:INFO:          setuptools: 67.8.0
2023-06-03 14:43:47,111:INFO:             pycaret: 3.0.2
2023-06-03 14:43:47,111:INFO:             IPython: 8.12.2
2023-06-03 14:43:47,111:INFO:          ipywidgets: 8.0.6
2023-06-03 14:43:47,112:INFO:                tqdm: 4.65.0
2023-06-03 14:43:47,112:INFO:               numpy: 1.23.5
2023-06-03 14:43:47,112:INFO:              pandas: 1.5.3
2023-06-03 14:43:47,112:INFO:              jinja2: 3.1.2
2023-06-03 14:43:47,112:INFO:               scipy: 1.10.1
2023-06-03 14:43:47,112:INFO:              joblib: 1.2.0
2023-06-03 14:43:47,112:INFO:             sklearn: 1.2.2
2023-06-03 14:43:47,112:INFO:                pyod: 1.0.9
2023-06-03 14:43:47,112:INFO:            imblearn: 0.10.1
2023-06-03 14:43:47,112:INFO:   category_encoders: 2.6.1
2023-06-03 14:43:47,112:INFO:            lightgbm: 3.3.5
2023-06-03 14:43:47,112:INFO:               numba: 0.57.0
2023-06-03 14:43:47,112:INFO:            requests: 2.31.0
2023-06-03 14:43:47,112:INFO:          matplotlib: 3.7.1
2023-06-03 14:43:47,112:INFO:          scikitplot: 0.3.7
2023-06-03 14:43:47,112:INFO:         yellowbrick: 1.5
2023-06-03 14:43:47,112:INFO:              plotly: 5.14.1
2023-06-03 14:43:47,112:INFO:             kaleido: 0.2.1
2023-06-03 14:43:47,112:INFO:         statsmodels: 0.14.0
2023-06-03 14:43:47,112:INFO:              sktime: 0.17.0
2023-06-03 14:43:47,112:INFO:               tbats: 1.1.3
2023-06-03 14:43:47,112:INFO:            pmdarima: 2.0.3
2023-06-03 14:43:47,112:INFO:              psutil: 5.9.5
2023-06-03 14:43:47,112:INFO:PyCaret optional dependencies:
2023-06-03 14:43:47,112:INFO:                shap: Not installed
2023-06-03 14:43:47,112:INFO:           interpret: Not installed
2023-06-03 14:43:47,112:INFO:                umap: Not installed
2023-06-03 14:43:47,112:INFO:    pandas_profiling: Not installed
2023-06-03 14:43:47,112:INFO:  explainerdashboard: Not installed
2023-06-03 14:43:47,112:INFO:             autoviz: Not installed
2023-06-03 14:43:47,112:INFO:           fairlearn: Not installed
2023-06-03 14:43:47,112:INFO:             xgboost: Not installed
2023-06-03 14:43:47,112:INFO:            catboost: Not installed
2023-06-03 14:43:47,112:INFO:              kmodes: Not installed
2023-06-03 14:43:47,112:INFO:             mlxtend: Not installed
2023-06-03 14:43:47,112:INFO:       statsforecast: Not installed
2023-06-03 14:43:47,112:INFO:        tune_sklearn: Not installed
2023-06-03 14:43:47,112:INFO:                 ray: Not installed
2023-06-03 14:43:47,112:INFO:            hyperopt: Not installed
2023-06-03 14:43:47,112:INFO:              optuna: Not installed
2023-06-03 14:43:47,113:INFO:               skopt: Not installed
2023-06-03 14:43:47,113:INFO:              mlflow: Not installed
2023-06-03 14:43:47,113:INFO:              gradio: Not installed
2023-06-03 14:43:47,113:INFO:             fastapi: Not installed
2023-06-03 14:43:47,113:INFO:             uvicorn: Not installed
2023-06-03 14:43:47,113:INFO:              m2cgen: Not installed
2023-06-03 14:43:47,113:INFO:           evidently: Not installed
2023-06-03 14:43:47,113:INFO:               fugue: Not installed
2023-06-03 14:43:47,113:INFO:           streamlit: Not installed
2023-06-03 14:43:47,113:INFO:             prophet: Not installed
2023-06-03 14:43:47,113:INFO:None
2023-06-03 14:43:47,113:INFO:Set up data.
2023-06-03 14:43:47,120:INFO:Set up train/test split.
2023-06-03 14:43:47,127:INFO:Set up index.
2023-06-03 14:43:47,127:INFO:Set up folding strategy.
2023-06-03 14:43:47,127:INFO:Assigning column types.
2023-06-03 14:43:47,131:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:43:47,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:43:47,163:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:47,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:43:47,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:47,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,235:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:43:47,265:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:47,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:47,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,336:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:43:47,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,439:INFO:Preparing preprocessing pipeline...
2023-06-03 14:43:47,440:INFO:Set up simple imputation.
2023-06-03 14:43:47,451:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:43:47,453:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-03 14:43:47,453:INFO:Creating final display dataframe.
2023-06-03 14:43:47,496:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d772
2023-06-03 14:43:47,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:47,617:INFO:setup() successfully completed in 0.52s...............
2023-06-03 14:43:49,823:INFO:PyCaret ClassificationExperiment
2023-06-03 14:43:49,823:INFO:Logging name: clf-default-name
2023-06-03 14:43:49,823:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:43:49,823:INFO:version 3.0.2
2023-06-03 14:43:49,823:INFO:Initializing setup()
2023-06-03 14:43:49,823:INFO:self.USI: d2d1
2023-06-03 14:43:49,823:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:43:49,823:INFO:Checking environment
2023-06-03 14:43:49,823:INFO:python_version: 3.8.16
2023-06-03 14:43:49,823:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:43:49,823:INFO:machine: x86_64
2023-06-03 14:43:49,823:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:43:49,824:INFO:Memory: svmem(total=134737395712, available=91412570112, percent=32.2, used=41899261952, free=4514308096, active=29267054592, inactive=91410399232, buffers=2420297728, cached=85903527936, shared=28483584, slab=4875350016)
2023-06-03 14:43:49,825:INFO:Physical Core: 10
2023-06-03 14:43:49,825:INFO:Logical Core: 20
2023-06-03 14:43:49,825:INFO:Checking libraries
2023-06-03 14:43:49,825:INFO:System:
2023-06-03 14:43:49,825:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:43:49,825:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:43:49,825:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:43:49,825:INFO:PyCaret required dependencies:
2023-06-03 14:43:49,825:INFO:                 pip: 23.0.1
2023-06-03 14:43:49,825:INFO:          setuptools: 67.8.0
2023-06-03 14:43:49,825:INFO:             pycaret: 3.0.2
2023-06-03 14:43:49,825:INFO:             IPython: 8.12.2
2023-06-03 14:43:49,826:INFO:          ipywidgets: 8.0.6
2023-06-03 14:43:49,826:INFO:                tqdm: 4.65.0
2023-06-03 14:43:49,826:INFO:               numpy: 1.23.5
2023-06-03 14:43:49,826:INFO:              pandas: 1.5.3
2023-06-03 14:43:49,826:INFO:              jinja2: 3.1.2
2023-06-03 14:43:49,826:INFO:               scipy: 1.10.1
2023-06-03 14:43:49,826:INFO:              joblib: 1.2.0
2023-06-03 14:43:49,826:INFO:             sklearn: 1.2.2
2023-06-03 14:43:49,826:INFO:                pyod: 1.0.9
2023-06-03 14:43:49,826:INFO:            imblearn: 0.10.1
2023-06-03 14:43:49,826:INFO:   category_encoders: 2.6.1
2023-06-03 14:43:49,826:INFO:            lightgbm: 3.3.5
2023-06-03 14:43:49,826:INFO:               numba: 0.57.0
2023-06-03 14:43:49,826:INFO:            requests: 2.31.0
2023-06-03 14:43:49,826:INFO:          matplotlib: 3.7.1
2023-06-03 14:43:49,826:INFO:          scikitplot: 0.3.7
2023-06-03 14:43:49,826:INFO:         yellowbrick: 1.5
2023-06-03 14:43:49,826:INFO:              plotly: 5.14.1
2023-06-03 14:43:49,826:INFO:             kaleido: 0.2.1
2023-06-03 14:43:49,826:INFO:         statsmodels: 0.14.0
2023-06-03 14:43:49,826:INFO:              sktime: 0.17.0
2023-06-03 14:43:49,826:INFO:               tbats: 1.1.3
2023-06-03 14:43:49,826:INFO:            pmdarima: 2.0.3
2023-06-03 14:43:49,826:INFO:              psutil: 5.9.5
2023-06-03 14:43:49,826:INFO:PyCaret optional dependencies:
2023-06-03 14:43:49,827:INFO:                shap: Not installed
2023-06-03 14:43:49,827:INFO:           interpret: Not installed
2023-06-03 14:43:49,827:INFO:                umap: Not installed
2023-06-03 14:43:49,827:INFO:    pandas_profiling: Not installed
2023-06-03 14:43:49,827:INFO:  explainerdashboard: Not installed
2023-06-03 14:43:49,827:INFO:             autoviz: Not installed
2023-06-03 14:43:49,827:INFO:           fairlearn: Not installed
2023-06-03 14:43:49,827:INFO:             xgboost: Not installed
2023-06-03 14:43:49,827:INFO:            catboost: Not installed
2023-06-03 14:43:49,827:INFO:              kmodes: Not installed
2023-06-03 14:43:49,827:INFO:             mlxtend: Not installed
2023-06-03 14:43:49,827:INFO:       statsforecast: Not installed
2023-06-03 14:43:49,827:INFO:        tune_sklearn: Not installed
2023-06-03 14:43:49,827:INFO:                 ray: Not installed
2023-06-03 14:43:49,827:INFO:            hyperopt: Not installed
2023-06-03 14:43:49,827:INFO:              optuna: Not installed
2023-06-03 14:43:49,827:INFO:               skopt: Not installed
2023-06-03 14:43:49,827:INFO:              mlflow: Not installed
2023-06-03 14:43:49,827:INFO:              gradio: Not installed
2023-06-03 14:43:49,827:INFO:             fastapi: Not installed
2023-06-03 14:43:49,827:INFO:             uvicorn: Not installed
2023-06-03 14:43:49,827:INFO:              m2cgen: Not installed
2023-06-03 14:43:49,827:INFO:           evidently: Not installed
2023-06-03 14:43:49,827:INFO:               fugue: Not installed
2023-06-03 14:43:49,827:INFO:           streamlit: Not installed
2023-06-03 14:43:49,827:INFO:             prophet: Not installed
2023-06-03 14:43:49,827:INFO:None
2023-06-03 14:43:49,827:INFO:Set up data.
2023-06-03 14:43:49,837:INFO:Set up train/test split.
2023-06-03 14:43:49,844:INFO:Set up index.
2023-06-03 14:43:49,844:INFO:Set up folding strategy.
2023-06-03 14:43:49,844:INFO:Assigning column types.
2023-06-03 14:43:49,848:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:43:49,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:43:49,880:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:49,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:49,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:49,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:43:49,932:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:49,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:49,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:49,952:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:43:49,983:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:50,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,035:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:43:50,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,055:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:43:50,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,158:INFO:Preparing preprocessing pipeline...
2023-06-03 14:43:50,159:INFO:Set up simple imputation.
2023-06-03 14:43:50,159:INFO:Set up feature normalization.
2023-06-03 14:43:50,175:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:43:50,178:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-06-03 14:43:50,178:INFO:Creating final display dataframe.
2023-06-03 14:43:50,236:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              d2d1
2023-06-03 14:43:50,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:50,346:INFO:setup() successfully completed in 0.54s...............
2023-06-03 14:43:52,139:INFO:gpu_param set to False
2023-06-03 14:43:52,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:52,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:52,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:52,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:43:54,350:INFO:Initializing compare_models()
2023-06-03 14:43:54,350:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, include=None, fold=5, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:43:54,351:INFO:Checking exceptions
2023-06-03 14:43:54,361:INFO:Preparing display monitor
2023-06-03 14:43:54,391:INFO:Initializing Logistic Regression
2023-06-03 14:43:54,391:INFO:Total runtime is 4.029273986816406e-06 minutes
2023-06-03 14:43:54,395:INFO:SubProcess create_model() called ==================================
2023-06-03 14:43:54,395:INFO:Initializing create_model()
2023-06-03 14:43:54,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:43:54,396:INFO:Checking exceptions
2023-06-03 14:43:54,396:INFO:Importing libraries
2023-06-03 14:43:54,396:INFO:Copying training dataset
2023-06-03 14:43:54,401:INFO:Defining folds
2023-06-03 14:43:54,401:INFO:Declaring metric variables
2023-06-03 14:43:54,404:INFO:Importing untrained model
2023-06-03 14:43:54,407:INFO:Logistic Regression Imported successfully
2023-06-03 14:43:54,413:INFO:Starting cross validation
2023-06-03 14:43:54,414:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:43:55,740:INFO:Calculating mean and std
2023-06-03 14:43:55,745:INFO:Creating metrics dataframe
2023-06-03 14:43:55,782:INFO:Uploading results into container
2023-06-03 14:43:55,783:INFO:Uploading model into container now
2023-06-03 14:43:55,783:INFO:_master_model_container: 1
2023-06-03 14:43:55,783:INFO:_display_container: 2
2023-06-03 14:43:55,784:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:43:55,784:INFO:create_model() successfully completed......................................
2023-06-03 14:43:55,909:INFO:SubProcess create_model() end ==================================
2023-06-03 14:43:55,909:INFO:Creating metrics dataframe
2023-06-03 14:43:55,916:INFO:Initializing K Neighbors Classifier
2023-06-03 14:43:55,917:INFO:Total runtime is 0.025425155957539875 minutes
2023-06-03 14:43:55,919:INFO:SubProcess create_model() called ==================================
2023-06-03 14:43:55,920:INFO:Initializing create_model()
2023-06-03 14:43:55,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:43:55,920:INFO:Checking exceptions
2023-06-03 14:43:55,920:INFO:Importing libraries
2023-06-03 14:43:55,920:INFO:Copying training dataset
2023-06-03 14:43:55,924:INFO:Defining folds
2023-06-03 14:43:55,925:INFO:Declaring metric variables
2023-06-03 14:43:55,927:INFO:Importing untrained model
2023-06-03 14:43:55,930:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:43:55,935:INFO:Starting cross validation
2023-06-03 14:43:55,936:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:43:56,916:INFO:Calculating mean and std
2023-06-03 14:43:56,917:INFO:Creating metrics dataframe
2023-06-03 14:43:56,948:INFO:Uploading results into container
2023-06-03 14:43:56,949:INFO:Uploading model into container now
2023-06-03 14:43:56,949:INFO:_master_model_container: 2
2023-06-03 14:43:56,949:INFO:_display_container: 2
2023-06-03 14:43:56,950:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:43:56,950:INFO:create_model() successfully completed......................................
2023-06-03 14:43:57,041:INFO:SubProcess create_model() end ==================================
2023-06-03 14:43:57,041:INFO:Creating metrics dataframe
2023-06-03 14:43:57,048:INFO:Initializing Naive Bayes
2023-06-03 14:43:57,049:INFO:Total runtime is 0.04429213603337606 minutes
2023-06-03 14:43:57,051:INFO:SubProcess create_model() called ==================================
2023-06-03 14:43:57,051:INFO:Initializing create_model()
2023-06-03 14:43:57,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:43:57,052:INFO:Checking exceptions
2023-06-03 14:43:57,052:INFO:Importing libraries
2023-06-03 14:43:57,052:INFO:Copying training dataset
2023-06-03 14:43:57,056:INFO:Defining folds
2023-06-03 14:43:57,056:INFO:Declaring metric variables
2023-06-03 14:43:57,059:INFO:Importing untrained model
2023-06-03 14:43:57,061:INFO:Naive Bayes Imported successfully
2023-06-03 14:43:57,066:INFO:Starting cross validation
2023-06-03 14:43:57,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:43:57,945:INFO:Calculating mean and std
2023-06-03 14:43:57,947:INFO:Creating metrics dataframe
2023-06-03 14:43:57,982:INFO:Uploading results into container
2023-06-03 14:43:57,983:INFO:Uploading model into container now
2023-06-03 14:43:57,984:INFO:_master_model_container: 3
2023-06-03 14:43:57,984:INFO:_display_container: 2
2023-06-03 14:43:57,984:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:43:57,984:INFO:create_model() successfully completed......................................
2023-06-03 14:43:58,070:INFO:SubProcess create_model() end ==================================
2023-06-03 14:43:58,071:INFO:Creating metrics dataframe
2023-06-03 14:43:58,079:INFO:Initializing Decision Tree Classifier
2023-06-03 14:43:58,079:INFO:Total runtime is 0.06146130959192912 minutes
2023-06-03 14:43:58,081:INFO:SubProcess create_model() called ==================================
2023-06-03 14:43:58,081:INFO:Initializing create_model()
2023-06-03 14:43:58,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:43:58,082:INFO:Checking exceptions
2023-06-03 14:43:58,082:INFO:Importing libraries
2023-06-03 14:43:58,082:INFO:Copying training dataset
2023-06-03 14:43:58,086:INFO:Defining folds
2023-06-03 14:43:58,086:INFO:Declaring metric variables
2023-06-03 14:43:58,089:INFO:Importing untrained model
2023-06-03 14:43:58,091:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:43:58,097:INFO:Starting cross validation
2023-06-03 14:43:58,098:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:43:59,031:INFO:Calculating mean and std
2023-06-03 14:43:59,034:INFO:Creating metrics dataframe
2023-06-03 14:43:59,067:INFO:Uploading results into container
2023-06-03 14:43:59,068:INFO:Uploading model into container now
2023-06-03 14:43:59,068:INFO:_master_model_container: 4
2023-06-03 14:43:59,068:INFO:_display_container: 2
2023-06-03 14:43:59,068:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:43:59,069:INFO:create_model() successfully completed......................................
2023-06-03 14:43:59,156:INFO:SubProcess create_model() end ==================================
2023-06-03 14:43:59,156:INFO:Creating metrics dataframe
2023-06-03 14:43:59,164:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:43:59,165:INFO:Total runtime is 0.07956039110819499 minutes
2023-06-03 14:43:59,167:INFO:SubProcess create_model() called ==================================
2023-06-03 14:43:59,168:INFO:Initializing create_model()
2023-06-03 14:43:59,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:43:59,168:INFO:Checking exceptions
2023-06-03 14:43:59,168:INFO:Importing libraries
2023-06-03 14:43:59,168:INFO:Copying training dataset
2023-06-03 14:43:59,172:INFO:Defining folds
2023-06-03 14:43:59,172:INFO:Declaring metric variables
2023-06-03 14:43:59,176:INFO:Importing untrained model
2023-06-03 14:43:59,179:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:43:59,185:INFO:Starting cross validation
2023-06-03 14:43:59,186:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:43:59,235:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:43:59,238:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:43:59,242:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:43:59,243:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:43:59,245:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:43:59,245:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:43:59,247:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:43:59,248:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:43:59,256:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:43:59,261:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:43:59,276:INFO:Calculating mean and std
2023-06-03 14:43:59,278:INFO:Creating metrics dataframe
2023-06-03 14:43:59,318:INFO:Uploading results into container
2023-06-03 14:43:59,319:INFO:Uploading model into container now
2023-06-03 14:43:59,319:INFO:_master_model_container: 5
2023-06-03 14:43:59,319:INFO:_display_container: 2
2023-06-03 14:43:59,320:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:43:59,321:INFO:create_model() successfully completed......................................
2023-06-03 14:43:59,412:INFO:SubProcess create_model() end ==================================
2023-06-03 14:43:59,412:INFO:Creating metrics dataframe
2023-06-03 14:43:59,421:INFO:Initializing Ridge Classifier
2023-06-03 14:43:59,421:INFO:Total runtime is 0.08383277654647828 minutes
2023-06-03 14:43:59,423:INFO:SubProcess create_model() called ==================================
2023-06-03 14:43:59,424:INFO:Initializing create_model()
2023-06-03 14:43:59,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:43:59,424:INFO:Checking exceptions
2023-06-03 14:43:59,424:INFO:Importing libraries
2023-06-03 14:43:59,424:INFO:Copying training dataset
2023-06-03 14:43:59,428:INFO:Defining folds
2023-06-03 14:43:59,428:INFO:Declaring metric variables
2023-06-03 14:43:59,431:INFO:Importing untrained model
2023-06-03 14:43:59,434:INFO:Ridge Classifier Imported successfully
2023-06-03 14:43:59,439:INFO:Starting cross validation
2023-06-03 14:43:59,440:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:43:59,484:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:43:59,498:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:43:59,499:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:43:59,505:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:43:59,508:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:43:59,524:INFO:Calculating mean and std
2023-06-03 14:43:59,524:INFO:Creating metrics dataframe
2023-06-03 14:43:59,545:INFO:Uploading results into container
2023-06-03 14:43:59,546:INFO:Uploading model into container now
2023-06-03 14:43:59,546:INFO:_master_model_container: 6
2023-06-03 14:43:59,546:INFO:_display_container: 2
2023-06-03 14:43:59,546:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:43:59,546:INFO:create_model() successfully completed......................................
2023-06-03 14:43:59,637:INFO:SubProcess create_model() end ==================================
2023-06-03 14:43:59,637:INFO:Creating metrics dataframe
2023-06-03 14:43:59,645:INFO:Initializing Random Forest Classifier
2023-06-03 14:43:59,646:INFO:Total runtime is 0.0875774621963501 minutes
2023-06-03 14:43:59,648:INFO:SubProcess create_model() called ==================================
2023-06-03 14:43:59,649:INFO:Initializing create_model()
2023-06-03 14:43:59,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:43:59,649:INFO:Checking exceptions
2023-06-03 14:43:59,649:INFO:Importing libraries
2023-06-03 14:43:59,649:INFO:Copying training dataset
2023-06-03 14:43:59,653:INFO:Defining folds
2023-06-03 14:43:59,653:INFO:Declaring metric variables
2023-06-03 14:43:59,655:INFO:Importing untrained model
2023-06-03 14:43:59,658:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:43:59,664:INFO:Starting cross validation
2023-06-03 14:43:59,664:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:00,044:INFO:Calculating mean and std
2023-06-03 14:44:00,045:INFO:Creating metrics dataframe
2023-06-03 14:44:00,070:INFO:Uploading results into container
2023-06-03 14:44:00,071:INFO:Uploading model into container now
2023-06-03 14:44:00,072:INFO:_master_model_container: 7
2023-06-03 14:44:00,072:INFO:_display_container: 2
2023-06-03 14:44:00,072:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:00,072:INFO:create_model() successfully completed......................................
2023-06-03 14:44:00,158:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:00,159:INFO:Creating metrics dataframe
2023-06-03 14:44:00,167:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:44:00,168:INFO:Total runtime is 0.09627657334009807 minutes
2023-06-03 14:44:00,170:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:00,170:INFO:Initializing create_model()
2023-06-03 14:44:00,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:00,170:INFO:Checking exceptions
2023-06-03 14:44:00,170:INFO:Importing libraries
2023-06-03 14:44:00,170:INFO:Copying training dataset
2023-06-03 14:44:00,179:INFO:Defining folds
2023-06-03 14:44:00,179:INFO:Declaring metric variables
2023-06-03 14:44:00,185:INFO:Importing untrained model
2023-06-03 14:44:00,191:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:44:00,201:INFO:Starting cross validation
2023-06-03 14:44:00,202:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:00,310:INFO:Calculating mean and std
2023-06-03 14:44:00,311:INFO:Creating metrics dataframe
2023-06-03 14:44:00,335:INFO:Uploading results into container
2023-06-03 14:44:00,336:INFO:Uploading model into container now
2023-06-03 14:44:00,336:INFO:_master_model_container: 8
2023-06-03 14:44:00,336:INFO:_display_container: 2
2023-06-03 14:44:00,337:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:44:00,337:INFO:create_model() successfully completed......................................
2023-06-03 14:44:00,423:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:00,423:INFO:Creating metrics dataframe
2023-06-03 14:44:00,433:INFO:Initializing Ada Boost Classifier
2023-06-03 14:44:00,434:INFO:Total runtime is 0.10070895353953044 minutes
2023-06-03 14:44:00,443:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:00,443:INFO:Initializing create_model()
2023-06-03 14:44:00,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:00,443:INFO:Checking exceptions
2023-06-03 14:44:00,444:INFO:Importing libraries
2023-06-03 14:44:00,444:INFO:Copying training dataset
2023-06-03 14:44:00,454:INFO:Defining folds
2023-06-03 14:44:00,454:INFO:Declaring metric variables
2023-06-03 14:44:00,460:INFO:Importing untrained model
2023-06-03 14:44:00,466:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:44:00,480:INFO:Starting cross validation
2023-06-03 14:44:00,481:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:00,654:INFO:Calculating mean and std
2023-06-03 14:44:00,655:INFO:Creating metrics dataframe
2023-06-03 14:44:00,677:INFO:Uploading results into container
2023-06-03 14:44:00,677:INFO:Uploading model into container now
2023-06-03 14:44:00,678:INFO:_master_model_container: 9
2023-06-03 14:44:00,678:INFO:_display_container: 2
2023-06-03 14:44:00,678:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:44:00,678:INFO:create_model() successfully completed......................................
2023-06-03 14:44:00,766:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:00,766:INFO:Creating metrics dataframe
2023-06-03 14:44:00,785:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:44:00,785:INFO:Total runtime is 0.10656816562016805 minutes
2023-06-03 14:44:00,788:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:00,788:INFO:Initializing create_model()
2023-06-03 14:44:00,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:00,789:INFO:Checking exceptions
2023-06-03 14:44:00,789:INFO:Importing libraries
2023-06-03 14:44:00,789:INFO:Copying training dataset
2023-06-03 14:44:00,793:INFO:Defining folds
2023-06-03 14:44:00,793:INFO:Declaring metric variables
2023-06-03 14:44:00,796:INFO:Importing untrained model
2023-06-03 14:44:00,799:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:44:00,805:INFO:Starting cross validation
2023-06-03 14:44:00,806:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:01,201:INFO:Calculating mean and std
2023-06-03 14:44:01,202:INFO:Creating metrics dataframe
2023-06-03 14:44:01,222:INFO:Uploading results into container
2023-06-03 14:44:01,223:INFO:Uploading model into container now
2023-06-03 14:44:01,224:INFO:_master_model_container: 10
2023-06-03 14:44:01,224:INFO:_display_container: 2
2023-06-03 14:44:01,224:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:44:01,224:INFO:create_model() successfully completed......................................
2023-06-03 14:44:01,311:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:01,311:INFO:Creating metrics dataframe
2023-06-03 14:44:01,320:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:44:01,321:INFO:Total runtime is 0.11549224058787028 minutes
2023-06-03 14:44:01,323:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:01,324:INFO:Initializing create_model()
2023-06-03 14:44:01,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:01,324:INFO:Checking exceptions
2023-06-03 14:44:01,324:INFO:Importing libraries
2023-06-03 14:44:01,324:INFO:Copying training dataset
2023-06-03 14:44:01,328:INFO:Defining folds
2023-06-03 14:44:01,328:INFO:Declaring metric variables
2023-06-03 14:44:01,330:INFO:Importing untrained model
2023-06-03 14:44:01,333:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:44:01,338:INFO:Starting cross validation
2023-06-03 14:44:01,339:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:01,435:INFO:Calculating mean and std
2023-06-03 14:44:01,436:INFO:Creating metrics dataframe
2023-06-03 14:44:01,456:INFO:Uploading results into container
2023-06-03 14:44:01,457:INFO:Uploading model into container now
2023-06-03 14:44:01,457:INFO:_master_model_container: 11
2023-06-03 14:44:01,457:INFO:_display_container: 2
2023-06-03 14:44:01,457:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:44:01,457:INFO:create_model() successfully completed......................................
2023-06-03 14:44:01,544:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:01,544:INFO:Creating metrics dataframe
2023-06-03 14:44:01,568:INFO:Initializing Extra Trees Classifier
2023-06-03 14:44:01,568:INFO:Total runtime is 0.11961810986200969 minutes
2023-06-03 14:44:01,573:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:01,573:INFO:Initializing create_model()
2023-06-03 14:44:01,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:01,573:INFO:Checking exceptions
2023-06-03 14:44:01,573:INFO:Importing libraries
2023-06-03 14:44:01,573:INFO:Copying training dataset
2023-06-03 14:44:01,578:INFO:Defining folds
2023-06-03 14:44:01,578:INFO:Declaring metric variables
2023-06-03 14:44:01,582:INFO:Importing untrained model
2023-06-03 14:44:01,585:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:44:01,592:INFO:Starting cross validation
2023-06-03 14:44:01,593:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:02,073:INFO:Calculating mean and std
2023-06-03 14:44:02,073:INFO:Creating metrics dataframe
2023-06-03 14:44:02,110:INFO:Uploading results into container
2023-06-03 14:44:02,110:INFO:Uploading model into container now
2023-06-03 14:44:02,111:INFO:_master_model_container: 12
2023-06-03 14:44:02,111:INFO:_display_container: 2
2023-06-03 14:44:02,111:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:02,111:INFO:create_model() successfully completed......................................
2023-06-03 14:44:02,201:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:02,201:INFO:Creating metrics dataframe
2023-06-03 14:44:02,212:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:44:02,212:INFO:Total runtime is 0.1303567409515381 minutes
2023-06-03 14:44:02,219:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:02,219:INFO:Initializing create_model()
2023-06-03 14:44:02,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:02,220:INFO:Checking exceptions
2023-06-03 14:44:02,220:INFO:Importing libraries
2023-06-03 14:44:02,220:INFO:Copying training dataset
2023-06-03 14:44:02,230:INFO:Defining folds
2023-06-03 14:44:02,230:INFO:Declaring metric variables
2023-06-03 14:44:02,234:INFO:Importing untrained model
2023-06-03 14:44:02,239:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:44:02,251:INFO:Starting cross validation
2023-06-03 14:44:02,252:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:02,572:INFO:Calculating mean and std
2023-06-03 14:44:02,573:INFO:Creating metrics dataframe
2023-06-03 14:44:02,598:INFO:Uploading results into container
2023-06-03 14:44:02,598:INFO:Uploading model into container now
2023-06-03 14:44:02,599:INFO:_master_model_container: 13
2023-06-03 14:44:02,599:INFO:_display_container: 2
2023-06-03 14:44:02,599:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:44:02,599:INFO:create_model() successfully completed......................................
2023-06-03 14:44:02,686:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:02,686:INFO:Creating metrics dataframe
2023-06-03 14:44:02,697:INFO:Initializing Dummy Classifier
2023-06-03 14:44:02,697:INFO:Total runtime is 0.1384410579999288 minutes
2023-06-03 14:44:02,701:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:02,701:INFO:Initializing create_model()
2023-06-03 14:44:02,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae6883940>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:02,702:INFO:Checking exceptions
2023-06-03 14:44:02,702:INFO:Importing libraries
2023-06-03 14:44:02,702:INFO:Copying training dataset
2023-06-03 14:44:02,711:INFO:Defining folds
2023-06-03 14:44:02,711:INFO:Declaring metric variables
2023-06-03 14:44:02,717:INFO:Importing untrained model
2023-06-03 14:44:02,722:INFO:Dummy Classifier Imported successfully
2023-06-03 14:44:02,730:INFO:Starting cross validation
2023-06-03 14:44:02,731:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:02,792:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:02,793:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:02,800:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:02,801:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:02,803:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:02,828:INFO:Calculating mean and std
2023-06-03 14:44:02,829:INFO:Creating metrics dataframe
2023-06-03 14:44:02,860:INFO:Uploading results into container
2023-06-03 14:44:02,860:INFO:Uploading model into container now
2023-06-03 14:44:02,861:INFO:_master_model_container: 14
2023-06-03 14:44:02,861:INFO:_display_container: 2
2023-06-03 14:44:02,861:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:44:02,861:INFO:create_model() successfully completed......................................
2023-06-03 14:44:02,953:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:02,953:INFO:Creating metrics dataframe
2023-06-03 14:44:02,981:INFO:Initializing create_model()
2023-06-03 14:44:02,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:02,981:INFO:Checking exceptions
2023-06-03 14:44:02,984:INFO:Importing libraries
2023-06-03 14:44:02,984:INFO:Copying training dataset
2023-06-03 14:44:02,991:INFO:Defining folds
2023-06-03 14:44:02,991:INFO:Declaring metric variables
2023-06-03 14:44:02,991:INFO:Importing untrained model
2023-06-03 14:44:02,991:INFO:Declaring custom model
2023-06-03 14:44:02,992:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:44:02,993:INFO:Cross validation set to False
2023-06-03 14:44:02,993:INFO:Fitting Model
2023-06-03 14:44:03,097:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:03,097:INFO:create_model() successfully completed......................................
2023-06-03 14:44:03,188:INFO:Initializing create_model()
2023-06-03 14:44:03,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:03,188:INFO:Checking exceptions
2023-06-03 14:44:03,189:INFO:Importing libraries
2023-06-03 14:44:03,190:INFO:Copying training dataset
2023-06-03 14:44:03,197:INFO:Defining folds
2023-06-03 14:44:03,197:INFO:Declaring metric variables
2023-06-03 14:44:03,198:INFO:Importing untrained model
2023-06-03 14:44:03,198:INFO:Declaring custom model
2023-06-03 14:44:03,199:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:44:03,200:INFO:Cross validation set to False
2023-06-03 14:44:03,200:INFO:Fitting Model
2023-06-03 14:44:03,390:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:03,390:INFO:create_model() successfully completed......................................
2023-06-03 14:44:03,483:INFO:Initializing create_model()
2023-06-03 14:44:03,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:03,483:INFO:Checking exceptions
2023-06-03 14:44:03,485:INFO:Importing libraries
2023-06-03 14:44:03,485:INFO:Copying training dataset
2023-06-03 14:44:03,489:INFO:Defining folds
2023-06-03 14:44:03,489:INFO:Declaring metric variables
2023-06-03 14:44:03,489:INFO:Importing untrained model
2023-06-03 14:44:03,489:INFO:Declaring custom model
2023-06-03 14:44:03,489:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:44:03,490:INFO:Cross validation set to False
2023-06-03 14:44:03,490:INFO:Fitting Model
2023-06-03 14:44:03,521:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:44:03,521:INFO:create_model() successfully completed......................................
2023-06-03 14:44:03,610:INFO:Initializing create_model()
2023-06-03 14:44:03,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:03,610:INFO:Checking exceptions
2023-06-03 14:44:03,613:INFO:Importing libraries
2023-06-03 14:44:03,613:INFO:Copying training dataset
2023-06-03 14:44:03,623:INFO:Defining folds
2023-06-03 14:44:03,623:INFO:Declaring metric variables
2023-06-03 14:44:03,623:INFO:Importing untrained model
2023-06-03 14:44:03,623:INFO:Declaring custom model
2023-06-03 14:44:03,624:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:44:03,625:INFO:Cross validation set to False
2023-06-03 14:44:03,625:INFO:Fitting Model
2023-06-03 14:44:03,662:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:44:03,663:INFO:create_model() successfully completed......................................
2023-06-03 14:44:03,759:INFO:Initializing create_model()
2023-06-03 14:44:03,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:03,759:INFO:Checking exceptions
2023-06-03 14:44:03,761:INFO:Importing libraries
2023-06-03 14:44:03,761:INFO:Copying training dataset
2023-06-03 14:44:03,765:INFO:Defining folds
2023-06-03 14:44:03,765:INFO:Declaring metric variables
2023-06-03 14:44:03,765:INFO:Importing untrained model
2023-06-03 14:44:03,765:INFO:Declaring custom model
2023-06-03 14:44:03,765:INFO:Logistic Regression Imported successfully
2023-06-03 14:44:03,766:INFO:Cross validation set to False
2023-06-03 14:44:03,766:INFO:Fitting Model
2023-06-03 14:44:03,785:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:44:03,785:INFO:create_model() successfully completed......................................
2023-06-03 14:44:03,898:INFO:_master_model_container: 14
2023-06-03 14:44:03,898:INFO:_display_container: 2
2023-06-03 14:44:03,899:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2023-06-03 14:44:03,899:INFO:compare_models() successfully completed......................................
2023-06-03 14:44:07,670:INFO:Initializing compare_models()
2023-06-03 14:44:07,670:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, include=None, fold=10, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:44:07,670:INFO:Checking exceptions
2023-06-03 14:44:07,677:INFO:Preparing display monitor
2023-06-03 14:44:07,717:INFO:Initializing Logistic Regression
2023-06-03 14:44:07,717:INFO:Total runtime is 5.706151326497396e-06 minutes
2023-06-03 14:44:07,723:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:07,723:INFO:Initializing create_model()
2023-06-03 14:44:07,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:07,724:INFO:Checking exceptions
2023-06-03 14:44:07,724:INFO:Importing libraries
2023-06-03 14:44:07,724:INFO:Copying training dataset
2023-06-03 14:44:07,732:INFO:Defining folds
2023-06-03 14:44:07,732:INFO:Declaring metric variables
2023-06-03 14:44:07,737:INFO:Importing untrained model
2023-06-03 14:44:07,743:INFO:Logistic Regression Imported successfully
2023-06-03 14:44:07,755:INFO:Starting cross validation
2023-06-03 14:44:07,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:07,903:INFO:Calculating mean and std
2023-06-03 14:44:07,903:INFO:Creating metrics dataframe
2023-06-03 14:44:07,925:INFO:Uploading results into container
2023-06-03 14:44:07,926:INFO:Uploading model into container now
2023-06-03 14:44:07,926:INFO:_master_model_container: 15
2023-06-03 14:44:07,926:INFO:_display_container: 3
2023-06-03 14:44:07,927:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:44:07,927:INFO:create_model() successfully completed......................................
2023-06-03 14:44:08,017:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:08,017:INFO:Creating metrics dataframe
2023-06-03 14:44:08,025:INFO:Initializing K Neighbors Classifier
2023-06-03 14:44:08,025:INFO:Total runtime is 0.0051430463790893555 minutes
2023-06-03 14:44:08,032:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:08,032:INFO:Initializing create_model()
2023-06-03 14:44:08,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:08,032:INFO:Checking exceptions
2023-06-03 14:44:08,032:INFO:Importing libraries
2023-06-03 14:44:08,032:INFO:Copying training dataset
2023-06-03 14:44:08,037:INFO:Defining folds
2023-06-03 14:44:08,037:INFO:Declaring metric variables
2023-06-03 14:44:08,040:INFO:Importing untrained model
2023-06-03 14:44:08,044:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:44:08,050:INFO:Starting cross validation
2023-06-03 14:44:08,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:08,276:INFO:Calculating mean and std
2023-06-03 14:44:08,276:INFO:Creating metrics dataframe
2023-06-03 14:44:08,306:INFO:Uploading results into container
2023-06-03 14:44:08,307:INFO:Uploading model into container now
2023-06-03 14:44:08,307:INFO:_master_model_container: 16
2023-06-03 14:44:08,307:INFO:_display_container: 3
2023-06-03 14:44:08,308:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:44:08,308:INFO:create_model() successfully completed......................................
2023-06-03 14:44:08,396:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:08,396:INFO:Creating metrics dataframe
2023-06-03 14:44:08,404:INFO:Initializing Naive Bayes
2023-06-03 14:44:08,404:INFO:Total runtime is 0.011455432573954264 minutes
2023-06-03 14:44:08,407:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:08,407:INFO:Initializing create_model()
2023-06-03 14:44:08,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:08,407:INFO:Checking exceptions
2023-06-03 14:44:08,407:INFO:Importing libraries
2023-06-03 14:44:08,407:INFO:Copying training dataset
2023-06-03 14:44:08,416:INFO:Defining folds
2023-06-03 14:44:08,416:INFO:Declaring metric variables
2023-06-03 14:44:08,422:INFO:Importing untrained model
2023-06-03 14:44:08,428:INFO:Naive Bayes Imported successfully
2023-06-03 14:44:08,439:INFO:Starting cross validation
2023-06-03 14:44:08,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:08,611:INFO:Calculating mean and std
2023-06-03 14:44:08,612:INFO:Creating metrics dataframe
2023-06-03 14:44:08,634:INFO:Uploading results into container
2023-06-03 14:44:08,634:INFO:Uploading model into container now
2023-06-03 14:44:08,634:INFO:_master_model_container: 17
2023-06-03 14:44:08,634:INFO:_display_container: 3
2023-06-03 14:44:08,635:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:44:08,635:INFO:create_model() successfully completed......................................
2023-06-03 14:44:08,728:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:08,728:INFO:Creating metrics dataframe
2023-06-03 14:44:08,736:INFO:Initializing Decision Tree Classifier
2023-06-03 14:44:08,736:INFO:Total runtime is 0.01699519157409668 minutes
2023-06-03 14:44:08,739:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:08,740:INFO:Initializing create_model()
2023-06-03 14:44:08,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:08,740:INFO:Checking exceptions
2023-06-03 14:44:08,740:INFO:Importing libraries
2023-06-03 14:44:08,740:INFO:Copying training dataset
2023-06-03 14:44:08,744:INFO:Defining folds
2023-06-03 14:44:08,744:INFO:Declaring metric variables
2023-06-03 14:44:08,748:INFO:Importing untrained model
2023-06-03 14:44:08,756:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:44:08,768:INFO:Starting cross validation
2023-06-03 14:44:08,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:08,956:INFO:Calculating mean and std
2023-06-03 14:44:08,957:INFO:Creating metrics dataframe
2023-06-03 14:44:08,978:INFO:Uploading results into container
2023-06-03 14:44:08,978:INFO:Uploading model into container now
2023-06-03 14:44:08,979:INFO:_master_model_container: 18
2023-06-03 14:44:08,979:INFO:_display_container: 3
2023-06-03 14:44:08,979:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:44:08,979:INFO:create_model() successfully completed......................................
2023-06-03 14:44:09,066:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:09,066:INFO:Creating metrics dataframe
2023-06-03 14:44:09,074:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:44:09,074:INFO:Total runtime is 0.02262275218963623 minutes
2023-06-03 14:44:09,077:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:09,077:INFO:Initializing create_model()
2023-06-03 14:44:09,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:09,077:INFO:Checking exceptions
2023-06-03 14:44:09,077:INFO:Importing libraries
2023-06-03 14:44:09,077:INFO:Copying training dataset
2023-06-03 14:44:09,081:INFO:Defining folds
2023-06-03 14:44:09,082:INFO:Declaring metric variables
2023-06-03 14:44:09,084:INFO:Importing untrained model
2023-06-03 14:44:09,087:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:44:09,092:INFO:Starting cross validation
2023-06-03 14:44:09,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:09,145:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,148:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,148:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,149:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,151:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,153:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,155:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,159:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,164:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,166:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,167:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,167:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,169:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,171:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,173:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,175:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,176:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:44:09,179:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,180:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:09,215:INFO:Calculating mean and std
2023-06-03 14:44:09,216:INFO:Creating metrics dataframe
2023-06-03 14:44:09,238:INFO:Uploading results into container
2023-06-03 14:44:09,238:INFO:Uploading model into container now
2023-06-03 14:44:09,238:INFO:_master_model_container: 19
2023-06-03 14:44:09,239:INFO:_display_container: 3
2023-06-03 14:44:09,239:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:44:09,239:INFO:create_model() successfully completed......................................
2023-06-03 14:44:09,326:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:09,326:INFO:Creating metrics dataframe
2023-06-03 14:44:09,335:INFO:Initializing Ridge Classifier
2023-06-03 14:44:09,335:INFO:Total runtime is 0.026975393295288086 minutes
2023-06-03 14:44:09,338:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:09,339:INFO:Initializing create_model()
2023-06-03 14:44:09,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:09,339:INFO:Checking exceptions
2023-06-03 14:44:09,339:INFO:Importing libraries
2023-06-03 14:44:09,339:INFO:Copying training dataset
2023-06-03 14:44:09,343:INFO:Defining folds
2023-06-03 14:44:09,343:INFO:Declaring metric variables
2023-06-03 14:44:09,347:INFO:Importing untrained model
2023-06-03 14:44:09,350:INFO:Ridge Classifier Imported successfully
2023-06-03 14:44:09,359:INFO:Starting cross validation
2023-06-03 14:44:09,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:09,423:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,428:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,432:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,432:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,433:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,435:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,441:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,442:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,456:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,460:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:44:09,489:INFO:Calculating mean and std
2023-06-03 14:44:09,491:INFO:Creating metrics dataframe
2023-06-03 14:44:09,522:INFO:Uploading results into container
2023-06-03 14:44:09,522:INFO:Uploading model into container now
2023-06-03 14:44:09,523:INFO:_master_model_container: 20
2023-06-03 14:44:09,523:INFO:_display_container: 3
2023-06-03 14:44:09,523:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:44:09,523:INFO:create_model() successfully completed......................................
2023-06-03 14:44:09,611:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:09,611:INFO:Creating metrics dataframe
2023-06-03 14:44:09,620:INFO:Initializing Random Forest Classifier
2023-06-03 14:44:09,620:INFO:Total runtime is 0.0317177693049113 minutes
2023-06-03 14:44:09,622:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:09,623:INFO:Initializing create_model()
2023-06-03 14:44:09,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:09,623:INFO:Checking exceptions
2023-06-03 14:44:09,623:INFO:Importing libraries
2023-06-03 14:44:09,623:INFO:Copying training dataset
2023-06-03 14:44:09,627:INFO:Defining folds
2023-06-03 14:44:09,627:INFO:Declaring metric variables
2023-06-03 14:44:09,630:INFO:Importing untrained model
2023-06-03 14:44:09,633:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:44:09,638:INFO:Starting cross validation
2023-06-03 14:44:09,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:10,174:INFO:Calculating mean and std
2023-06-03 14:44:10,177:INFO:Creating metrics dataframe
2023-06-03 14:44:10,207:INFO:Uploading results into container
2023-06-03 14:44:10,208:INFO:Uploading model into container now
2023-06-03 14:44:10,208:INFO:_master_model_container: 21
2023-06-03 14:44:10,208:INFO:_display_container: 3
2023-06-03 14:44:10,209:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:10,209:INFO:create_model() successfully completed......................................
2023-06-03 14:44:10,298:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:10,298:INFO:Creating metrics dataframe
2023-06-03 14:44:10,306:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:44:10,307:INFO:Total runtime is 0.043165755271911625 minutes
2023-06-03 14:44:10,309:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:10,309:INFO:Initializing create_model()
2023-06-03 14:44:10,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:10,309:INFO:Checking exceptions
2023-06-03 14:44:10,309:INFO:Importing libraries
2023-06-03 14:44:10,309:INFO:Copying training dataset
2023-06-03 14:44:10,314:INFO:Defining folds
2023-06-03 14:44:10,314:INFO:Declaring metric variables
2023-06-03 14:44:10,317:INFO:Importing untrained model
2023-06-03 14:44:10,319:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:44:10,325:INFO:Starting cross validation
2023-06-03 14:44:10,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:10,475:INFO:Calculating mean and std
2023-06-03 14:44:10,477:INFO:Creating metrics dataframe
2023-06-03 14:44:10,511:INFO:Uploading results into container
2023-06-03 14:44:10,512:INFO:Uploading model into container now
2023-06-03 14:44:10,512:INFO:_master_model_container: 22
2023-06-03 14:44:10,512:INFO:_display_container: 3
2023-06-03 14:44:10,512:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:44:10,512:INFO:create_model() successfully completed......................................
2023-06-03 14:44:10,602:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:10,602:INFO:Creating metrics dataframe
2023-06-03 14:44:10,611:INFO:Initializing Ada Boost Classifier
2023-06-03 14:44:10,611:INFO:Total runtime is 0.048239680131276455 minutes
2023-06-03 14:44:10,614:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:10,614:INFO:Initializing create_model()
2023-06-03 14:44:10,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:10,614:INFO:Checking exceptions
2023-06-03 14:44:10,614:INFO:Importing libraries
2023-06-03 14:44:10,614:INFO:Copying training dataset
2023-06-03 14:44:10,618:INFO:Defining folds
2023-06-03 14:44:10,619:INFO:Declaring metric variables
2023-06-03 14:44:10,621:INFO:Importing untrained model
2023-06-03 14:44:10,624:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:44:10,629:INFO:Starting cross validation
2023-06-03 14:44:10,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:10,836:INFO:Calculating mean and std
2023-06-03 14:44:10,838:INFO:Creating metrics dataframe
2023-06-03 14:44:10,865:INFO:Uploading results into container
2023-06-03 14:44:10,865:INFO:Uploading model into container now
2023-06-03 14:44:10,865:INFO:_master_model_container: 23
2023-06-03 14:44:10,866:INFO:_display_container: 3
2023-06-03 14:44:10,866:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:44:10,866:INFO:create_model() successfully completed......................................
2023-06-03 14:44:10,956:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:10,957:INFO:Creating metrics dataframe
2023-06-03 14:44:10,966:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:44:10,966:INFO:Total runtime is 0.054162522157033294 minutes
2023-06-03 14:44:10,969:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:10,970:INFO:Initializing create_model()
2023-06-03 14:44:10,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:10,970:INFO:Checking exceptions
2023-06-03 14:44:10,970:INFO:Importing libraries
2023-06-03 14:44:10,970:INFO:Copying training dataset
2023-06-03 14:44:10,974:INFO:Defining folds
2023-06-03 14:44:10,975:INFO:Declaring metric variables
2023-06-03 14:44:10,978:INFO:Importing untrained model
2023-06-03 14:44:10,981:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:44:10,987:INFO:Starting cross validation
2023-06-03 14:44:10,987:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:11,409:INFO:Calculating mean and std
2023-06-03 14:44:11,412:INFO:Creating metrics dataframe
2023-06-03 14:44:11,433:INFO:Uploading results into container
2023-06-03 14:44:11,433:INFO:Uploading model into container now
2023-06-03 14:44:11,433:INFO:_master_model_container: 24
2023-06-03 14:44:11,433:INFO:_display_container: 3
2023-06-03 14:44:11,434:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:44:11,434:INFO:create_model() successfully completed......................................
2023-06-03 14:44:11,521:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:11,521:INFO:Creating metrics dataframe
2023-06-03 14:44:11,531:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:44:11,531:INFO:Total runtime is 0.06357271273930869 minutes
2023-06-03 14:44:11,534:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:11,535:INFO:Initializing create_model()
2023-06-03 14:44:11,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:11,535:INFO:Checking exceptions
2023-06-03 14:44:11,535:INFO:Importing libraries
2023-06-03 14:44:11,535:INFO:Copying training dataset
2023-06-03 14:44:11,539:INFO:Defining folds
2023-06-03 14:44:11,539:INFO:Declaring metric variables
2023-06-03 14:44:11,543:INFO:Importing untrained model
2023-06-03 14:44:11,545:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:44:11,555:INFO:Starting cross validation
2023-06-03 14:44:11,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:11,708:INFO:Calculating mean and std
2023-06-03 14:44:11,711:INFO:Creating metrics dataframe
2023-06-03 14:44:11,751:INFO:Uploading results into container
2023-06-03 14:44:11,752:INFO:Uploading model into container now
2023-06-03 14:44:11,752:INFO:_master_model_container: 25
2023-06-03 14:44:11,752:INFO:_display_container: 3
2023-06-03 14:44:11,752:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:44:11,752:INFO:create_model() successfully completed......................................
2023-06-03 14:44:11,840:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:11,841:INFO:Creating metrics dataframe
2023-06-03 14:44:11,850:INFO:Initializing Extra Trees Classifier
2023-06-03 14:44:11,850:INFO:Total runtime is 0.06889286835988363 minutes
2023-06-03 14:44:11,853:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:11,853:INFO:Initializing create_model()
2023-06-03 14:44:11,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:11,853:INFO:Checking exceptions
2023-06-03 14:44:11,853:INFO:Importing libraries
2023-06-03 14:44:11,853:INFO:Copying training dataset
2023-06-03 14:44:11,858:INFO:Defining folds
2023-06-03 14:44:11,858:INFO:Declaring metric variables
2023-06-03 14:44:11,860:INFO:Importing untrained model
2023-06-03 14:44:11,863:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:44:11,868:INFO:Starting cross validation
2023-06-03 14:44:11,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:12,510:INFO:Calculating mean and std
2023-06-03 14:44:12,511:INFO:Creating metrics dataframe
2023-06-03 14:44:12,533:INFO:Uploading results into container
2023-06-03 14:44:12,533:INFO:Uploading model into container now
2023-06-03 14:44:12,534:INFO:_master_model_container: 26
2023-06-03 14:44:12,534:INFO:_display_container: 3
2023-06-03 14:44:12,534:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:12,534:INFO:create_model() successfully completed......................................
2023-06-03 14:44:12,623:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:12,623:INFO:Creating metrics dataframe
2023-06-03 14:44:12,633:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:44:12,633:INFO:Total runtime is 0.0819408416748047 minutes
2023-06-03 14:44:12,636:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:12,637:INFO:Initializing create_model()
2023-06-03 14:44:12,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:12,637:INFO:Checking exceptions
2023-06-03 14:44:12,637:INFO:Importing libraries
2023-06-03 14:44:12,637:INFO:Copying training dataset
2023-06-03 14:44:12,641:INFO:Defining folds
2023-06-03 14:44:12,642:INFO:Declaring metric variables
2023-06-03 14:44:12,645:INFO:Importing untrained model
2023-06-03 14:44:12,648:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:44:12,654:INFO:Starting cross validation
2023-06-03 14:44:12,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:12,997:INFO:Calculating mean and std
2023-06-03 14:44:12,999:INFO:Creating metrics dataframe
2023-06-03 14:44:13,025:INFO:Uploading results into container
2023-06-03 14:44:13,026:INFO:Uploading model into container now
2023-06-03 14:44:13,026:INFO:_master_model_container: 27
2023-06-03 14:44:13,026:INFO:_display_container: 3
2023-06-03 14:44:13,027:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:44:13,027:INFO:create_model() successfully completed......................................
2023-06-03 14:44:13,132:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:13,132:INFO:Creating metrics dataframe
2023-06-03 14:44:13,143:INFO:Initializing Dummy Classifier
2023-06-03 14:44:13,143:INFO:Total runtime is 0.09043808380762737 minutes
2023-06-03 14:44:13,148:INFO:SubProcess create_model() called ==================================
2023-06-03 14:44:13,148:INFO:Initializing create_model()
2023-06-03 14:44:13,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae636a430>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:13,149:INFO:Checking exceptions
2023-06-03 14:44:13,149:INFO:Importing libraries
2023-06-03 14:44:13,149:INFO:Copying training dataset
2023-06-03 14:44:13,161:INFO:Defining folds
2023-06-03 14:44:13,161:INFO:Declaring metric variables
2023-06-03 14:44:13,168:INFO:Importing untrained model
2023-06-03 14:44:13,176:INFO:Dummy Classifier Imported successfully
2023-06-03 14:44:13,189:INFO:Starting cross validation
2023-06-03 14:44:13,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:44:13,273:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,287:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,288:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,290:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,302:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,312:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,317:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,317:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,319:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,326:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:44:13,342:INFO:Calculating mean and std
2023-06-03 14:44:13,343:INFO:Creating metrics dataframe
2023-06-03 14:44:13,375:INFO:Uploading results into container
2023-06-03 14:44:13,376:INFO:Uploading model into container now
2023-06-03 14:44:13,377:INFO:_master_model_container: 28
2023-06-03 14:44:13,377:INFO:_display_container: 3
2023-06-03 14:44:13,377:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:44:13,377:INFO:create_model() successfully completed......................................
2023-06-03 14:44:13,481:INFO:SubProcess create_model() end ==================================
2023-06-03 14:44:13,481:INFO:Creating metrics dataframe
2023-06-03 14:44:13,499:INFO:Initializing create_model()
2023-06-03 14:44:13,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:13,499:INFO:Checking exceptions
2023-06-03 14:44:13,500:INFO:Importing libraries
2023-06-03 14:44:13,500:INFO:Copying training dataset
2023-06-03 14:44:13,505:INFO:Defining folds
2023-06-03 14:44:13,505:INFO:Declaring metric variables
2023-06-03 14:44:13,505:INFO:Importing untrained model
2023-06-03 14:44:13,505:INFO:Declaring custom model
2023-06-03 14:44:13,506:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:44:13,506:INFO:Cross validation set to False
2023-06-03 14:44:13,506:INFO:Fitting Model
2023-06-03 14:44:13,650:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:13,650:INFO:create_model() successfully completed......................................
2023-06-03 14:44:13,741:INFO:Initializing create_model()
2023-06-03 14:44:13,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:13,741:INFO:Checking exceptions
2023-06-03 14:44:13,743:INFO:Importing libraries
2023-06-03 14:44:13,743:INFO:Copying training dataset
2023-06-03 14:44:13,749:INFO:Defining folds
2023-06-03 14:44:13,750:INFO:Declaring metric variables
2023-06-03 14:44:13,750:INFO:Importing untrained model
2023-06-03 14:44:13,750:INFO:Declaring custom model
2023-06-03 14:44:13,750:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:44:13,751:INFO:Cross validation set to False
2023-06-03 14:44:13,751:INFO:Fitting Model
2023-06-03 14:44:13,829:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:44:13,829:INFO:create_model() successfully completed......................................
2023-06-03 14:44:13,924:INFO:Initializing create_model()
2023-06-03 14:44:13,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:13,924:INFO:Checking exceptions
2023-06-03 14:44:13,926:INFO:Importing libraries
2023-06-03 14:44:13,926:INFO:Copying training dataset
2023-06-03 14:44:13,930:INFO:Defining folds
2023-06-03 14:44:13,930:INFO:Declaring metric variables
2023-06-03 14:44:13,930:INFO:Importing untrained model
2023-06-03 14:44:13,930:INFO:Declaring custom model
2023-06-03 14:44:13,930:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:44:13,931:INFO:Cross validation set to False
2023-06-03 14:44:13,931:INFO:Fitting Model
2023-06-03 14:44:13,972:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:44:13,972:INFO:create_model() successfully completed......................................
2023-06-03 14:44:14,066:INFO:Initializing create_model()
2023-06-03 14:44:14,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:14,067:INFO:Checking exceptions
2023-06-03 14:44:14,070:INFO:Importing libraries
2023-06-03 14:44:14,070:INFO:Copying training dataset
2023-06-03 14:44:14,079:INFO:Defining folds
2023-06-03 14:44:14,079:INFO:Declaring metric variables
2023-06-03 14:44:14,079:INFO:Importing untrained model
2023-06-03 14:44:14,079:INFO:Declaring custom model
2023-06-03 14:44:14,080:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:44:14,081:INFO:Cross validation set to False
2023-06-03 14:44:14,081:INFO:Fitting Model
2023-06-03 14:44:14,118:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:44:14,118:INFO:create_model() successfully completed......................................
2023-06-03 14:44:14,209:INFO:Initializing create_model()
2023-06-03 14:44:14,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55743c10>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:44:14,210:INFO:Checking exceptions
2023-06-03 14:44:14,211:INFO:Importing libraries
2023-06-03 14:44:14,211:INFO:Copying training dataset
2023-06-03 14:44:14,215:INFO:Defining folds
2023-06-03 14:44:14,215:INFO:Declaring metric variables
2023-06-03 14:44:14,215:INFO:Importing untrained model
2023-06-03 14:44:14,215:INFO:Declaring custom model
2023-06-03 14:44:14,215:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:44:14,216:INFO:Cross validation set to False
2023-06-03 14:44:14,216:INFO:Fitting Model
2023-06-03 14:44:14,511:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:44:14,511:INFO:create_model() successfully completed......................................
2023-06-03 14:44:14,640:INFO:_master_model_container: 28
2023-06-03 14:44:14,640:INFO:_display_container: 3
2023-06-03 14:44:14,642:INFO:[ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)]
2023-06-03 14:44:14,642:INFO:compare_models() successfully completed......................................
2023-06-03 14:46:00,170:INFO:PyCaret ClassificationExperiment
2023-06-03 14:46:00,170:INFO:Logging name: clf-default-name
2023-06-03 14:46:00,171:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:46:00,171:INFO:version 3.0.2
2023-06-03 14:46:00,171:INFO:Initializing setup()
2023-06-03 14:46:00,171:INFO:self.USI: 4cbd
2023-06-03 14:46:00,171:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:46:00,171:INFO:Checking environment
2023-06-03 14:46:00,171:INFO:python_version: 3.8.16
2023-06-03 14:46:00,171:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:46:00,171:INFO:machine: x86_64
2023-06-03 14:46:00,171:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:00,171:INFO:Memory: svmem(total=134737395712, available=88695697408, percent=34.2, used=44616048640, free=2974236672, active=31133130752, inactive=91058372608, buffers=2419167232, cached=84727943168, shared=28565504, slab=4876173312)
2023-06-03 14:46:00,172:INFO:Physical Core: 10
2023-06-03 14:46:00,172:INFO:Logical Core: 20
2023-06-03 14:46:00,172:INFO:Checking libraries
2023-06-03 14:46:00,172:INFO:System:
2023-06-03 14:46:00,172:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:46:00,172:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:46:00,172:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:00,172:INFO:PyCaret required dependencies:
2023-06-03 14:46:00,172:INFO:                 pip: 23.0.1
2023-06-03 14:46:00,172:INFO:          setuptools: 67.8.0
2023-06-03 14:46:00,172:INFO:             pycaret: 3.0.2
2023-06-03 14:46:00,172:INFO:             IPython: 8.12.2
2023-06-03 14:46:00,172:INFO:          ipywidgets: 8.0.6
2023-06-03 14:46:00,172:INFO:                tqdm: 4.65.0
2023-06-03 14:46:00,172:INFO:               numpy: 1.23.5
2023-06-03 14:46:00,172:INFO:              pandas: 1.5.3
2023-06-03 14:46:00,172:INFO:              jinja2: 3.1.2
2023-06-03 14:46:00,172:INFO:               scipy: 1.10.1
2023-06-03 14:46:00,172:INFO:              joblib: 1.2.0
2023-06-03 14:46:00,172:INFO:             sklearn: 1.2.2
2023-06-03 14:46:00,172:INFO:                pyod: 1.0.9
2023-06-03 14:46:00,172:INFO:            imblearn: 0.10.1
2023-06-03 14:46:00,172:INFO:   category_encoders: 2.6.1
2023-06-03 14:46:00,172:INFO:            lightgbm: 3.3.5
2023-06-03 14:46:00,172:INFO:               numba: 0.57.0
2023-06-03 14:46:00,172:INFO:            requests: 2.31.0
2023-06-03 14:46:00,172:INFO:          matplotlib: 3.7.1
2023-06-03 14:46:00,172:INFO:          scikitplot: 0.3.7
2023-06-03 14:46:00,172:INFO:         yellowbrick: 1.5
2023-06-03 14:46:00,172:INFO:              plotly: 5.14.1
2023-06-03 14:46:00,172:INFO:             kaleido: 0.2.1
2023-06-03 14:46:00,172:INFO:         statsmodels: 0.14.0
2023-06-03 14:46:00,172:INFO:              sktime: 0.17.0
2023-06-03 14:46:00,172:INFO:               tbats: 1.1.3
2023-06-03 14:46:00,172:INFO:            pmdarima: 2.0.3
2023-06-03 14:46:00,172:INFO:              psutil: 5.9.5
2023-06-03 14:46:00,172:INFO:PyCaret optional dependencies:
2023-06-03 14:46:00,172:INFO:                shap: Not installed
2023-06-03 14:46:00,173:INFO:           interpret: Not installed
2023-06-03 14:46:00,173:INFO:                umap: Not installed
2023-06-03 14:46:00,173:INFO:    pandas_profiling: Not installed
2023-06-03 14:46:00,173:INFO:  explainerdashboard: Not installed
2023-06-03 14:46:00,173:INFO:             autoviz: Not installed
2023-06-03 14:46:00,173:INFO:           fairlearn: Not installed
2023-06-03 14:46:00,173:INFO:             xgboost: Not installed
2023-06-03 14:46:00,173:INFO:            catboost: Not installed
2023-06-03 14:46:00,173:INFO:              kmodes: Not installed
2023-06-03 14:46:00,173:INFO:             mlxtend: Not installed
2023-06-03 14:46:00,173:INFO:       statsforecast: Not installed
2023-06-03 14:46:00,173:INFO:        tune_sklearn: Not installed
2023-06-03 14:46:00,173:INFO:                 ray: Not installed
2023-06-03 14:46:00,173:INFO:            hyperopt: Not installed
2023-06-03 14:46:00,173:INFO:              optuna: Not installed
2023-06-03 14:46:00,173:INFO:               skopt: Not installed
2023-06-03 14:46:00,173:INFO:              mlflow: Not installed
2023-06-03 14:46:00,173:INFO:              gradio: Not installed
2023-06-03 14:46:00,173:INFO:             fastapi: Not installed
2023-06-03 14:46:00,173:INFO:             uvicorn: Not installed
2023-06-03 14:46:00,173:INFO:              m2cgen: Not installed
2023-06-03 14:46:00,173:INFO:           evidently: Not installed
2023-06-03 14:46:00,173:INFO:               fugue: Not installed
2023-06-03 14:46:00,173:INFO:           streamlit: Not installed
2023-06-03 14:46:00,173:INFO:             prophet: Not installed
2023-06-03 14:46:00,173:INFO:None
2023-06-03 14:46:00,173:INFO:Set up data.
2023-06-03 14:46:00,180:INFO:Set up train/test split.
2023-06-03 14:46:00,187:INFO:Set up index.
2023-06-03 14:46:00,187:INFO:Set up folding strategy.
2023-06-03 14:46:00,187:INFO:Assigning column types.
2023-06-03 14:46:00,191:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:46:00,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,274:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,275:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,294:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:46:00,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,376:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:46:00,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,498:INFO:Preparing preprocessing pipeline...
2023-06-03 14:46:00,499:INFO:Set up simple imputation.
2023-06-03 14:46:00,510:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:46:00,513:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-03 14:46:00,513:INFO:Creating final display dataframe.
2023-06-03 14:46:00,556:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4cbd
2023-06-03 14:46:00,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,613:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,664:INFO:setup() successfully completed in 0.5s...............
2023-06-03 14:46:00,794:INFO:PyCaret ClassificationExperiment
2023-06-03 14:46:00,795:INFO:Logging name: clf-default-name
2023-06-03 14:46:00,795:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:46:00,795:INFO:version 3.0.2
2023-06-03 14:46:00,795:INFO:Initializing setup()
2023-06-03 14:46:00,795:INFO:self.USI: b677
2023-06-03 14:46:00,795:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:46:00,795:INFO:Checking environment
2023-06-03 14:46:00,795:INFO:python_version: 3.8.16
2023-06-03 14:46:00,795:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:46:00,795:INFO:machine: x86_64
2023-06-03 14:46:00,795:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:00,796:INFO:Memory: svmem(total=134737395712, available=88690053120, percent=34.2, used=44621692928, free=2968567808, active=31133118464, inactive=91076870144, buffers=2419171328, cached=84727963648, shared=28565504, slab=4876230656)
2023-06-03 14:46:00,797:INFO:Physical Core: 10
2023-06-03 14:46:00,797:INFO:Logical Core: 20
2023-06-03 14:46:00,797:INFO:Checking libraries
2023-06-03 14:46:00,797:INFO:System:
2023-06-03 14:46:00,798:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:46:00,798:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:46:00,798:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:00,798:INFO:PyCaret required dependencies:
2023-06-03 14:46:00,798:INFO:                 pip: 23.0.1
2023-06-03 14:46:00,798:INFO:          setuptools: 67.8.0
2023-06-03 14:46:00,798:INFO:             pycaret: 3.0.2
2023-06-03 14:46:00,798:INFO:             IPython: 8.12.2
2023-06-03 14:46:00,798:INFO:          ipywidgets: 8.0.6
2023-06-03 14:46:00,798:INFO:                tqdm: 4.65.0
2023-06-03 14:46:00,798:INFO:               numpy: 1.23.5
2023-06-03 14:46:00,798:INFO:              pandas: 1.5.3
2023-06-03 14:46:00,798:INFO:              jinja2: 3.1.2
2023-06-03 14:46:00,798:INFO:               scipy: 1.10.1
2023-06-03 14:46:00,798:INFO:              joblib: 1.2.0
2023-06-03 14:46:00,798:INFO:             sklearn: 1.2.2
2023-06-03 14:46:00,798:INFO:                pyod: 1.0.9
2023-06-03 14:46:00,798:INFO:            imblearn: 0.10.1
2023-06-03 14:46:00,798:INFO:   category_encoders: 2.6.1
2023-06-03 14:46:00,798:INFO:            lightgbm: 3.3.5
2023-06-03 14:46:00,798:INFO:               numba: 0.57.0
2023-06-03 14:46:00,799:INFO:            requests: 2.31.0
2023-06-03 14:46:00,799:INFO:          matplotlib: 3.7.1
2023-06-03 14:46:00,799:INFO:          scikitplot: 0.3.7
2023-06-03 14:46:00,799:INFO:         yellowbrick: 1.5
2023-06-03 14:46:00,799:INFO:              plotly: 5.14.1
2023-06-03 14:46:00,799:INFO:             kaleido: 0.2.1
2023-06-03 14:46:00,799:INFO:         statsmodels: 0.14.0
2023-06-03 14:46:00,799:INFO:              sktime: 0.17.0
2023-06-03 14:46:00,799:INFO:               tbats: 1.1.3
2023-06-03 14:46:00,799:INFO:            pmdarima: 2.0.3
2023-06-03 14:46:00,799:INFO:              psutil: 5.9.5
2023-06-03 14:46:00,799:INFO:PyCaret optional dependencies:
2023-06-03 14:46:00,799:INFO:                shap: Not installed
2023-06-03 14:46:00,799:INFO:           interpret: Not installed
2023-06-03 14:46:00,799:INFO:                umap: Not installed
2023-06-03 14:46:00,799:INFO:    pandas_profiling: Not installed
2023-06-03 14:46:00,799:INFO:  explainerdashboard: Not installed
2023-06-03 14:46:00,799:INFO:             autoviz: Not installed
2023-06-03 14:46:00,799:INFO:           fairlearn: Not installed
2023-06-03 14:46:00,799:INFO:             xgboost: Not installed
2023-06-03 14:46:00,799:INFO:            catboost: Not installed
2023-06-03 14:46:00,799:INFO:              kmodes: Not installed
2023-06-03 14:46:00,800:INFO:             mlxtend: Not installed
2023-06-03 14:46:00,800:INFO:       statsforecast: Not installed
2023-06-03 14:46:00,800:INFO:        tune_sklearn: Not installed
2023-06-03 14:46:00,800:INFO:                 ray: Not installed
2023-06-03 14:46:00,800:INFO:            hyperopt: Not installed
2023-06-03 14:46:00,800:INFO:              optuna: Not installed
2023-06-03 14:46:00,800:INFO:               skopt: Not installed
2023-06-03 14:46:00,800:INFO:              mlflow: Not installed
2023-06-03 14:46:00,800:INFO:              gradio: Not installed
2023-06-03 14:46:00,800:INFO:             fastapi: Not installed
2023-06-03 14:46:00,800:INFO:             uvicorn: Not installed
2023-06-03 14:46:00,800:INFO:              m2cgen: Not installed
2023-06-03 14:46:00,800:INFO:           evidently: Not installed
2023-06-03 14:46:00,800:INFO:               fugue: Not installed
2023-06-03 14:46:00,800:INFO:           streamlit: Not installed
2023-06-03 14:46:00,800:INFO:             prophet: Not installed
2023-06-03 14:46:00,800:INFO:None
2023-06-03 14:46:00,800:INFO:Set up data.
2023-06-03 14:46:00,813:INFO:Set up train/test split.
2023-06-03 14:46:00,821:INFO:Set up index.
2023-06-03 14:46:00,821:INFO:Set up folding strategy.
2023-06-03 14:46:00,821:INFO:Assigning column types.
2023-06-03 14:46:00,824:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:46:00,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,907:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,928:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:46:00,960:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:00,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:00,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,011:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:01,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,031:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:46:01,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,132:INFO:Preparing preprocessing pipeline...
2023-06-03 14:46:01,133:INFO:Set up simple imputation.
2023-06-03 14:46:01,133:INFO:Set up feature normalization.
2023-06-03 14:46:01,148:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:46:01,151:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-06-03 14:46:01,151:INFO:Creating final display dataframe.
2023-06-03 14:46:01,209:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              b677
2023-06-03 14:46:01,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,317:INFO:setup() successfully completed in 0.54s...............
2023-06-03 14:46:01,397:INFO:gpu_param set to False
2023-06-03 14:46:01,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:01,556:INFO:Initializing compare_models()
2023-06-03 14:46:01,557:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55802460>, include=None, fold=10, round=4, cross_validation=True, sort=accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b55802460>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:46:01,557:INFO:Checking exceptions
2023-06-03 14:46:22,116:INFO:PyCaret ClassificationExperiment
2023-06-03 14:46:22,116:INFO:Logging name: clf-default-name
2023-06-03 14:46:22,116:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:46:22,116:INFO:version 3.0.2
2023-06-03 14:46:22,116:INFO:Initializing setup()
2023-06-03 14:46:22,116:INFO:self.USI: 9650
2023-06-03 14:46:22,116:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:46:22,116:INFO:Checking environment
2023-06-03 14:46:22,116:INFO:python_version: 3.8.16
2023-06-03 14:46:22,116:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:46:22,116:INFO:machine: x86_64
2023-06-03 14:46:22,116:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:22,116:INFO:Memory: svmem(total=134737395712, available=88690507776, percent=34.2, used=44621238272, free=2968956928, active=31133417472, inactive=91070648320, buffers=2419195904, cached=84728004608, shared=28565504, slab=4876623872)
2023-06-03 14:46:22,117:INFO:Physical Core: 10
2023-06-03 14:46:22,117:INFO:Logical Core: 20
2023-06-03 14:46:22,117:INFO:Checking libraries
2023-06-03 14:46:22,117:INFO:System:
2023-06-03 14:46:22,117:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:46:22,117:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:46:22,117:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:22,117:INFO:PyCaret required dependencies:
2023-06-03 14:46:22,117:INFO:                 pip: 23.0.1
2023-06-03 14:46:22,117:INFO:          setuptools: 67.8.0
2023-06-03 14:46:22,117:INFO:             pycaret: 3.0.2
2023-06-03 14:46:22,117:INFO:             IPython: 8.12.2
2023-06-03 14:46:22,117:INFO:          ipywidgets: 8.0.6
2023-06-03 14:46:22,117:INFO:                tqdm: 4.65.0
2023-06-03 14:46:22,117:INFO:               numpy: 1.23.5
2023-06-03 14:46:22,117:INFO:              pandas: 1.5.3
2023-06-03 14:46:22,117:INFO:              jinja2: 3.1.2
2023-06-03 14:46:22,117:INFO:               scipy: 1.10.1
2023-06-03 14:46:22,118:INFO:              joblib: 1.2.0
2023-06-03 14:46:22,118:INFO:             sklearn: 1.2.2
2023-06-03 14:46:22,118:INFO:                pyod: 1.0.9
2023-06-03 14:46:22,118:INFO:            imblearn: 0.10.1
2023-06-03 14:46:22,118:INFO:   category_encoders: 2.6.1
2023-06-03 14:46:22,118:INFO:            lightgbm: 3.3.5
2023-06-03 14:46:22,118:INFO:               numba: 0.57.0
2023-06-03 14:46:22,118:INFO:            requests: 2.31.0
2023-06-03 14:46:22,118:INFO:          matplotlib: 3.7.1
2023-06-03 14:46:22,118:INFO:          scikitplot: 0.3.7
2023-06-03 14:46:22,118:INFO:         yellowbrick: 1.5
2023-06-03 14:46:22,118:INFO:              plotly: 5.14.1
2023-06-03 14:46:22,118:INFO:             kaleido: 0.2.1
2023-06-03 14:46:22,118:INFO:         statsmodels: 0.14.0
2023-06-03 14:46:22,118:INFO:              sktime: 0.17.0
2023-06-03 14:46:22,118:INFO:               tbats: 1.1.3
2023-06-03 14:46:22,118:INFO:            pmdarima: 2.0.3
2023-06-03 14:46:22,118:INFO:              psutil: 5.9.5
2023-06-03 14:46:22,118:INFO:PyCaret optional dependencies:
2023-06-03 14:46:22,118:INFO:                shap: Not installed
2023-06-03 14:46:22,118:INFO:           interpret: Not installed
2023-06-03 14:46:22,118:INFO:                umap: Not installed
2023-06-03 14:46:22,118:INFO:    pandas_profiling: Not installed
2023-06-03 14:46:22,118:INFO:  explainerdashboard: Not installed
2023-06-03 14:46:22,118:INFO:             autoviz: Not installed
2023-06-03 14:46:22,118:INFO:           fairlearn: Not installed
2023-06-03 14:46:22,118:INFO:             xgboost: Not installed
2023-06-03 14:46:22,118:INFO:            catboost: Not installed
2023-06-03 14:46:22,118:INFO:              kmodes: Not installed
2023-06-03 14:46:22,118:INFO:             mlxtend: Not installed
2023-06-03 14:46:22,118:INFO:       statsforecast: Not installed
2023-06-03 14:46:22,118:INFO:        tune_sklearn: Not installed
2023-06-03 14:46:22,118:INFO:                 ray: Not installed
2023-06-03 14:46:22,118:INFO:            hyperopt: Not installed
2023-06-03 14:46:22,118:INFO:              optuna: Not installed
2023-06-03 14:46:22,118:INFO:               skopt: Not installed
2023-06-03 14:46:22,118:INFO:              mlflow: Not installed
2023-06-03 14:46:22,118:INFO:              gradio: Not installed
2023-06-03 14:46:22,118:INFO:             fastapi: Not installed
2023-06-03 14:46:22,118:INFO:             uvicorn: Not installed
2023-06-03 14:46:22,118:INFO:              m2cgen: Not installed
2023-06-03 14:46:22,118:INFO:           evidently: Not installed
2023-06-03 14:46:22,118:INFO:               fugue: Not installed
2023-06-03 14:46:22,118:INFO:           streamlit: Not installed
2023-06-03 14:46:22,118:INFO:             prophet: Not installed
2023-06-03 14:46:22,118:INFO:None
2023-06-03 14:46:22,118:INFO:Set up data.
2023-06-03 14:46:22,126:INFO:Set up train/test split.
2023-06-03 14:46:22,132:INFO:Set up index.
2023-06-03 14:46:22,133:INFO:Set up folding strategy.
2023-06-03 14:46:22,133:INFO:Assigning column types.
2023-06-03 14:46:22,137:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:46:22,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,238:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:46:22,269:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,320:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,339:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:46:22,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,440:INFO:Preparing preprocessing pipeline...
2023-06-03 14:46:22,441:INFO:Set up simple imputation.
2023-06-03 14:46:22,452:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:46:22,454:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-03 14:46:22,455:INFO:Creating final display dataframe.
2023-06-03 14:46:22,497:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9650
2023-06-03 14:46:22,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,606:INFO:setup() successfully completed in 0.5s...............
2023-06-03 14:46:22,720:INFO:PyCaret ClassificationExperiment
2023-06-03 14:46:22,720:INFO:Logging name: clf-default-name
2023-06-03 14:46:22,721:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:46:22,721:INFO:version 3.0.2
2023-06-03 14:46:22,721:INFO:Initializing setup()
2023-06-03 14:46:22,721:INFO:self.USI: dcc6
2023-06-03 14:46:22,721:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:46:22,721:INFO:Checking environment
2023-06-03 14:46:22,721:INFO:python_version: 3.8.16
2023-06-03 14:46:22,721:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:46:22,721:INFO:machine: x86_64
2023-06-03 14:46:22,721:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:22,721:INFO:Memory: svmem(total=134737395712, available=88690262016, percent=34.2, used=44621479936, free=2968698880, active=31133417472, inactive=91073204224, buffers=2419200000, cached=84728016896, shared=28565504, slab=4876623872)
2023-06-03 14:46:22,723:INFO:Physical Core: 10
2023-06-03 14:46:22,723:INFO:Logical Core: 20
2023-06-03 14:46:22,723:INFO:Checking libraries
2023-06-03 14:46:22,723:INFO:System:
2023-06-03 14:46:22,723:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:46:22,723:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:46:22,723:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:46:22,723:INFO:PyCaret required dependencies:
2023-06-03 14:46:22,723:INFO:                 pip: 23.0.1
2023-06-03 14:46:22,723:INFO:          setuptools: 67.8.0
2023-06-03 14:46:22,723:INFO:             pycaret: 3.0.2
2023-06-03 14:46:22,723:INFO:             IPython: 8.12.2
2023-06-03 14:46:22,723:INFO:          ipywidgets: 8.0.6
2023-06-03 14:46:22,723:INFO:                tqdm: 4.65.0
2023-06-03 14:46:22,723:INFO:               numpy: 1.23.5
2023-06-03 14:46:22,723:INFO:              pandas: 1.5.3
2023-06-03 14:46:22,723:INFO:              jinja2: 3.1.2
2023-06-03 14:46:22,723:INFO:               scipy: 1.10.1
2023-06-03 14:46:22,723:INFO:              joblib: 1.2.0
2023-06-03 14:46:22,723:INFO:             sklearn: 1.2.2
2023-06-03 14:46:22,723:INFO:                pyod: 1.0.9
2023-06-03 14:46:22,723:INFO:            imblearn: 0.10.1
2023-06-03 14:46:22,723:INFO:   category_encoders: 2.6.1
2023-06-03 14:46:22,723:INFO:            lightgbm: 3.3.5
2023-06-03 14:46:22,723:INFO:               numba: 0.57.0
2023-06-03 14:46:22,723:INFO:            requests: 2.31.0
2023-06-03 14:46:22,723:INFO:          matplotlib: 3.7.1
2023-06-03 14:46:22,724:INFO:          scikitplot: 0.3.7
2023-06-03 14:46:22,724:INFO:         yellowbrick: 1.5
2023-06-03 14:46:22,724:INFO:              plotly: 5.14.1
2023-06-03 14:46:22,724:INFO:             kaleido: 0.2.1
2023-06-03 14:46:22,724:INFO:         statsmodels: 0.14.0
2023-06-03 14:46:22,724:INFO:              sktime: 0.17.0
2023-06-03 14:46:22,724:INFO:               tbats: 1.1.3
2023-06-03 14:46:22,724:INFO:            pmdarima: 2.0.3
2023-06-03 14:46:22,724:INFO:              psutil: 5.9.5
2023-06-03 14:46:22,724:INFO:PyCaret optional dependencies:
2023-06-03 14:46:22,724:INFO:                shap: Not installed
2023-06-03 14:46:22,724:INFO:           interpret: Not installed
2023-06-03 14:46:22,724:INFO:                umap: Not installed
2023-06-03 14:46:22,724:INFO:    pandas_profiling: Not installed
2023-06-03 14:46:22,724:INFO:  explainerdashboard: Not installed
2023-06-03 14:46:22,724:INFO:             autoviz: Not installed
2023-06-03 14:46:22,724:INFO:           fairlearn: Not installed
2023-06-03 14:46:22,724:INFO:             xgboost: Not installed
2023-06-03 14:46:22,724:INFO:            catboost: Not installed
2023-06-03 14:46:22,724:INFO:              kmodes: Not installed
2023-06-03 14:46:22,724:INFO:             mlxtend: Not installed
2023-06-03 14:46:22,724:INFO:       statsforecast: Not installed
2023-06-03 14:46:22,724:INFO:        tune_sklearn: Not installed
2023-06-03 14:46:22,724:INFO:                 ray: Not installed
2023-06-03 14:46:22,724:INFO:            hyperopt: Not installed
2023-06-03 14:46:22,724:INFO:              optuna: Not installed
2023-06-03 14:46:22,724:INFO:               skopt: Not installed
2023-06-03 14:46:22,724:INFO:              mlflow: Not installed
2023-06-03 14:46:22,724:INFO:              gradio: Not installed
2023-06-03 14:46:22,724:INFO:             fastapi: Not installed
2023-06-03 14:46:22,724:INFO:             uvicorn: Not installed
2023-06-03 14:46:22,724:INFO:              m2cgen: Not installed
2023-06-03 14:46:22,724:INFO:           evidently: Not installed
2023-06-03 14:46:22,724:INFO:               fugue: Not installed
2023-06-03 14:46:22,724:INFO:           streamlit: Not installed
2023-06-03 14:46:22,725:INFO:             prophet: Not installed
2023-06-03 14:46:22,725:INFO:None
2023-06-03 14:46:22,725:INFO:Set up data.
2023-06-03 14:46:22,733:INFO:Set up train/test split.
2023-06-03 14:46:22,740:INFO:Set up index.
2023-06-03 14:46:22,740:INFO:Set up folding strategy.
2023-06-03 14:46:22,740:INFO:Assigning column types.
2023-06-03 14:46:22,744:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:46:22,774:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,775:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,826:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,845:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:46:22,876:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,926:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:46:22,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,945:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:46:22,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:22,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,039:INFO:Preparing preprocessing pipeline...
2023-06-03 14:46:23,040:INFO:Set up simple imputation.
2023-06-03 14:46:23,040:INFO:Set up feature normalization.
2023-06-03 14:46:23,056:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:46:23,059:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-06-03 14:46:23,059:INFO:Creating final display dataframe.
2023-06-03 14:46:23,116:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape       (10150, 12)
4        Transformed data shape       (10150, 12)
5   Transformed train set shape        (7105, 12)
6    Transformed test set shape        (3045, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              dcc6
2023-06-03 14:46:23,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,249:INFO:setup() successfully completed in 0.55s...............
2023-06-03 14:46:23,305:INFO:gpu_param set to False
2023-06-03 14:46:23,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:46:23,468:INFO:Initializing compare_models()
2023-06-03 14:46:23,469:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:46:23,469:INFO:Checking exceptions
2023-06-03 14:46:23,477:INFO:Preparing display monitor
2023-06-03 14:46:23,505:INFO:Initializing Logistic Regression
2023-06-03 14:46:23,505:INFO:Total runtime is 3.0040740966796874e-06 minutes
2023-06-03 14:46:23,508:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:23,509:INFO:Initializing create_model()
2023-06-03 14:46:23,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:23,509:INFO:Checking exceptions
2023-06-03 14:46:23,509:INFO:Importing libraries
2023-06-03 14:46:23,509:INFO:Copying training dataset
2023-06-03 14:46:23,514:INFO:Defining folds
2023-06-03 14:46:23,514:INFO:Declaring metric variables
2023-06-03 14:46:23,517:INFO:Importing untrained model
2023-06-03 14:46:23,520:INFO:Logistic Regression Imported successfully
2023-06-03 14:46:23,525:INFO:Starting cross validation
2023-06-03 14:46:23,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:23,661:INFO:Calculating mean and std
2023-06-03 14:46:23,662:INFO:Creating metrics dataframe
2023-06-03 14:46:23,683:INFO:Uploading results into container
2023-06-03 14:46:23,684:INFO:Uploading model into container now
2023-06-03 14:46:23,684:INFO:_master_model_container: 1
2023-06-03 14:46:23,684:INFO:_display_container: 2
2023-06-03 14:46:23,684:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:46:23,684:INFO:create_model() successfully completed......................................
2023-06-03 14:46:23,790:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:23,790:INFO:Creating metrics dataframe
2023-06-03 14:46:23,797:INFO:Initializing K Neighbors Classifier
2023-06-03 14:46:23,798:INFO:Total runtime is 0.004876883824666341 minutes
2023-06-03 14:46:23,801:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:23,802:INFO:Initializing create_model()
2023-06-03 14:46:23,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:23,802:INFO:Checking exceptions
2023-06-03 14:46:23,802:INFO:Importing libraries
2023-06-03 14:46:23,802:INFO:Copying training dataset
2023-06-03 14:46:23,813:INFO:Defining folds
2023-06-03 14:46:23,813:INFO:Declaring metric variables
2023-06-03 14:46:23,819:INFO:Importing untrained model
2023-06-03 14:46:23,825:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:46:23,838:INFO:Starting cross validation
2023-06-03 14:46:23,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:24,050:INFO:Calculating mean and std
2023-06-03 14:46:24,050:INFO:Creating metrics dataframe
2023-06-03 14:46:24,079:INFO:Uploading results into container
2023-06-03 14:46:24,080:INFO:Uploading model into container now
2023-06-03 14:46:24,080:INFO:_master_model_container: 2
2023-06-03 14:46:24,080:INFO:_display_container: 2
2023-06-03 14:46:24,080:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:46:24,080:INFO:create_model() successfully completed......................................
2023-06-03 14:46:24,181:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:24,182:INFO:Creating metrics dataframe
2023-06-03 14:46:24,189:INFO:Initializing Naive Bayes
2023-06-03 14:46:24,189:INFO:Total runtime is 0.01140838066736857 minutes
2023-06-03 14:46:24,192:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:24,192:INFO:Initializing create_model()
2023-06-03 14:46:24,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:24,192:INFO:Checking exceptions
2023-06-03 14:46:24,192:INFO:Importing libraries
2023-06-03 14:46:24,192:INFO:Copying training dataset
2023-06-03 14:46:24,196:INFO:Defining folds
2023-06-03 14:46:24,196:INFO:Declaring metric variables
2023-06-03 14:46:24,199:INFO:Importing untrained model
2023-06-03 14:46:24,201:INFO:Naive Bayes Imported successfully
2023-06-03 14:46:24,206:INFO:Starting cross validation
2023-06-03 14:46:24,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:24,337:INFO:Calculating mean and std
2023-06-03 14:46:24,338:INFO:Creating metrics dataframe
2023-06-03 14:46:24,362:INFO:Uploading results into container
2023-06-03 14:46:24,363:INFO:Uploading model into container now
2023-06-03 14:46:24,363:INFO:_master_model_container: 3
2023-06-03 14:46:24,363:INFO:_display_container: 2
2023-06-03 14:46:24,363:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:46:24,363:INFO:create_model() successfully completed......................................
2023-06-03 14:46:24,463:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:24,463:INFO:Creating metrics dataframe
2023-06-03 14:46:24,471:INFO:Initializing Decision Tree Classifier
2023-06-03 14:46:24,471:INFO:Total runtime is 0.016099901994069417 minutes
2023-06-03 14:46:24,473:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:24,474:INFO:Initializing create_model()
2023-06-03 14:46:24,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:24,474:INFO:Checking exceptions
2023-06-03 14:46:24,474:INFO:Importing libraries
2023-06-03 14:46:24,474:INFO:Copying training dataset
2023-06-03 14:46:24,478:INFO:Defining folds
2023-06-03 14:46:24,478:INFO:Declaring metric variables
2023-06-03 14:46:24,481:INFO:Importing untrained model
2023-06-03 14:46:24,487:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:46:24,496:INFO:Starting cross validation
2023-06-03 14:46:24,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:24,667:INFO:Calculating mean and std
2023-06-03 14:46:24,669:INFO:Creating metrics dataframe
2023-06-03 14:46:24,702:INFO:Uploading results into container
2023-06-03 14:46:24,702:INFO:Uploading model into container now
2023-06-03 14:46:24,703:INFO:_master_model_container: 4
2023-06-03 14:46:24,703:INFO:_display_container: 2
2023-06-03 14:46:24,703:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:46:24,703:INFO:create_model() successfully completed......................................
2023-06-03 14:46:24,805:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:24,805:INFO:Creating metrics dataframe
2023-06-03 14:46:24,813:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:46:24,813:INFO:Total runtime is 0.02180893023808797 minutes
2023-06-03 14:46:24,817:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:24,817:INFO:Initializing create_model()
2023-06-03 14:46:24,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:24,818:INFO:Checking exceptions
2023-06-03 14:46:24,818:INFO:Importing libraries
2023-06-03 14:46:24,818:INFO:Copying training dataset
2023-06-03 14:46:24,829:INFO:Defining folds
2023-06-03 14:46:24,829:INFO:Declaring metric variables
2023-06-03 14:46:24,836:INFO:Importing untrained model
2023-06-03 14:46:24,841:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:46:24,850:INFO:Starting cross validation
2023-06-03 14:46:24,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:24,919:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,921:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,922:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,923:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,928:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,929:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,929:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,931:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,933:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,933:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,934:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,934:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,936:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,939:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,939:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,940:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,942:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,946:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:46:24,953:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:24,976:INFO:Calculating mean and std
2023-06-03 14:46:24,977:INFO:Creating metrics dataframe
2023-06-03 14:46:24,999:INFO:Uploading results into container
2023-06-03 14:46:25,000:INFO:Uploading model into container now
2023-06-03 14:46:25,000:INFO:_master_model_container: 5
2023-06-03 14:46:25,000:INFO:_display_container: 2
2023-06-03 14:46:25,001:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:46:25,001:INFO:create_model() successfully completed......................................
2023-06-03 14:46:25,100:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:25,100:INFO:Creating metrics dataframe
2023-06-03 14:46:25,109:INFO:Initializing Ridge Classifier
2023-06-03 14:46:25,109:INFO:Total runtime is 0.02673893372217814 minutes
2023-06-03 14:46:25,116:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:25,116:INFO:Initializing create_model()
2023-06-03 14:46:25,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:25,117:INFO:Checking exceptions
2023-06-03 14:46:25,117:INFO:Importing libraries
2023-06-03 14:46:25,117:INFO:Copying training dataset
2023-06-03 14:46:25,126:INFO:Defining folds
2023-06-03 14:46:25,127:INFO:Declaring metric variables
2023-06-03 14:46:25,131:INFO:Importing untrained model
2023-06-03 14:46:25,135:INFO:Ridge Classifier Imported successfully
2023-06-03 14:46:25,141:INFO:Starting cross validation
2023-06-03 14:46:25,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:25,204:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,214:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,216:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,217:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,220:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,221:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,225:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,225:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,235:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,239:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:46:25,269:INFO:Calculating mean and std
2023-06-03 14:46:25,272:INFO:Creating metrics dataframe
2023-06-03 14:46:25,302:INFO:Uploading results into container
2023-06-03 14:46:25,303:INFO:Uploading model into container now
2023-06-03 14:46:25,303:INFO:_master_model_container: 6
2023-06-03 14:46:25,303:INFO:_display_container: 2
2023-06-03 14:46:25,303:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:46:25,303:INFO:create_model() successfully completed......................................
2023-06-03 14:46:25,402:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:25,402:INFO:Creating metrics dataframe
2023-06-03 14:46:25,411:INFO:Initializing Random Forest Classifier
2023-06-03 14:46:25,411:INFO:Total runtime is 0.03176862398783366 minutes
2023-06-03 14:46:25,414:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:25,414:INFO:Initializing create_model()
2023-06-03 14:46:25,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:25,414:INFO:Checking exceptions
2023-06-03 14:46:25,414:INFO:Importing libraries
2023-06-03 14:46:25,414:INFO:Copying training dataset
2023-06-03 14:46:25,418:INFO:Defining folds
2023-06-03 14:46:25,419:INFO:Declaring metric variables
2023-06-03 14:46:25,421:INFO:Importing untrained model
2023-06-03 14:46:25,424:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:46:25,428:INFO:Starting cross validation
2023-06-03 14:46:25,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:25,879:INFO:Calculating mean and std
2023-06-03 14:46:25,881:INFO:Creating metrics dataframe
2023-06-03 14:46:25,906:INFO:Uploading results into container
2023-06-03 14:46:25,906:INFO:Uploading model into container now
2023-06-03 14:46:25,907:INFO:_master_model_container: 7
2023-06-03 14:46:25,907:INFO:_display_container: 2
2023-06-03 14:46:25,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:25,907:INFO:create_model() successfully completed......................................
2023-06-03 14:46:26,007:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:26,007:INFO:Creating metrics dataframe
2023-06-03 14:46:26,016:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:46:26,016:INFO:Total runtime is 0.04185508886973063 minutes
2023-06-03 14:46:26,019:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:26,019:INFO:Initializing create_model()
2023-06-03 14:46:26,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:26,019:INFO:Checking exceptions
2023-06-03 14:46:26,019:INFO:Importing libraries
2023-06-03 14:46:26,019:INFO:Copying training dataset
2023-06-03 14:46:26,024:INFO:Defining folds
2023-06-03 14:46:26,024:INFO:Declaring metric variables
2023-06-03 14:46:26,027:INFO:Importing untrained model
2023-06-03 14:46:26,029:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:46:26,034:INFO:Starting cross validation
2023-06-03 14:46:26,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:26,202:INFO:Calculating mean and std
2023-06-03 14:46:26,204:INFO:Creating metrics dataframe
2023-06-03 14:46:26,246:INFO:Uploading results into container
2023-06-03 14:46:26,247:INFO:Uploading model into container now
2023-06-03 14:46:26,247:INFO:_master_model_container: 8
2023-06-03 14:46:26,247:INFO:_display_container: 2
2023-06-03 14:46:26,248:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:46:26,248:INFO:create_model() successfully completed......................................
2023-06-03 14:46:26,353:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:26,353:INFO:Creating metrics dataframe
2023-06-03 14:46:26,362:INFO:Initializing Ada Boost Classifier
2023-06-03 14:46:26,362:INFO:Total runtime is 0.047623880704243976 minutes
2023-06-03 14:46:26,366:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:26,366:INFO:Initializing create_model()
2023-06-03 14:46:26,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:26,366:INFO:Checking exceptions
2023-06-03 14:46:26,366:INFO:Importing libraries
2023-06-03 14:46:26,366:INFO:Copying training dataset
2023-06-03 14:46:26,370:INFO:Defining folds
2023-06-03 14:46:26,371:INFO:Declaring metric variables
2023-06-03 14:46:26,374:INFO:Importing untrained model
2023-06-03 14:46:26,377:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:46:26,382:INFO:Starting cross validation
2023-06-03 14:46:26,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:26,584:INFO:Calculating mean and std
2023-06-03 14:46:26,585:INFO:Creating metrics dataframe
2023-06-03 14:46:26,615:INFO:Uploading results into container
2023-06-03 14:46:26,615:INFO:Uploading model into container now
2023-06-03 14:46:26,616:INFO:_master_model_container: 9
2023-06-03 14:46:26,616:INFO:_display_container: 2
2023-06-03 14:46:26,616:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:46:26,616:INFO:create_model() successfully completed......................................
2023-06-03 14:46:26,716:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:26,717:INFO:Creating metrics dataframe
2023-06-03 14:46:26,726:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:46:26,726:INFO:Total runtime is 0.053682994842529294 minutes
2023-06-03 14:46:26,729:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:26,729:INFO:Initializing create_model()
2023-06-03 14:46:26,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:26,729:INFO:Checking exceptions
2023-06-03 14:46:26,729:INFO:Importing libraries
2023-06-03 14:46:26,729:INFO:Copying training dataset
2023-06-03 14:46:26,733:INFO:Defining folds
2023-06-03 14:46:26,734:INFO:Declaring metric variables
2023-06-03 14:46:26,737:INFO:Importing untrained model
2023-06-03 14:46:26,743:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:46:26,752:INFO:Starting cross validation
2023-06-03 14:46:26,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:27,192:INFO:Calculating mean and std
2023-06-03 14:46:27,193:INFO:Creating metrics dataframe
2023-06-03 14:46:27,225:INFO:Uploading results into container
2023-06-03 14:46:27,226:INFO:Uploading model into container now
2023-06-03 14:46:27,227:INFO:_master_model_container: 10
2023-06-03 14:46:27,227:INFO:_display_container: 2
2023-06-03 14:46:27,227:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:46:27,227:INFO:create_model() successfully completed......................................
2023-06-03 14:46:27,329:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:27,329:INFO:Creating metrics dataframe
2023-06-03 14:46:27,339:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:46:27,339:INFO:Total runtime is 0.06389806667963663 minutes
2023-06-03 14:46:27,342:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:27,342:INFO:Initializing create_model()
2023-06-03 14:46:27,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:27,342:INFO:Checking exceptions
2023-06-03 14:46:27,342:INFO:Importing libraries
2023-06-03 14:46:27,342:INFO:Copying training dataset
2023-06-03 14:46:27,347:INFO:Defining folds
2023-06-03 14:46:27,347:INFO:Declaring metric variables
2023-06-03 14:46:27,350:INFO:Importing untrained model
2023-06-03 14:46:27,353:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:46:27,359:INFO:Starting cross validation
2023-06-03 14:46:27,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:27,498:INFO:Calculating mean and std
2023-06-03 14:46:27,500:INFO:Creating metrics dataframe
2023-06-03 14:46:27,535:INFO:Uploading results into container
2023-06-03 14:46:27,535:INFO:Uploading model into container now
2023-06-03 14:46:27,536:INFO:_master_model_container: 11
2023-06-03 14:46:27,536:INFO:_display_container: 2
2023-06-03 14:46:27,536:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:46:27,536:INFO:create_model() successfully completed......................................
2023-06-03 14:46:27,643:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:27,643:INFO:Creating metrics dataframe
2023-06-03 14:46:27,653:INFO:Initializing Extra Trees Classifier
2023-06-03 14:46:27,653:INFO:Total runtime is 0.06913416783014932 minutes
2023-06-03 14:46:27,656:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:27,656:INFO:Initializing create_model()
2023-06-03 14:46:27,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:27,657:INFO:Checking exceptions
2023-06-03 14:46:27,657:INFO:Importing libraries
2023-06-03 14:46:27,657:INFO:Copying training dataset
2023-06-03 14:46:27,668:INFO:Defining folds
2023-06-03 14:46:27,668:INFO:Declaring metric variables
2023-06-03 14:46:27,672:INFO:Importing untrained model
2023-06-03 14:46:27,677:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:46:27,683:INFO:Starting cross validation
2023-06-03 14:46:27,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:28,207:INFO:Calculating mean and std
2023-06-03 14:46:28,209:INFO:Creating metrics dataframe
2023-06-03 14:46:28,247:INFO:Uploading results into container
2023-06-03 14:46:28,248:INFO:Uploading model into container now
2023-06-03 14:46:28,248:INFO:_master_model_container: 12
2023-06-03 14:46:28,249:INFO:_display_container: 2
2023-06-03 14:46:28,249:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:28,249:INFO:create_model() successfully completed......................................
2023-06-03 14:46:28,352:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:28,352:INFO:Creating metrics dataframe
2023-06-03 14:46:28,361:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:46:28,361:INFO:Total runtime is 0.0809430440266927 minutes
2023-06-03 14:46:28,365:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:28,365:INFO:Initializing create_model()
2023-06-03 14:46:28,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:28,365:INFO:Checking exceptions
2023-06-03 14:46:28,365:INFO:Importing libraries
2023-06-03 14:46:28,365:INFO:Copying training dataset
2023-06-03 14:46:28,376:INFO:Defining folds
2023-06-03 14:46:28,376:INFO:Declaring metric variables
2023-06-03 14:46:28,381:INFO:Importing untrained model
2023-06-03 14:46:28,385:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:46:28,392:INFO:Starting cross validation
2023-06-03 14:46:28,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:28,788:INFO:Calculating mean and std
2023-06-03 14:46:28,790:INFO:Creating metrics dataframe
2023-06-03 14:46:28,821:INFO:Uploading results into container
2023-06-03 14:46:28,822:INFO:Uploading model into container now
2023-06-03 14:46:28,822:INFO:_master_model_container: 13
2023-06-03 14:46:28,822:INFO:_display_container: 2
2023-06-03 14:46:28,823:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:46:28,823:INFO:create_model() successfully completed......................................
2023-06-03 14:46:28,922:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:28,922:INFO:Creating metrics dataframe
2023-06-03 14:46:28,931:INFO:Initializing Dummy Classifier
2023-06-03 14:46:28,931:INFO:Total runtime is 0.09044187863667805 minutes
2023-06-03 14:46:28,934:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:28,934:INFO:Initializing create_model()
2023-06-03 14:46:28,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55802fd0>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:28,934:INFO:Checking exceptions
2023-06-03 14:46:28,934:INFO:Importing libraries
2023-06-03 14:46:28,934:INFO:Copying training dataset
2023-06-03 14:46:28,939:INFO:Defining folds
2023-06-03 14:46:28,939:INFO:Declaring metric variables
2023-06-03 14:46:28,942:INFO:Importing untrained model
2023-06-03 14:46:28,944:INFO:Dummy Classifier Imported successfully
2023-06-03 14:46:28,949:INFO:Starting cross validation
2023-06-03 14:46:28,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:29,027:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,036:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,043:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,048:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,055:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,055:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,069:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,077:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,079:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,084:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:46:29,106:INFO:Calculating mean and std
2023-06-03 14:46:29,108:INFO:Creating metrics dataframe
2023-06-03 14:46:29,133:INFO:Uploading results into container
2023-06-03 14:46:29,133:INFO:Uploading model into container now
2023-06-03 14:46:29,133:INFO:_master_model_container: 14
2023-06-03 14:46:29,133:INFO:_display_container: 2
2023-06-03 14:46:29,134:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:46:29,134:INFO:create_model() successfully completed......................................
2023-06-03 14:46:29,234:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:29,234:INFO:Creating metrics dataframe
2023-06-03 14:46:29,252:INFO:Initializing create_model()
2023-06-03 14:46:29,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:29,252:INFO:Checking exceptions
2023-06-03 14:46:29,254:INFO:Importing libraries
2023-06-03 14:46:29,254:INFO:Copying training dataset
2023-06-03 14:46:29,258:INFO:Defining folds
2023-06-03 14:46:29,258:INFO:Declaring metric variables
2023-06-03 14:46:29,258:INFO:Importing untrained model
2023-06-03 14:46:29,258:INFO:Declaring custom model
2023-06-03 14:46:29,258:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:46:29,259:INFO:Cross validation set to False
2023-06-03 14:46:29,259:INFO:Fitting Model
2023-06-03 14:46:29,419:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:29,419:INFO:create_model() successfully completed......................................
2023-06-03 14:46:29,523:INFO:Initializing create_model()
2023-06-03 14:46:29,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:29,523:INFO:Checking exceptions
2023-06-03 14:46:29,524:INFO:Importing libraries
2023-06-03 14:46:29,524:INFO:Copying training dataset
2023-06-03 14:46:29,528:INFO:Defining folds
2023-06-03 14:46:29,528:INFO:Declaring metric variables
2023-06-03 14:46:29,529:INFO:Importing untrained model
2023-06-03 14:46:29,529:INFO:Declaring custom model
2023-06-03 14:46:29,529:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:46:29,530:INFO:Cross validation set to False
2023-06-03 14:46:29,530:INFO:Fitting Model
2023-06-03 14:46:29,595:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:29,595:INFO:create_model() successfully completed......................................
2023-06-03 14:46:29,700:INFO:Initializing create_model()
2023-06-03 14:46:29,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:29,700:INFO:Checking exceptions
2023-06-03 14:46:29,702:INFO:Importing libraries
2023-06-03 14:46:29,702:INFO:Copying training dataset
2023-06-03 14:46:29,705:INFO:Defining folds
2023-06-03 14:46:29,706:INFO:Declaring metric variables
2023-06-03 14:46:29,706:INFO:Importing untrained model
2023-06-03 14:46:29,706:INFO:Declaring custom model
2023-06-03 14:46:29,706:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:46:29,707:INFO:Cross validation set to False
2023-06-03 14:46:29,707:INFO:Fitting Model
2023-06-03 14:46:29,737:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:46:29,737:INFO:create_model() successfully completed......................................
2023-06-03 14:46:29,842:INFO:Initializing create_model()
2023-06-03 14:46:29,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:29,842:INFO:Checking exceptions
2023-06-03 14:46:29,845:INFO:Importing libraries
2023-06-03 14:46:29,845:INFO:Copying training dataset
2023-06-03 14:46:29,854:INFO:Defining folds
2023-06-03 14:46:29,854:INFO:Declaring metric variables
2023-06-03 14:46:29,854:INFO:Importing untrained model
2023-06-03 14:46:29,855:INFO:Declaring custom model
2023-06-03 14:46:29,856:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:46:29,857:INFO:Cross validation set to False
2023-06-03 14:46:29,857:INFO:Fitting Model
2023-06-03 14:46:29,898:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:46:29,898:INFO:create_model() successfully completed......................................
2023-06-03 14:46:30,002:INFO:Initializing create_model()
2023-06-03 14:46:30,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:30,003:INFO:Checking exceptions
2023-06-03 14:46:30,004:INFO:Importing libraries
2023-06-03 14:46:30,004:INFO:Copying training dataset
2023-06-03 14:46:30,008:INFO:Defining folds
2023-06-03 14:46:30,008:INFO:Declaring metric variables
2023-06-03 14:46:30,008:INFO:Importing untrained model
2023-06-03 14:46:30,008:INFO:Declaring custom model
2023-06-03 14:46:30,009:INFO:Logistic Regression Imported successfully
2023-06-03 14:46:30,009:INFO:Cross validation set to False
2023-06-03 14:46:30,009:INFO:Fitting Model
2023-06-03 14:46:30,028:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:46:30,028:INFO:create_model() successfully completed......................................
2023-06-03 14:46:30,145:INFO:_master_model_container: 14
2023-06-03 14:46:30,146:INFO:_display_container: 2
2023-06-03 14:46:30,147:INFO:[ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2023-06-03 14:46:30,147:INFO:compare_models() successfully completed......................................
2023-06-03 14:46:30,352:INFO:Initializing tune_model()
2023-06-03 14:46:30,352:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>)
2023-06-03 14:46:30,352:INFO:Checking exceptions
2023-06-03 14:46:30,386:INFO:Copying training dataset
2023-06-03 14:46:30,392:INFO:Checking base model
2023-06-03 14:46:30,393:INFO:Base model : Extra Trees Classifier
2023-06-03 14:46:30,400:INFO:Declaring metric variables
2023-06-03 14:46:30,406:INFO:Defining Hyperparameters
2023-06-03 14:46:30,539:INFO:Tuning with n_jobs=-1
2023-06-03 14:46:30,539:INFO:Initializing RandomizedSearchCV
2023-06-03 14:46:36,286:INFO:best_params: {'actual_estimator__n_estimators': 200, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-06-03 14:46:36,287:INFO:Hyperparameter search completed
2023-06-03 14:46:36,287:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:36,288:INFO:Initializing create_model()
2023-06-03 14:46:36,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae55150d0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 200, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-06-03 14:46:36,288:INFO:Checking exceptions
2023-06-03 14:46:36,288:INFO:Importing libraries
2023-06-03 14:46:36,288:INFO:Copying training dataset
2023-06-03 14:46:36,294:INFO:Defining folds
2023-06-03 14:46:36,294:INFO:Declaring metric variables
2023-06-03 14:46:36,297:INFO:Importing untrained model
2023-06-03 14:46:36,297:INFO:Declaring custom model
2023-06-03 14:46:36,301:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:46:36,307:INFO:Starting cross validation
2023-06-03 14:46:36,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:36,936:INFO:Calculating mean and std
2023-06-03 14:46:36,939:INFO:Creating metrics dataframe
2023-06-03 14:46:36,944:INFO:Finalizing model
2023-06-03 14:46:37,908:INFO:Uploading results into container
2023-06-03 14:46:37,909:INFO:Uploading model into container now
2023-06-03 14:46:37,909:INFO:_master_model_container: 15
2023-06-03 14:46:37,910:INFO:_display_container: 3
2023-06-03 14:46:37,910:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=6, max_features=1.0, max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=4, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2023-06-03 14:46:37,910:INFO:create_model() successfully completed......................................
2023-06-03 14:46:38,018:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:38,018:INFO:choose_better activated
2023-06-03 14:46:38,021:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:38,021:INFO:Initializing create_model()
2023-06-03 14:46:38,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:38,021:INFO:Checking exceptions
2023-06-03 14:46:38,023:INFO:Importing libraries
2023-06-03 14:46:38,023:INFO:Copying training dataset
2023-06-03 14:46:38,027:INFO:Defining folds
2023-06-03 14:46:38,027:INFO:Declaring metric variables
2023-06-03 14:46:38,027:INFO:Importing untrained model
2023-06-03 14:46:38,027:INFO:Declaring custom model
2023-06-03 14:46:38,028:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:46:38,028:INFO:Starting cross validation
2023-06-03 14:46:38,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:38,611:INFO:Calculating mean and std
2023-06-03 14:46:38,611:INFO:Creating metrics dataframe
2023-06-03 14:46:38,614:INFO:Finalizing model
2023-06-03 14:46:38,798:INFO:Uploading results into container
2023-06-03 14:46:38,799:INFO:Uploading model into container now
2023-06-03 14:46:38,799:INFO:_master_model_container: 16
2023-06-03 14:46:38,799:INFO:_display_container: 4
2023-06-03 14:46:38,800:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:38,800:INFO:create_model() successfully completed......................................
2023-06-03 14:46:38,899:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:38,899:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.2926
2023-06-03 14:46:38,900:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                     class_weight='balanced_subsample', criterion='gini',
                     max_depth=6, max_features=1.0, max_leaf_nodes=None,
                     max_samples=None, min_impurity_decrease=0,
                     min_samples_leaf=4, min_samples_split=7,
                     min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False) result for Accuracy is 0.276
2023-06-03 14:46:38,900:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) is best model
2023-06-03 14:46:38,900:INFO:choose_better completed
2023-06-03 14:46:38,900:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-03 14:46:38,907:INFO:_master_model_container: 16
2023-06-03 14:46:38,907:INFO:_display_container: 3
2023-06-03 14:46:38,908:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:38,908:INFO:tune_model() successfully completed......................................
2023-06-03 14:46:39,035:INFO:Initializing tune_model()
2023-06-03 14:46:39,036:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>)
2023-06-03 14:46:39,036:INFO:Checking exceptions
2023-06-03 14:46:39,049:INFO:Copying training dataset
2023-06-03 14:46:39,052:INFO:Checking base model
2023-06-03 14:46:39,052:INFO:Base model : Random Forest Classifier
2023-06-03 14:46:39,055:INFO:Declaring metric variables
2023-06-03 14:46:39,061:INFO:Defining Hyperparameters
2023-06-03 14:46:39,171:INFO:Tuning with n_jobs=-1
2023-06-03 14:46:39,171:INFO:Initializing RandomizedSearchCV
2023-06-03 14:46:49,004:INFO:best_params: {'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': True}
2023-06-03 14:46:49,005:INFO:Hyperparameter search completed
2023-06-03 14:46:49,005:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:49,005:INFO:Initializing create_model()
2023-06-03 14:46:49,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b57935580>, model_only=True, return_train_score=False, kwargs={'n_estimators': 130, 'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 4, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': True})
2023-06-03 14:46:49,005:INFO:Checking exceptions
2023-06-03 14:46:49,006:INFO:Importing libraries
2023-06-03 14:46:49,006:INFO:Copying training dataset
2023-06-03 14:46:49,010:INFO:Defining folds
2023-06-03 14:46:49,010:INFO:Declaring metric variables
2023-06-03 14:46:49,014:INFO:Importing untrained model
2023-06-03 14:46:49,014:INFO:Declaring custom model
2023-06-03 14:46:49,017:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:46:49,027:INFO:Starting cross validation
2023-06-03 14:46:49,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:49,591:INFO:Calculating mean and std
2023-06-03 14:46:49,594:INFO:Creating metrics dataframe
2023-06-03 14:46:49,606:INFO:Finalizing model
2023-06-03 14:46:50,813:INFO:Uploading results into container
2023-06-03 14:46:50,814:INFO:Uploading model into container now
2023-06-03 14:46:50,814:INFO:_master_model_container: 17
2023-06-03 14:46:50,814:INFO:_display_container: 4
2023-06-03 14:46:50,815:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=130,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-06-03 14:46:50,815:INFO:create_model() successfully completed......................................
2023-06-03 14:46:50,918:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:50,918:INFO:choose_better activated
2023-06-03 14:46:50,921:INFO:SubProcess create_model() called ==================================
2023-06-03 14:46:50,921:INFO:Initializing create_model()
2023-06-03 14:46:50,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:46:50,921:INFO:Checking exceptions
2023-06-03 14:46:50,923:INFO:Importing libraries
2023-06-03 14:46:50,923:INFO:Copying training dataset
2023-06-03 14:46:50,932:INFO:Defining folds
2023-06-03 14:46:50,932:INFO:Declaring metric variables
2023-06-03 14:46:50,932:INFO:Importing untrained model
2023-06-03 14:46:50,932:INFO:Declaring custom model
2023-06-03 14:46:50,934:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:46:50,934:INFO:Starting cross validation
2023-06-03 14:46:50,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:46:51,435:INFO:Calculating mean and std
2023-06-03 14:46:51,435:INFO:Creating metrics dataframe
2023-06-03 14:46:51,437:INFO:Finalizing model
2023-06-03 14:46:51,554:INFO:Uploading results into container
2023-06-03 14:46:51,555:INFO:Uploading model into container now
2023-06-03 14:46:51,555:INFO:_master_model_container: 18
2023-06-03 14:46:51,555:INFO:_display_container: 5
2023-06-03 14:46:51,555:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:51,555:INFO:create_model() successfully completed......................................
2023-06-03 14:46:51,655:INFO:SubProcess create_model() end ==================================
2023-06-03 14:46:51,656:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.2899
2023-06-03 14:46:51,656:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=4, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0002,
                       min_samples_leaf=5, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=130,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.269
2023-06-03 14:46:51,656:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-06-03 14:46:51,656:INFO:choose_better completed
2023-06-03 14:46:51,656:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-03 14:46:51,664:INFO:_master_model_container: 18
2023-06-03 14:46:51,664:INFO:_display_container: 4
2023-06-03 14:46:51,664:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:46:51,664:INFO:tune_model() successfully completed......................................
2023-06-03 14:46:51,778:INFO:Initializing tune_model()
2023-06-03 14:46:51,778:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>)
2023-06-03 14:46:51,778:INFO:Checking exceptions
2023-06-03 14:46:51,790:INFO:Copying training dataset
2023-06-03 14:46:51,793:INFO:Checking base model
2023-06-03 14:46:51,793:INFO:Base model : Gradient Boosting Classifier
2023-06-03 14:46:51,796:INFO:Declaring metric variables
2023-06-03 14:46:51,798:INFO:Defining Hyperparameters
2023-06-03 14:46:51,899:INFO:Tuning with n_jobs=-1
2023-06-03 14:46:51,899:INFO:Initializing RandomizedSearchCV
2023-06-03 14:47:11,289:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:18,772:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:18,973:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:18,982:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:19,098:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:19,110:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:19,179:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:19,261:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:19,273:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:19,274:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:19,384:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:30,882:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,138:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,168:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,181:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,260:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,265:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,397:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,462:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:31,834:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:32,008:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:47:37,161:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-03 14:47:37,162:INFO:Hyperparameter search completed
2023-06-03 14:47:37,162:INFO:SubProcess create_model() called ==================================
2023-06-03 14:47:37,162:INFO:Initializing create_model()
2023-06-03 14:47:37,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b5530f370>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-03 14:47:37,162:INFO:Checking exceptions
2023-06-03 14:47:37,162:INFO:Importing libraries
2023-06-03 14:47:37,163:INFO:Copying training dataset
2023-06-03 14:47:37,167:INFO:Defining folds
2023-06-03 14:47:37,168:INFO:Declaring metric variables
2023-06-03 14:47:37,171:INFO:Importing untrained model
2023-06-03 14:47:37,171:INFO:Declaring custom model
2023-06-03 14:47:37,174:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:47:37,180:INFO:Starting cross validation
2023-06-03 14:47:37,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:47:37,942:INFO:Calculating mean and std
2023-06-03 14:47:37,945:INFO:Creating metrics dataframe
2023-06-03 14:47:37,957:INFO:Finalizing model
2023-06-03 14:47:41,605:INFO:Uploading results into container
2023-06-03 14:47:41,605:INFO:Uploading model into container now
2023-06-03 14:47:41,606:INFO:_master_model_container: 19
2023-06-03 14:47:41,606:INFO:_display_container: 5
2023-06-03 14:47:41,606:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:47:41,606:INFO:create_model() successfully completed......................................
2023-06-03 14:47:41,713:INFO:SubProcess create_model() end ==================================
2023-06-03 14:47:41,713:INFO:choose_better activated
2023-06-03 14:47:41,716:INFO:SubProcess create_model() called ==================================
2023-06-03 14:47:41,717:INFO:Initializing create_model()
2023-06-03 14:47:41,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:47:41,717:INFO:Checking exceptions
2023-06-03 14:47:41,718:INFO:Importing libraries
2023-06-03 14:47:41,718:INFO:Copying training dataset
2023-06-03 14:47:41,722:INFO:Defining folds
2023-06-03 14:47:41,722:INFO:Declaring metric variables
2023-06-03 14:47:41,722:INFO:Importing untrained model
2023-06-03 14:47:41,723:INFO:Declaring custom model
2023-06-03 14:47:41,723:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:47:41,724:INFO:Starting cross validation
2023-06-03 14:47:41,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:47:42,196:INFO:Calculating mean and std
2023-06-03 14:47:42,197:INFO:Creating metrics dataframe
2023-06-03 14:47:42,201:INFO:Finalizing model
2023-06-03 14:47:42,312:INFO:Uploading results into container
2023-06-03 14:47:42,313:INFO:Uploading model into container now
2023-06-03 14:47:42,313:INFO:_master_model_container: 20
2023-06-03 14:47:42,313:INFO:_display_container: 6
2023-06-03 14:47:42,313:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:47:42,313:INFO:create_model() successfully completed......................................
2023-06-03 14:47:42,415:INFO:SubProcess create_model() end ==================================
2023-06-03 14:47:42,416:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.2801
2023-06-03 14:47:42,416:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.2849
2023-06-03 14:47:42,417:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-03 14:47:42,417:INFO:choose_better completed
2023-06-03 14:47:42,423:INFO:_master_model_container: 20
2023-06-03 14:47:42,424:INFO:_display_container: 5
2023-06-03 14:47:42,424:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:47:42,424:INFO:tune_model() successfully completed......................................
2023-06-03 14:47:42,542:INFO:Initializing tune_model()
2023-06-03 14:47:42,542:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>)
2023-06-03 14:47:42,542:INFO:Checking exceptions
2023-06-03 14:47:42,563:INFO:Copying training dataset
2023-06-03 14:47:42,569:INFO:Checking base model
2023-06-03 14:47:42,569:INFO:Base model : Light Gradient Boosting Machine
2023-06-03 14:47:42,574:INFO:Declaring metric variables
2023-06-03 14:47:42,579:INFO:Defining Hyperparameters
2023-06-03 14:47:42,683:INFO:Tuning with n_jobs=-1
2023-06-03 14:47:42,683:INFO:Initializing RandomizedSearchCV
2023-06-03 14:47:50,483:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.005, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.8}
2023-06-03 14:47:50,484:INFO:Hyperparameter search completed
2023-06-03 14:47:50,484:INFO:SubProcess create_model() called ==================================
2023-06-03 14:47:50,485:INFO:Initializing create_model()
2023-06-03 14:47:50,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55368910>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 0.001, 'num_leaves': 80, 'n_estimators': 210, 'min_split_gain': 0.5, 'min_child_samples': 96, 'learning_rate': 0.005, 'feature_fraction': 1.0, 'bagging_freq': 3, 'bagging_fraction': 0.8})
2023-06-03 14:47:50,485:INFO:Checking exceptions
2023-06-03 14:47:50,485:INFO:Importing libraries
2023-06-03 14:47:50,485:INFO:Copying training dataset
2023-06-03 14:47:50,490:INFO:Defining folds
2023-06-03 14:47:50,490:INFO:Declaring metric variables
2023-06-03 14:47:50,493:INFO:Importing untrained model
2023-06-03 14:47:50,493:INFO:Declaring custom model
2023-06-03 14:47:50,497:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:47:50,502:INFO:Starting cross validation
2023-06-03 14:47:50,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:47:51,354:INFO:Calculating mean and std
2023-06-03 14:47:51,357:INFO:Creating metrics dataframe
2023-06-03 14:47:51,367:INFO:Finalizing model
2023-06-03 14:47:52,689:INFO:Uploading results into container
2023-06-03 14:47:52,690:INFO:Uploading model into container now
2023-06-03 14:47:52,690:INFO:_master_model_container: 21
2023-06-03 14:47:52,690:INFO:_display_container: 6
2023-06-03 14:47:52,691:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-06-03 14:47:52,691:INFO:create_model() successfully completed......................................
2023-06-03 14:47:52,801:INFO:SubProcess create_model() end ==================================
2023-06-03 14:47:52,801:INFO:choose_better activated
2023-06-03 14:47:52,804:INFO:SubProcess create_model() called ==================================
2023-06-03 14:47:52,805:INFO:Initializing create_model()
2023-06-03 14:47:52,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:47:52,805:INFO:Checking exceptions
2023-06-03 14:47:52,807:INFO:Importing libraries
2023-06-03 14:47:52,807:INFO:Copying training dataset
2023-06-03 14:47:52,812:INFO:Defining folds
2023-06-03 14:47:52,812:INFO:Declaring metric variables
2023-06-03 14:47:52,812:INFO:Importing untrained model
2023-06-03 14:47:52,812:INFO:Declaring custom model
2023-06-03 14:47:52,813:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:47:52,813:INFO:Starting cross validation
2023-06-03 14:47:52,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:47:53,274:INFO:Calculating mean and std
2023-06-03 14:47:53,275:INFO:Creating metrics dataframe
2023-06-03 14:47:53,277:INFO:Finalizing model
2023-06-03 14:47:53,374:INFO:Uploading results into container
2023-06-03 14:47:53,374:INFO:Uploading model into container now
2023-06-03 14:47:53,375:INFO:_master_model_container: 22
2023-06-03 14:47:53,375:INFO:_display_container: 7
2023-06-03 14:47:53,375:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:47:53,375:INFO:create_model() successfully completed......................................
2023-06-03 14:47:53,482:INFO:SubProcess create_model() end ==================================
2023-06-03 14:47:53,483:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.279
2023-06-03 14:47:53,483:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Accuracy is 0.2861
2023-06-03 14:47:53,484:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-06-03 14:47:53,484:INFO:choose_better completed
2023-06-03 14:47:53,493:INFO:_master_model_container: 22
2023-06-03 14:47:53,493:INFO:_display_container: 6
2023-06-03 14:47:53,494:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.005, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=210, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=0.001, reg_lambda=1e-06,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-06-03 14:47:53,494:INFO:tune_model() successfully completed......................................
2023-06-03 14:47:53,616:INFO:Initializing tune_model()
2023-06-03 14:47:53,616:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>)
2023-06-03 14:47:53,616:INFO:Checking exceptions
2023-06-03 14:47:53,631:INFO:Copying training dataset
2023-06-03 14:47:53,637:INFO:Checking base model
2023-06-03 14:47:53,637:INFO:Base model : Logistic Regression
2023-06-03 14:47:53,643:INFO:Declaring metric variables
2023-06-03 14:47:53,648:INFO:Defining Hyperparameters
2023-06-03 14:47:53,762:INFO:Tuning with n_jobs=-1
2023-06-03 14:47:53,762:INFO:Initializing RandomizedSearchCV
2023-06-03 14:47:55,393:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,428:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,445:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,463:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,480:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,492:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,493:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,499:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,500:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,522:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,524:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,535:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,541:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,553:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,560:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,572:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,580:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,585:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:55,620:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,188:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,203:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,206:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,221:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,226:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,233:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,234:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,265:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,269:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,274:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,290:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,304:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,307:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,315:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,351:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,370:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,468:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,516:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,573:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:57,608:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:58,933:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:58,980:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:58,999:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,010:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,012:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,015:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,019:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,041:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,044:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,052:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,062:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,102:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,112:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,199:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,236:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,296:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,378:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,424:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,472:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:47:59,472:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,739:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,759:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,772:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,777:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,783:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,795:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,805:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,843:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,847:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,858:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,864:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,912:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,995:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:00,995:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:01,058:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:01,155:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:01,187:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:01,197:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:01,251:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:01,391:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,497:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,536:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,561:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,594:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,600:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,612:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,647:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,658:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,685:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,704:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,762:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,767:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,770:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,785:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,823:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,921:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:02,970:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:03,000:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:03,046:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:03,200:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 7.689}
2023-06-03 14:48:03,201:INFO:Hyperparameter search completed
2023-06-03 14:48:03,201:INFO:SubProcess create_model() called ==================================
2023-06-03 14:48:03,201:INFO:Initializing create_model()
2023-06-03 14:48:03,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae5745d00>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 7.689})
2023-06-03 14:48:03,202:INFO:Checking exceptions
2023-06-03 14:48:03,202:INFO:Importing libraries
2023-06-03 14:48:03,202:INFO:Copying training dataset
2023-06-03 14:48:03,207:INFO:Defining folds
2023-06-03 14:48:03,207:INFO:Declaring metric variables
2023-06-03 14:48:03,210:INFO:Importing untrained model
2023-06-03 14:48:03,210:INFO:Declaring custom model
2023-06-03 14:48:03,214:INFO:Logistic Regression Imported successfully
2023-06-03 14:48:03,220:INFO:Starting cross validation
2023-06-03 14:48:03,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:48:03,543:INFO:Calculating mean and std
2023-06-03 14:48:03,544:INFO:Creating metrics dataframe
2023-06-03 14:48:03,549:INFO:Finalizing model
2023-06-03 14:48:04,566:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:04,606:INFO:Uploading results into container
2023-06-03 14:48:04,606:INFO:Uploading model into container now
2023-06-03 14:48:04,607:INFO:_master_model_container: 23
2023-06-03 14:48:04,607:INFO:_display_container: 7
2023-06-03 14:48:04,607:INFO:LogisticRegression(C=7.689, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:48:04,607:INFO:create_model() successfully completed......................................
2023-06-03 14:48:04,711:INFO:SubProcess create_model() end ==================================
2023-06-03 14:48:04,712:INFO:choose_better activated
2023-06-03 14:48:04,714:INFO:SubProcess create_model() called ==================================
2023-06-03 14:48:04,715:INFO:Initializing create_model()
2023-06-03 14:48:04,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:48:04,715:INFO:Checking exceptions
2023-06-03 14:48:04,716:INFO:Importing libraries
2023-06-03 14:48:04,717:INFO:Copying training dataset
2023-06-03 14:48:04,721:INFO:Defining folds
2023-06-03 14:48:04,721:INFO:Declaring metric variables
2023-06-03 14:48:04,721:INFO:Importing untrained model
2023-06-03 14:48:04,721:INFO:Declaring custom model
2023-06-03 14:48:04,722:INFO:Logistic Regression Imported successfully
2023-06-03 14:48:04,722:INFO:Starting cross validation
2023-06-03 14:48:04,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:48:05,008:INFO:Calculating mean and std
2023-06-03 14:48:05,009:INFO:Creating metrics dataframe
2023-06-03 14:48:05,013:INFO:Finalizing model
2023-06-03 14:48:05,154:INFO:Uploading results into container
2023-06-03 14:48:05,155:INFO:Uploading model into container now
2023-06-03 14:48:05,156:INFO:_master_model_container: 24
2023-06-03 14:48:05,156:INFO:_display_container: 8
2023-06-03 14:48:05,156:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:48:05,156:INFO:create_model() successfully completed......................................
2023-06-03 14:48:05,262:INFO:SubProcess create_model() end ==================================
2023-06-03 14:48:05,262:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.2701
2023-06-03 14:48:05,262:INFO:LogisticRegression(C=7.689, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.2729
2023-06-03 14:48:05,263:INFO:LogisticRegression(C=7.689, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-06-03 14:48:05,263:INFO:choose_better completed
2023-06-03 14:48:05,271:INFO:_master_model_container: 24
2023-06-03 14:48:05,271:INFO:_display_container: 7
2023-06-03 14:48:05,271:INFO:LogisticRegression(C=7.689, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:48:05,271:INFO:tune_model() successfully completed......................................
2023-06-03 14:48:05,453:INFO:Initializing blend_models()
2023-06-03 14:48:05,453:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator_list=[ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=10, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-06-03 14:48:05,454:INFO:Checking exceptions
2023-06-03 14:48:05,482:INFO:Importing libraries
2023-06-03 14:48:05,482:INFO:Copying training dataset
2023-06-03 14:48:05,487:INFO:Getting model names
2023-06-03 14:48:05,491:INFO:SubProcess create_model() called ==================================
2023-06-03 14:48:05,499:INFO:Initializing create_model()
2023-06-03 14:48:05,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=VotingClassifier(estimators=[('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   ra...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b5790ed60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:48:05,499:INFO:Checking exceptions
2023-06-03 14:48:05,499:INFO:Importing libraries
2023-06-03 14:48:05,499:INFO:Copying training dataset
2023-06-03 14:48:05,504:INFO:Defining folds
2023-06-03 14:48:05,504:INFO:Declaring metric variables
2023-06-03 14:48:05,506:INFO:Importing untrained model
2023-06-03 14:48:05,507:INFO:Declaring custom model
2023-06-03 14:48:05,511:INFO:Voting Classifier Imported successfully
2023-06-03 14:48:05,516:INFO:Starting cross validation
2023-06-03 14:48:05,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:48:09,068:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,110:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,133:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,136:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,161:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,203:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,210:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,225:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,294:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:09,295:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:14,232:INFO:Calculating mean and std
2023-06-03 14:48:14,233:INFO:Creating metrics dataframe
2023-06-03 14:48:14,239:INFO:Finalizing model
2023-06-03 14:48:15,463:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:19,242:INFO:Uploading results into container
2023-06-03 14:48:19,243:INFO:Uploading model into container now
2023-06-03 14:48:19,243:INFO:_master_model_container: 25
2023-06-03 14:48:19,243:INFO:_display_container: 8
2023-06-03 14:48:19,250:INFO:VotingClassifier(estimators=[('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   ra...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-06-03 14:48:19,250:INFO:create_model() successfully completed......................................
2023-06-03 14:48:19,355:INFO:SubProcess create_model() end ==================================
2023-06-03 14:48:19,362:INFO:_master_model_container: 25
2023-06-03 14:48:19,362:INFO:_display_container: 8
2023-06-03 14:48:19,367:INFO:VotingClassifier(estimators=[('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   ra...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-06-03 14:48:19,367:INFO:blend_models() successfully completed......................................
2023-06-03 14:48:19,537:INFO:Initializing finalize_model()
2023-06-03 14:48:19,537:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=VotingClassifier(estimators=[('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   ra...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-03 14:48:19,545:INFO:Finalizing VotingClassifier(estimators=[('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   ra...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-06-03 14:48:19,555:INFO:Initializing create_model()
2023-06-03 14:48:19,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20d69fd0>, estimator=VotingClassifier(estimators=[('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,
                                                   ccp_alpha=0.0,
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   ra...
                                             subsample_freq=0)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-03 14:48:19,555:INFO:Checking exceptions
2023-06-03 14:48:19,556:INFO:Importing libraries
2023-06-03 14:48:19,557:INFO:Copying training dataset
2023-06-03 14:48:19,557:INFO:Defining folds
2023-06-03 14:48:19,557:INFO:Declaring metric variables
2023-06-03 14:48:19,557:INFO:Importing untrained model
2023-06-03 14:48:19,557:INFO:Declaring custom model
2023-06-03 14:48:19,559:INFO:Voting Classifier Imported successfully
2023-06-03 14:48:19,559:INFO:Cross validation set to False
2023-06-03 14:48:19,560:INFO:Fitting Model
2023-06-03 14:48:21,181:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:48:26,120:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                              ('Logistic Regression',
                                               LogisticRegression(C=1.0,
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-06-03 14:48:26,121:INFO:create_model() successfully completed......................................
2023-06-03 14:48:26,228:INFO:_master_model_container: 25
2023-06-03 14:48:26,228:INFO:_display_container: 8
2023-06-03 14:48:26,256:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                              ('Logistic Regression',
                                               LogisticRegression(C=1.0,
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-06-03 14:48:26,256:INFO:finalize_model() successfully completed......................................
2023-06-03 14:53:08,071:INFO:PyCaret ClassificationExperiment
2023-06-03 14:53:08,072:INFO:Logging name: clf-default-name
2023-06-03 14:53:08,072:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:53:08,072:INFO:version 3.0.2
2023-06-03 14:53:08,072:INFO:Initializing setup()
2023-06-03 14:53:08,072:INFO:self.USI: 868d
2023-06-03 14:53:08,072:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:53:08,072:INFO:Checking environment
2023-06-03 14:53:08,072:INFO:python_version: 3.8.16
2023-06-03 14:53:08,072:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:53:08,072:INFO:machine: x86_64
2023-06-03 14:53:08,072:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:53:08,072:INFO:Memory: svmem(total=134737395712, available=84973797376, percent=36.9, used=48463773696, free=936067072, active=30349860864, inactive=93921927168, buffers=2414276608, cached=82923278336, shared=28565504, slab=4830339072)
2023-06-03 14:53:08,073:INFO:Physical Core: 10
2023-06-03 14:53:08,073:INFO:Logical Core: 20
2023-06-03 14:53:08,073:INFO:Checking libraries
2023-06-03 14:53:08,073:INFO:System:
2023-06-03 14:53:08,073:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:53:08,073:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:53:08,073:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:53:08,073:INFO:PyCaret required dependencies:
2023-06-03 14:53:08,073:INFO:                 pip: 23.0.1
2023-06-03 14:53:08,073:INFO:          setuptools: 67.8.0
2023-06-03 14:53:08,073:INFO:             pycaret: 3.0.2
2023-06-03 14:53:08,073:INFO:             IPython: 8.12.2
2023-06-03 14:53:08,073:INFO:          ipywidgets: 8.0.6
2023-06-03 14:53:08,073:INFO:                tqdm: 4.65.0
2023-06-03 14:53:08,073:INFO:               numpy: 1.23.5
2023-06-03 14:53:08,073:INFO:              pandas: 1.5.3
2023-06-03 14:53:08,073:INFO:              jinja2: 3.1.2
2023-06-03 14:53:08,073:INFO:               scipy: 1.10.1
2023-06-03 14:53:08,073:INFO:              joblib: 1.2.0
2023-06-03 14:53:08,073:INFO:             sklearn: 1.2.2
2023-06-03 14:53:08,073:INFO:                pyod: 1.0.9
2023-06-03 14:53:08,073:INFO:            imblearn: 0.10.1
2023-06-03 14:53:08,073:INFO:   category_encoders: 2.6.1
2023-06-03 14:53:08,073:INFO:            lightgbm: 3.3.5
2023-06-03 14:53:08,073:INFO:               numba: 0.57.0
2023-06-03 14:53:08,073:INFO:            requests: 2.31.0
2023-06-03 14:53:08,073:INFO:          matplotlib: 3.7.1
2023-06-03 14:53:08,073:INFO:          scikitplot: 0.3.7
2023-06-03 14:53:08,073:INFO:         yellowbrick: 1.5
2023-06-03 14:53:08,073:INFO:              plotly: 5.14.1
2023-06-03 14:53:08,073:INFO:             kaleido: 0.2.1
2023-06-03 14:53:08,073:INFO:         statsmodels: 0.14.0
2023-06-03 14:53:08,073:INFO:              sktime: 0.17.0
2023-06-03 14:53:08,073:INFO:               tbats: 1.1.3
2023-06-03 14:53:08,073:INFO:            pmdarima: 2.0.3
2023-06-03 14:53:08,073:INFO:              psutil: 5.9.5
2023-06-03 14:53:08,073:INFO:PyCaret optional dependencies:
2023-06-03 14:53:08,073:INFO:                shap: Not installed
2023-06-03 14:53:08,073:INFO:           interpret: Not installed
2023-06-03 14:53:08,073:INFO:                umap: Not installed
2023-06-03 14:53:08,073:INFO:    pandas_profiling: Not installed
2023-06-03 14:53:08,073:INFO:  explainerdashboard: Not installed
2023-06-03 14:53:08,073:INFO:             autoviz: Not installed
2023-06-03 14:53:08,073:INFO:           fairlearn: Not installed
2023-06-03 14:53:08,073:INFO:             xgboost: Not installed
2023-06-03 14:53:08,074:INFO:            catboost: Not installed
2023-06-03 14:53:08,074:INFO:              kmodes: Not installed
2023-06-03 14:53:08,074:INFO:             mlxtend: Not installed
2023-06-03 14:53:08,074:INFO:       statsforecast: Not installed
2023-06-03 14:53:08,074:INFO:        tune_sklearn: Not installed
2023-06-03 14:53:08,074:INFO:                 ray: Not installed
2023-06-03 14:53:08,074:INFO:            hyperopt: Not installed
2023-06-03 14:53:08,074:INFO:              optuna: Not installed
2023-06-03 14:53:08,074:INFO:               skopt: Not installed
2023-06-03 14:53:08,074:INFO:              mlflow: Not installed
2023-06-03 14:53:08,074:INFO:              gradio: Not installed
2023-06-03 14:53:08,074:INFO:             fastapi: Not installed
2023-06-03 14:53:08,074:INFO:             uvicorn: Not installed
2023-06-03 14:53:08,074:INFO:              m2cgen: Not installed
2023-06-03 14:53:08,074:INFO:           evidently: Not installed
2023-06-03 14:53:08,074:INFO:               fugue: Not installed
2023-06-03 14:53:08,074:INFO:           streamlit: Not installed
2023-06-03 14:53:08,074:INFO:             prophet: Not installed
2023-06-03 14:53:08,074:INFO:None
2023-06-03 14:53:08,074:INFO:Set up data.
2023-06-03 14:53:08,079:INFO:Set up train/test split.
2023-06-03 14:53:08,084:INFO:Set up index.
2023-06-03 14:53:08,085:INFO:Set up folding strategy.
2023-06-03 14:53:08,085:INFO:Assigning column types.
2023-06-03 14:53:08,088:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:53:08,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,119:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,169:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,190:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:53:08,220:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,290:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:53:08,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,391:INFO:Preparing preprocessing pipeline...
2023-06-03 14:53:08,391:INFO:Set up simple imputation.
2023-06-03 14:53:08,402:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:53:08,405:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-03 14:53:08,405:INFO:Creating final display dataframe.
2023-06-03 14:53:08,447:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape        (8120, 12)
4        Transformed data shape        (8120, 12)
5   Transformed train set shape        (5684, 12)
6    Transformed test set shape        (2436, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              868d
2023-06-03 14:53:08,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,558:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,558:INFO:setup() successfully completed in 0.52s...............
2023-06-03 14:53:08,723:INFO:PyCaret ClassificationExperiment
2023-06-03 14:53:08,723:INFO:Logging name: clf-default-name
2023-06-03 14:53:08,723:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 14:53:08,723:INFO:version 3.0.2
2023-06-03 14:53:08,723:INFO:Initializing setup()
2023-06-03 14:53:08,723:INFO:self.USI: e83f
2023-06-03 14:53:08,723:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'seed', 'pipeline', 'X_test', '_ml_usecase', 'html_param', 'is_multiclass', 'X', 'USI', 'idx', 'gpu_n_jobs_param', 'logging_param', 'fix_imbalance', 'target_param', 'n_jobs_param', 'y_test', 'fold_shuffle_param', 'exp_id', '_available_plots', 'data', 'X_train', 'log_plots_param', 'fold_groups_param', 'memory', 'y_train', 'y', 'fold_generator'}
2023-06-03 14:53:08,723:INFO:Checking environment
2023-06-03 14:53:08,723:INFO:python_version: 3.8.16
2023-06-03 14:53:08,723:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 14:53:08,723:INFO:machine: x86_64
2023-06-03 14:53:08,723:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:53:08,724:INFO:Memory: svmem(total=134737395712, available=84974338048, percent=36.9, used=48463241216, free=936587264, active=30350184448, inactive=93923696640, buffers=2414280704, cached=82923286528, shared=28565504, slab=4830330880)
2023-06-03 14:53:08,724:INFO:Physical Core: 10
2023-06-03 14:53:08,724:INFO:Logical Core: 20
2023-06-03 14:53:08,724:INFO:Checking libraries
2023-06-03 14:53:08,724:INFO:System:
2023-06-03 14:53:08,724:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 14:53:08,724:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 14:53:08,724:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 14:53:08,724:INFO:PyCaret required dependencies:
2023-06-03 14:53:08,724:INFO:                 pip: 23.0.1
2023-06-03 14:53:08,724:INFO:          setuptools: 67.8.0
2023-06-03 14:53:08,724:INFO:             pycaret: 3.0.2
2023-06-03 14:53:08,724:INFO:             IPython: 8.12.2
2023-06-03 14:53:08,724:INFO:          ipywidgets: 8.0.6
2023-06-03 14:53:08,724:INFO:                tqdm: 4.65.0
2023-06-03 14:53:08,724:INFO:               numpy: 1.23.5
2023-06-03 14:53:08,724:INFO:              pandas: 1.5.3
2023-06-03 14:53:08,724:INFO:              jinja2: 3.1.2
2023-06-03 14:53:08,724:INFO:               scipy: 1.10.1
2023-06-03 14:53:08,725:INFO:              joblib: 1.2.0
2023-06-03 14:53:08,725:INFO:             sklearn: 1.2.2
2023-06-03 14:53:08,725:INFO:                pyod: 1.0.9
2023-06-03 14:53:08,725:INFO:            imblearn: 0.10.1
2023-06-03 14:53:08,725:INFO:   category_encoders: 2.6.1
2023-06-03 14:53:08,725:INFO:            lightgbm: 3.3.5
2023-06-03 14:53:08,725:INFO:               numba: 0.57.0
2023-06-03 14:53:08,725:INFO:            requests: 2.31.0
2023-06-03 14:53:08,725:INFO:          matplotlib: 3.7.1
2023-06-03 14:53:08,725:INFO:          scikitplot: 0.3.7
2023-06-03 14:53:08,725:INFO:         yellowbrick: 1.5
2023-06-03 14:53:08,725:INFO:              plotly: 5.14.1
2023-06-03 14:53:08,725:INFO:             kaleido: 0.2.1
2023-06-03 14:53:08,725:INFO:         statsmodels: 0.14.0
2023-06-03 14:53:08,725:INFO:              sktime: 0.17.0
2023-06-03 14:53:08,725:INFO:               tbats: 1.1.3
2023-06-03 14:53:08,725:INFO:            pmdarima: 2.0.3
2023-06-03 14:53:08,725:INFO:              psutil: 5.9.5
2023-06-03 14:53:08,725:INFO:PyCaret optional dependencies:
2023-06-03 14:53:08,725:INFO:                shap: Not installed
2023-06-03 14:53:08,725:INFO:           interpret: Not installed
2023-06-03 14:53:08,725:INFO:                umap: Not installed
2023-06-03 14:53:08,725:INFO:    pandas_profiling: Not installed
2023-06-03 14:53:08,725:INFO:  explainerdashboard: Not installed
2023-06-03 14:53:08,725:INFO:             autoviz: Not installed
2023-06-03 14:53:08,725:INFO:           fairlearn: Not installed
2023-06-03 14:53:08,725:INFO:             xgboost: Not installed
2023-06-03 14:53:08,725:INFO:            catboost: Not installed
2023-06-03 14:53:08,725:INFO:              kmodes: Not installed
2023-06-03 14:53:08,725:INFO:             mlxtend: Not installed
2023-06-03 14:53:08,725:INFO:       statsforecast: Not installed
2023-06-03 14:53:08,725:INFO:        tune_sklearn: Not installed
2023-06-03 14:53:08,725:INFO:                 ray: Not installed
2023-06-03 14:53:08,725:INFO:            hyperopt: Not installed
2023-06-03 14:53:08,725:INFO:              optuna: Not installed
2023-06-03 14:53:08,725:INFO:               skopt: Not installed
2023-06-03 14:53:08,725:INFO:              mlflow: Not installed
2023-06-03 14:53:08,725:INFO:              gradio: Not installed
2023-06-03 14:53:08,725:INFO:             fastapi: Not installed
2023-06-03 14:53:08,725:INFO:             uvicorn: Not installed
2023-06-03 14:53:08,725:INFO:              m2cgen: Not installed
2023-06-03 14:53:08,725:INFO:           evidently: Not installed
2023-06-03 14:53:08,725:INFO:               fugue: Not installed
2023-06-03 14:53:08,725:INFO:           streamlit: Not installed
2023-06-03 14:53:08,725:INFO:             prophet: Not installed
2023-06-03 14:53:08,725:INFO:None
2023-06-03 14:53:08,725:INFO:Set up data.
2023-06-03 14:53:08,731:INFO:Set up train/test split.
2023-06-03 14:53:08,737:INFO:Set up index.
2023-06-03 14:53:08,737:INFO:Set up folding strategy.
2023-06-03 14:53:08,737:INFO:Assigning column types.
2023-06-03 14:53:08,740:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 14:53:08,772:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,822:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,842:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 14:53:08,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,922:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 14:53:08,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,942:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 14:53:08,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:08,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,044:INFO:Preparing preprocessing pipeline...
2023-06-03 14:53:09,045:INFO:Set up simple imputation.
2023-06-03 14:53:09,045:INFO:Set up feature normalization.
2023-06-03 14:53:09,060:INFO:Finished creating preprocessing pipeline.
2023-06-03 14:53:09,063:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-06-03 14:53:09,063:INFO:Creating final display dataframe.
2023-06-03 14:53:09,120:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape        (8120, 12)
4        Transformed data shape        (8120, 12)
5   Transformed train set shape        (5684, 12)
6    Transformed test set shape        (2436, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e83f
2023-06-03 14:53:09,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,174:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,220:INFO:setup() successfully completed in 0.54s...............
2023-06-03 14:53:09,275:INFO:gpu_param set to False
2023-06-03 14:53:09,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 14:53:09,459:INFO:Initializing compare_models()
2023-06-03 14:53:09,459:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 14:53:09,459:INFO:Checking exceptions
2023-06-03 14:53:09,468:INFO:Preparing display monitor
2023-06-03 14:53:09,504:INFO:Initializing Logistic Regression
2023-06-03 14:53:09,504:INFO:Total runtime is 4.2120615641276044e-06 minutes
2023-06-03 14:53:09,510:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:09,510:INFO:Initializing create_model()
2023-06-03 14:53:09,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:09,510:INFO:Checking exceptions
2023-06-03 14:53:09,510:INFO:Importing libraries
2023-06-03 14:53:09,511:INFO:Copying training dataset
2023-06-03 14:53:09,517:INFO:Defining folds
2023-06-03 14:53:09,517:INFO:Declaring metric variables
2023-06-03 14:53:09,522:INFO:Importing untrained model
2023-06-03 14:53:09,526:INFO:Logistic Regression Imported successfully
2023-06-03 14:53:09,538:INFO:Starting cross validation
2023-06-03 14:53:09,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:10,343:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,373:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,382:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,383:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,402:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,419:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,423:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,424:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,667:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,719:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:10,760:INFO:Calculating mean and std
2023-06-03 14:53:10,762:INFO:Creating metrics dataframe
2023-06-03 14:53:10,878:INFO:Uploading results into container
2023-06-03 14:53:10,878:INFO:Uploading model into container now
2023-06-03 14:53:10,879:INFO:_master_model_container: 1
2023-06-03 14:53:10,879:INFO:_display_container: 2
2023-06-03 14:53:10,879:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:53:10,879:INFO:create_model() successfully completed......................................
2023-06-03 14:53:11,029:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:11,029:INFO:Creating metrics dataframe
2023-06-03 14:53:11,036:INFO:Initializing K Neighbors Classifier
2023-06-03 14:53:11,036:INFO:Total runtime is 0.0255327582359314 minutes
2023-06-03 14:53:11,042:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:11,043:INFO:Initializing create_model()
2023-06-03 14:53:11,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:11,043:INFO:Checking exceptions
2023-06-03 14:53:11,043:INFO:Importing libraries
2023-06-03 14:53:11,043:INFO:Copying training dataset
2023-06-03 14:53:11,053:INFO:Defining folds
2023-06-03 14:53:11,053:INFO:Declaring metric variables
2023-06-03 14:53:11,058:INFO:Importing untrained model
2023-06-03 14:53:11,062:INFO:K Neighbors Classifier Imported successfully
2023-06-03 14:53:11,069:INFO:Starting cross validation
2023-06-03 14:53:11,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:11,472:INFO:Calculating mean and std
2023-06-03 14:53:11,473:INFO:Creating metrics dataframe
2023-06-03 14:53:11,582:INFO:Uploading results into container
2023-06-03 14:53:11,582:INFO:Uploading model into container now
2023-06-03 14:53:11,583:INFO:_master_model_container: 2
2023-06-03 14:53:11,583:INFO:_display_container: 2
2023-06-03 14:53:11,583:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 14:53:11,583:INFO:create_model() successfully completed......................................
2023-06-03 14:53:11,692:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:11,693:INFO:Creating metrics dataframe
2023-06-03 14:53:11,701:INFO:Initializing Naive Bayes
2023-06-03 14:53:11,701:INFO:Total runtime is 0.03661624987920126 minutes
2023-06-03 14:53:11,707:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:11,707:INFO:Initializing create_model()
2023-06-03 14:53:11,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:11,708:INFO:Checking exceptions
2023-06-03 14:53:11,708:INFO:Importing libraries
2023-06-03 14:53:11,708:INFO:Copying training dataset
2023-06-03 14:53:11,718:INFO:Defining folds
2023-06-03 14:53:11,718:INFO:Declaring metric variables
2023-06-03 14:53:11,722:INFO:Importing untrained model
2023-06-03 14:53:11,726:INFO:Naive Bayes Imported successfully
2023-06-03 14:53:11,733:INFO:Starting cross validation
2023-06-03 14:53:11,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:12,096:INFO:Calculating mean and std
2023-06-03 14:53:12,098:INFO:Creating metrics dataframe
2023-06-03 14:53:12,221:INFO:Uploading results into container
2023-06-03 14:53:12,221:INFO:Uploading model into container now
2023-06-03 14:53:12,221:INFO:_master_model_container: 3
2023-06-03 14:53:12,222:INFO:_display_container: 2
2023-06-03 14:53:12,222:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 14:53:12,222:INFO:create_model() successfully completed......................................
2023-06-03 14:53:12,335:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:12,336:INFO:Creating metrics dataframe
2023-06-03 14:53:12,345:INFO:Initializing Decision Tree Classifier
2023-06-03 14:53:12,346:INFO:Total runtime is 0.047362609704335534 minutes
2023-06-03 14:53:12,353:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:12,353:INFO:Initializing create_model()
2023-06-03 14:53:12,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:12,354:INFO:Checking exceptions
2023-06-03 14:53:12,354:INFO:Importing libraries
2023-06-03 14:53:12,354:INFO:Copying training dataset
2023-06-03 14:53:12,363:INFO:Defining folds
2023-06-03 14:53:12,364:INFO:Declaring metric variables
2023-06-03 14:53:12,368:INFO:Importing untrained model
2023-06-03 14:53:12,373:INFO:Decision Tree Classifier Imported successfully
2023-06-03 14:53:12,379:INFO:Starting cross validation
2023-06-03 14:53:12,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:12,741:INFO:Calculating mean and std
2023-06-03 14:53:12,744:INFO:Creating metrics dataframe
2023-06-03 14:53:12,852:INFO:Uploading results into container
2023-06-03 14:53:12,852:INFO:Uploading model into container now
2023-06-03 14:53:12,853:INFO:_master_model_container: 4
2023-06-03 14:53:12,853:INFO:_display_container: 2
2023-06-03 14:53:12,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 14:53:12,853:INFO:create_model() successfully completed......................................
2023-06-03 14:53:12,964:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:12,965:INFO:Creating metrics dataframe
2023-06-03 14:53:12,974:INFO:Initializing SVM - Linear Kernel
2023-06-03 14:53:12,974:INFO:Total runtime is 0.05783633391062419 minutes
2023-06-03 14:53:12,977:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:12,977:INFO:Initializing create_model()
2023-06-03 14:53:12,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:12,977:INFO:Checking exceptions
2023-06-03 14:53:12,977:INFO:Importing libraries
2023-06-03 14:53:12,978:INFO:Copying training dataset
2023-06-03 14:53:12,982:INFO:Defining folds
2023-06-03 14:53:12,982:INFO:Declaring metric variables
2023-06-03 14:53:12,986:INFO:Importing untrained model
2023-06-03 14:53:12,993:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 14:53:13,004:INFO:Starting cross validation
2023-06-03 14:53:13,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:13,173:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,177:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,187:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,191:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,260:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,261:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,263:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,264:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,264:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,268:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,273:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,276:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,276:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,277:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,279:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,280:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,283:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,364:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 14:53:13,368:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:13,483:INFO:Calculating mean and std
2023-06-03 14:53:13,484:INFO:Creating metrics dataframe
2023-06-03 14:53:13,597:INFO:Uploading results into container
2023-06-03 14:53:13,597:INFO:Uploading model into container now
2023-06-03 14:53:13,598:INFO:_master_model_container: 5
2023-06-03 14:53:13,598:INFO:_display_container: 2
2023-06-03 14:53:13,598:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 14:53:13,598:INFO:create_model() successfully completed......................................
2023-06-03 14:53:13,709:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:13,709:INFO:Creating metrics dataframe
2023-06-03 14:53:13,718:INFO:Initializing Ridge Classifier
2023-06-03 14:53:13,718:INFO:Total runtime is 0.07023196617762248 minutes
2023-06-03 14:53:13,721:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:13,721:INFO:Initializing create_model()
2023-06-03 14:53:13,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:13,721:INFO:Checking exceptions
2023-06-03 14:53:13,721:INFO:Importing libraries
2023-06-03 14:53:13,721:INFO:Copying training dataset
2023-06-03 14:53:13,726:INFO:Defining folds
2023-06-03 14:53:13,726:INFO:Declaring metric variables
2023-06-03 14:53:13,729:INFO:Importing untrained model
2023-06-03 14:53:13,733:INFO:Ridge Classifier Imported successfully
2023-06-03 14:53:13,741:INFO:Starting cross validation
2023-06-03 14:53:13,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:13,795:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,797:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,806:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,806:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,807:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,816:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,817:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,823:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,824:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:13,824:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 14:53:14,055:INFO:Calculating mean and std
2023-06-03 14:53:14,057:INFO:Creating metrics dataframe
2023-06-03 14:53:14,171:INFO:Uploading results into container
2023-06-03 14:53:14,172:INFO:Uploading model into container now
2023-06-03 14:53:14,172:INFO:_master_model_container: 6
2023-06-03 14:53:14,172:INFO:_display_container: 2
2023-06-03 14:53:14,173:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 14:53:14,173:INFO:create_model() successfully completed......................................
2023-06-03 14:53:14,284:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:14,284:INFO:Creating metrics dataframe
2023-06-03 14:53:14,293:INFO:Initializing Random Forest Classifier
2023-06-03 14:53:14,293:INFO:Total runtime is 0.07982534567515055 minutes
2023-06-03 14:53:14,297:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:14,297:INFO:Initializing create_model()
2023-06-03 14:53:14,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:14,297:INFO:Checking exceptions
2023-06-03 14:53:14,297:INFO:Importing libraries
2023-06-03 14:53:14,297:INFO:Copying training dataset
2023-06-03 14:53:14,302:INFO:Defining folds
2023-06-03 14:53:14,302:INFO:Declaring metric variables
2023-06-03 14:53:14,305:INFO:Importing untrained model
2023-06-03 14:53:14,308:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:53:14,317:INFO:Starting cross validation
2023-06-03 14:53:14,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:15,937:INFO:Calculating mean and std
2023-06-03 14:53:15,940:INFO:Creating metrics dataframe
2023-06-03 14:53:16,059:INFO:Uploading results into container
2023-06-03 14:53:16,060:INFO:Uploading model into container now
2023-06-03 14:53:16,060:INFO:_master_model_container: 7
2023-06-03 14:53:16,060:INFO:_display_container: 2
2023-06-03 14:53:16,061:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:16,061:INFO:create_model() successfully completed......................................
2023-06-03 14:53:16,172:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:16,172:INFO:Creating metrics dataframe
2023-06-03 14:53:16,181:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 14:53:16,181:INFO:Total runtime is 0.11129175821940104 minutes
2023-06-03 14:53:16,185:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:16,185:INFO:Initializing create_model()
2023-06-03 14:53:16,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:16,185:INFO:Checking exceptions
2023-06-03 14:53:16,185:INFO:Importing libraries
2023-06-03 14:53:16,185:INFO:Copying training dataset
2023-06-03 14:53:16,196:INFO:Defining folds
2023-06-03 14:53:16,196:INFO:Declaring metric variables
2023-06-03 14:53:16,200:INFO:Importing untrained model
2023-06-03 14:53:16,205:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 14:53:16,213:INFO:Starting cross validation
2023-06-03 14:53:16,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:16,538:INFO:Calculating mean and std
2023-06-03 14:53:16,540:INFO:Creating metrics dataframe
2023-06-03 14:53:16,657:INFO:Uploading results into container
2023-06-03 14:53:16,658:INFO:Uploading model into container now
2023-06-03 14:53:16,659:INFO:_master_model_container: 8
2023-06-03 14:53:16,659:INFO:_display_container: 2
2023-06-03 14:53:16,659:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 14:53:16,659:INFO:create_model() successfully completed......................................
2023-06-03 14:53:16,775:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:16,775:INFO:Creating metrics dataframe
2023-06-03 14:53:16,785:INFO:Initializing Ada Boost Classifier
2023-06-03 14:53:16,785:INFO:Total runtime is 0.12135212421417237 minutes
2023-06-03 14:53:16,788:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:16,788:INFO:Initializing create_model()
2023-06-03 14:53:16,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:16,788:INFO:Checking exceptions
2023-06-03 14:53:16,788:INFO:Importing libraries
2023-06-03 14:53:16,788:INFO:Copying training dataset
2023-06-03 14:53:16,794:INFO:Defining folds
2023-06-03 14:53:16,795:INFO:Declaring metric variables
2023-06-03 14:53:16,802:INFO:Importing untrained model
2023-06-03 14:53:16,806:INFO:Ada Boost Classifier Imported successfully
2023-06-03 14:53:16,813:INFO:Starting cross validation
2023-06-03 14:53:16,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:17,516:INFO:Calculating mean and std
2023-06-03 14:53:17,519:INFO:Creating metrics dataframe
2023-06-03 14:53:17,652:INFO:Uploading results into container
2023-06-03 14:53:17,653:INFO:Uploading model into container now
2023-06-03 14:53:17,653:INFO:_master_model_container: 9
2023-06-03 14:53:17,653:INFO:_display_container: 2
2023-06-03 14:53:17,654:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 14:53:17,654:INFO:create_model() successfully completed......................................
2023-06-03 14:53:17,765:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:17,765:INFO:Creating metrics dataframe
2023-06-03 14:53:17,774:INFO:Initializing Gradient Boosting Classifier
2023-06-03 14:53:17,775:INFO:Total runtime is 0.1378440022468567 minutes
2023-06-03 14:53:17,777:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:17,777:INFO:Initializing create_model()
2023-06-03 14:53:17,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:17,777:INFO:Checking exceptions
2023-06-03 14:53:17,777:INFO:Importing libraries
2023-06-03 14:53:17,777:INFO:Copying training dataset
2023-06-03 14:53:17,782:INFO:Defining folds
2023-06-03 14:53:17,782:INFO:Declaring metric variables
2023-06-03 14:53:17,785:INFO:Importing untrained model
2023-06-03 14:53:17,792:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:53:17,803:INFO:Starting cross validation
2023-06-03 14:53:17,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:21,999:INFO:Calculating mean and std
2023-06-03 14:53:22,002:INFO:Creating metrics dataframe
2023-06-03 14:53:22,125:INFO:Uploading results into container
2023-06-03 14:53:22,126:INFO:Uploading model into container now
2023-06-03 14:53:22,126:INFO:_master_model_container: 10
2023-06-03 14:53:22,126:INFO:_display_container: 2
2023-06-03 14:53:22,126:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:53:22,126:INFO:create_model() successfully completed......................................
2023-06-03 14:53:22,236:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:22,236:INFO:Creating metrics dataframe
2023-06-03 14:53:22,247:INFO:Initializing Linear Discriminant Analysis
2023-06-03 14:53:22,247:INFO:Total runtime is 0.21238808631896972 minutes
2023-06-03 14:53:22,250:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:22,250:INFO:Initializing create_model()
2023-06-03 14:53:22,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:22,251:INFO:Checking exceptions
2023-06-03 14:53:22,251:INFO:Importing libraries
2023-06-03 14:53:22,251:INFO:Copying training dataset
2023-06-03 14:53:22,255:INFO:Defining folds
2023-06-03 14:53:22,255:INFO:Declaring metric variables
2023-06-03 14:53:22,259:INFO:Importing untrained model
2023-06-03 14:53:22,262:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 14:53:22,268:INFO:Starting cross validation
2023-06-03 14:53:22,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:22,628:INFO:Calculating mean and std
2023-06-03 14:53:22,629:INFO:Creating metrics dataframe
2023-06-03 14:53:22,743:INFO:Uploading results into container
2023-06-03 14:53:22,744:INFO:Uploading model into container now
2023-06-03 14:53:22,744:INFO:_master_model_container: 11
2023-06-03 14:53:22,744:INFO:_display_container: 2
2023-06-03 14:53:22,744:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 14:53:22,744:INFO:create_model() successfully completed......................................
2023-06-03 14:53:22,854:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:22,854:INFO:Creating metrics dataframe
2023-06-03 14:53:22,865:INFO:Initializing Extra Trees Classifier
2023-06-03 14:53:22,865:INFO:Total runtime is 0.22269024451573688 minutes
2023-06-03 14:53:22,872:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:22,872:INFO:Initializing create_model()
2023-06-03 14:53:22,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:22,873:INFO:Checking exceptions
2023-06-03 14:53:22,873:INFO:Importing libraries
2023-06-03 14:53:22,873:INFO:Copying training dataset
2023-06-03 14:53:22,882:INFO:Defining folds
2023-06-03 14:53:22,883:INFO:Declaring metric variables
2023-06-03 14:53:22,889:INFO:Importing untrained model
2023-06-03 14:53:22,896:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:53:22,906:INFO:Starting cross validation
2023-06-03 14:53:22,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:24,280:INFO:Calculating mean and std
2023-06-03 14:53:24,283:INFO:Creating metrics dataframe
2023-06-03 14:53:24,404:INFO:Uploading results into container
2023-06-03 14:53:24,405:INFO:Uploading model into container now
2023-06-03 14:53:24,405:INFO:_master_model_container: 12
2023-06-03 14:53:24,405:INFO:_display_container: 2
2023-06-03 14:53:24,406:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:24,406:INFO:create_model() successfully completed......................................
2023-06-03 14:53:24,516:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:24,516:INFO:Creating metrics dataframe
2023-06-03 14:53:24,527:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 14:53:24,527:INFO:Total runtime is 0.250385574499766 minutes
2023-06-03 14:53:24,530:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:24,531:INFO:Initializing create_model()
2023-06-03 14:53:24,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:24,531:INFO:Checking exceptions
2023-06-03 14:53:24,531:INFO:Importing libraries
2023-06-03 14:53:24,531:INFO:Copying training dataset
2023-06-03 14:53:24,535:INFO:Defining folds
2023-06-03 14:53:24,535:INFO:Declaring metric variables
2023-06-03 14:53:24,539:INFO:Importing untrained model
2023-06-03 14:53:24,542:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:53:24,548:INFO:Starting cross validation
2023-06-03 14:53:24,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:25,642:INFO:Calculating mean and std
2023-06-03 14:53:25,643:INFO:Creating metrics dataframe
2023-06-03 14:53:25,753:INFO:Uploading results into container
2023-06-03 14:53:25,754:INFO:Uploading model into container now
2023-06-03 14:53:25,754:INFO:_master_model_container: 13
2023-06-03 14:53:25,754:INFO:_display_container: 2
2023-06-03 14:53:25,754:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:53:25,754:INFO:create_model() successfully completed......................................
2023-06-03 14:53:25,863:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:25,864:INFO:Creating metrics dataframe
2023-06-03 14:53:25,884:INFO:Initializing Dummy Classifier
2023-06-03 14:53:25,884:INFO:Total runtime is 0.27300121386845905 minutes
2023-06-03 14:53:25,888:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:25,889:INFO:Initializing create_model()
2023-06-03 14:53:25,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b557fda60>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:25,889:INFO:Checking exceptions
2023-06-03 14:53:25,889:INFO:Importing libraries
2023-06-03 14:53:25,889:INFO:Copying training dataset
2023-06-03 14:53:25,894:INFO:Defining folds
2023-06-03 14:53:25,894:INFO:Declaring metric variables
2023-06-03 14:53:25,898:INFO:Importing untrained model
2023-06-03 14:53:25,901:INFO:Dummy Classifier Imported successfully
2023-06-03 14:53:25,908:INFO:Starting cross validation
2023-06-03 14:53:25,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:25,999:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,008:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,013:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,015:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,024:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,025:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,033:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,035:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,041:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,046:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 14:53:26,277:INFO:Calculating mean and std
2023-06-03 14:53:26,278:INFO:Creating metrics dataframe
2023-06-03 14:53:26,404:INFO:Uploading results into container
2023-06-03 14:53:26,405:INFO:Uploading model into container now
2023-06-03 14:53:26,406:INFO:_master_model_container: 14
2023-06-03 14:53:26,406:INFO:_display_container: 2
2023-06-03 14:53:26,406:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 14:53:26,406:INFO:create_model() successfully completed......................................
2023-06-03 14:53:26,524:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:26,524:INFO:Creating metrics dataframe
2023-06-03 14:53:26,545:INFO:Initializing create_model()
2023-06-03 14:53:26,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:26,546:INFO:Checking exceptions
2023-06-03 14:53:26,549:INFO:Importing libraries
2023-06-03 14:53:26,549:INFO:Copying training dataset
2023-06-03 14:53:26,559:INFO:Defining folds
2023-06-03 14:53:26,559:INFO:Declaring metric variables
2023-06-03 14:53:26,559:INFO:Importing untrained model
2023-06-03 14:53:26,560:INFO:Declaring custom model
2023-06-03 14:53:26,561:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:53:26,562:INFO:Cross validation set to False
2023-06-03 14:53:26,562:INFO:Fitting Model
2023-06-03 14:53:27,165:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:27,165:INFO:create_model() successfully completed......................................
2023-06-03 14:53:27,279:INFO:Initializing create_model()
2023-06-03 14:53:27,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:27,280:INFO:Checking exceptions
2023-06-03 14:53:27,281:INFO:Importing libraries
2023-06-03 14:53:27,281:INFO:Copying training dataset
2023-06-03 14:53:27,285:INFO:Defining folds
2023-06-03 14:53:27,285:INFO:Declaring metric variables
2023-06-03 14:53:27,285:INFO:Importing untrained model
2023-06-03 14:53:27,285:INFO:Declaring custom model
2023-06-03 14:53:27,286:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:53:27,286:INFO:Cross validation set to False
2023-06-03 14:53:27,286:INFO:Fitting Model
2023-06-03 14:53:27,879:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:27,879:INFO:create_model() successfully completed......................................
2023-06-03 14:53:27,996:INFO:Initializing create_model()
2023-06-03 14:53:27,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:27,996:INFO:Checking exceptions
2023-06-03 14:53:27,999:INFO:Importing libraries
2023-06-03 14:53:27,999:INFO:Copying training dataset
2023-06-03 14:53:28,008:INFO:Defining folds
2023-06-03 14:53:28,009:INFO:Declaring metric variables
2023-06-03 14:53:28,009:INFO:Importing untrained model
2023-06-03 14:53:28,009:INFO:Declaring custom model
2023-06-03 14:53:28,010:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:53:28,011:INFO:Cross validation set to False
2023-06-03 14:53:28,011:INFO:Fitting Model
2023-06-03 14:53:29,475:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:53:29,475:INFO:create_model() successfully completed......................................
2023-06-03 14:53:29,589:INFO:Initializing create_model()
2023-06-03 14:53:29,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:29,589:INFO:Checking exceptions
2023-06-03 14:53:29,591:INFO:Importing libraries
2023-06-03 14:53:29,591:INFO:Copying training dataset
2023-06-03 14:53:29,595:INFO:Defining folds
2023-06-03 14:53:29,595:INFO:Declaring metric variables
2023-06-03 14:53:29,595:INFO:Importing untrained model
2023-06-03 14:53:29,595:INFO:Declaring custom model
2023-06-03 14:53:29,596:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:53:29,596:INFO:Cross validation set to False
2023-06-03 14:53:29,596:INFO:Fitting Model
2023-06-03 14:53:33,296:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:53:33,296:INFO:create_model() successfully completed......................................
2023-06-03 14:53:33,417:INFO:Initializing create_model()
2023-06-03 14:53:33,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:33,417:INFO:Checking exceptions
2023-06-03 14:53:33,418:INFO:Importing libraries
2023-06-03 14:53:33,418:INFO:Copying training dataset
2023-06-03 14:53:33,422:INFO:Defining folds
2023-06-03 14:53:33,422:INFO:Declaring metric variables
2023-06-03 14:53:33,423:INFO:Importing untrained model
2023-06-03 14:53:33,423:INFO:Declaring custom model
2023-06-03 14:53:33,423:INFO:Logistic Regression Imported successfully
2023-06-03 14:53:33,423:INFO:Cross validation set to False
2023-06-03 14:53:33,423:INFO:Fitting Model
2023-06-03 14:53:34,238:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:53:34,279:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:53:34,279:INFO:create_model() successfully completed......................................
2023-06-03 14:53:34,408:INFO:_master_model_container: 14
2023-06-03 14:53:34,408:INFO:_display_container: 2
2023-06-03 14:53:34,409:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2023-06-03 14:53:34,409:INFO:compare_models() successfully completed......................................
2023-06-03 14:53:34,618:INFO:Initializing tune_model()
2023-06-03 14:53:34,619:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>)
2023-06-03 14:53:34,619:INFO:Checking exceptions
2023-06-03 14:53:34,644:INFO:Copying training dataset
2023-06-03 14:53:34,649:INFO:Checking base model
2023-06-03 14:53:34,649:INFO:Base model : Random Forest Classifier
2023-06-03 14:53:34,653:INFO:Declaring metric variables
2023-06-03 14:53:34,657:INFO:Defining Hyperparameters
2023-06-03 14:53:34,787:INFO:Tuning with n_jobs=-1
2023-06-03 14:53:34,787:INFO:Initializing RandomizedSearchCV
2023-06-03 14:53:38,524:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:53:40,809:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:53:44,175:INFO:best_params: {'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-06-03 14:53:44,175:INFO:Hyperparameter search completed
2023-06-03 14:53:44,175:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:44,176:INFO:Initializing create_model()
2023-06-03 14:53:44,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b21284af0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 260, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-06-03 14:53:44,176:INFO:Checking exceptions
2023-06-03 14:53:44,176:INFO:Importing libraries
2023-06-03 14:53:44,176:INFO:Copying training dataset
2023-06-03 14:53:44,180:INFO:Defining folds
2023-06-03 14:53:44,181:INFO:Declaring metric variables
2023-06-03 14:53:44,183:INFO:Importing untrained model
2023-06-03 14:53:44,183:INFO:Declaring custom model
2023-06-03 14:53:44,186:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:53:44,192:INFO:Starting cross validation
2023-06-03 14:53:44,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:45,157:INFO:Calculating mean and std
2023-06-03 14:53:45,160:INFO:Creating metrics dataframe
2023-06-03 14:53:45,170:INFO:Finalizing model
2023-06-03 14:53:46,447:INFO:Uploading results into container
2023-06-03 14:53:46,447:INFO:Uploading model into container now
2023-06-03 14:53:46,448:INFO:_master_model_container: 15
2023-06-03 14:53:46,448:INFO:_display_container: 3
2023-06-03 14:53:46,449:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0005,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=260,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-06-03 14:53:46,449:INFO:create_model() successfully completed......................................
2023-06-03 14:53:46,564:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:46,564:INFO:choose_better activated
2023-06-03 14:53:46,567:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:46,568:INFO:Initializing create_model()
2023-06-03 14:53:46,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:46,568:INFO:Checking exceptions
2023-06-03 14:53:46,569:INFO:Importing libraries
2023-06-03 14:53:46,569:INFO:Copying training dataset
2023-06-03 14:53:46,574:INFO:Defining folds
2023-06-03 14:53:46,574:INFO:Declaring metric variables
2023-06-03 14:53:46,574:INFO:Importing untrained model
2023-06-03 14:53:46,574:INFO:Declaring custom model
2023-06-03 14:53:46,575:INFO:Random Forest Classifier Imported successfully
2023-06-03 14:53:46,575:INFO:Starting cross validation
2023-06-03 14:53:46,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:47,256:INFO:Calculating mean and std
2023-06-03 14:53:47,257:INFO:Creating metrics dataframe
2023-06-03 14:53:47,262:INFO:Finalizing model
2023-06-03 14:53:47,475:INFO:Uploading results into container
2023-06-03 14:53:47,476:INFO:Uploading model into container now
2023-06-03 14:53:47,476:INFO:_master_model_container: 16
2023-06-03 14:53:47,476:INFO:_display_container: 4
2023-06-03 14:53:47,477:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:47,477:INFO:create_model() successfully completed......................................
2023-06-03 14:53:47,588:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:47,588:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.2783
2023-06-03 14:53:47,588:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0005,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=260,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.2609
2023-06-03 14:53:47,589:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-06-03 14:53:47,589:INFO:choose_better completed
2023-06-03 14:53:47,589:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-03 14:53:47,597:INFO:_master_model_container: 16
2023-06-03 14:53:47,597:INFO:_display_container: 3
2023-06-03 14:53:47,598:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:47,598:INFO:tune_model() successfully completed......................................
2023-06-03 14:53:47,746:INFO:Initializing tune_model()
2023-06-03 14:53:47,746:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>)
2023-06-03 14:53:47,746:INFO:Checking exceptions
2023-06-03 14:53:47,758:INFO:Copying training dataset
2023-06-03 14:53:47,762:INFO:Checking base model
2023-06-03 14:53:47,762:INFO:Base model : Extra Trees Classifier
2023-06-03 14:53:47,766:INFO:Declaring metric variables
2023-06-03 14:53:47,769:INFO:Defining Hyperparameters
2023-06-03 14:53:47,880:INFO:Tuning with n_jobs=-1
2023-06-03 14:53:47,881:INFO:Initializing RandomizedSearchCV
2023-06-03 14:53:55,433:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-06-03 14:53:55,434:INFO:Hyperparameter search completed
2023-06-03 14:53:55,434:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:55,434:INFO:Initializing create_model()
2023-06-03 14:53:55,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae5876400>, model_only=True, return_train_score=False, kwargs={'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 1.0, 'max_depth': 5, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': False})
2023-06-03 14:53:55,434:INFO:Checking exceptions
2023-06-03 14:53:55,435:INFO:Importing libraries
2023-06-03 14:53:55,435:INFO:Copying training dataset
2023-06-03 14:53:55,439:INFO:Defining folds
2023-06-03 14:53:55,439:INFO:Declaring metric variables
2023-06-03 14:53:55,442:INFO:Importing untrained model
2023-06-03 14:53:55,442:INFO:Declaring custom model
2023-06-03 14:53:55,445:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:53:55,450:INFO:Starting cross validation
2023-06-03 14:53:55,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:56,194:INFO:Calculating mean and std
2023-06-03 14:53:56,197:INFO:Creating metrics dataframe
2023-06-03 14:53:56,209:INFO:Finalizing model
2023-06-03 14:53:57,031:INFO:Uploading results into container
2023-06-03 14:53:57,032:INFO:Uploading model into container now
2023-06-03 14:53:57,032:INFO:_master_model_container: 17
2023-06-03 14:53:57,032:INFO:_display_container: 4
2023-06-03 14:53:57,033:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=5, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0002, min_samples_leaf=5,
                     min_samples_split=10, min_weight_fraction_leaf=0.0,
                     n_estimators=150, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:57,033:INFO:create_model() successfully completed......................................
2023-06-03 14:53:57,142:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:57,142:INFO:choose_better activated
2023-06-03 14:53:57,145:INFO:SubProcess create_model() called ==================================
2023-06-03 14:53:57,146:INFO:Initializing create_model()
2023-06-03 14:53:57,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:53:57,146:INFO:Checking exceptions
2023-06-03 14:53:57,147:INFO:Importing libraries
2023-06-03 14:53:57,147:INFO:Copying training dataset
2023-06-03 14:53:57,151:INFO:Defining folds
2023-06-03 14:53:57,151:INFO:Declaring metric variables
2023-06-03 14:53:57,151:INFO:Importing untrained model
2023-06-03 14:53:57,151:INFO:Declaring custom model
2023-06-03 14:53:57,152:INFO:Extra Trees Classifier Imported successfully
2023-06-03 14:53:57,152:INFO:Starting cross validation
2023-06-03 14:53:57,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:53:57,969:INFO:Calculating mean and std
2023-06-03 14:53:57,970:INFO:Creating metrics dataframe
2023-06-03 14:53:57,972:INFO:Finalizing model
2023-06-03 14:53:58,188:INFO:Uploading results into container
2023-06-03 14:53:58,189:INFO:Uploading model into container now
2023-06-03 14:53:58,189:INFO:_master_model_container: 18
2023-06-03 14:53:58,189:INFO:_display_container: 5
2023-06-03 14:53:58,190:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:58,190:INFO:create_model() successfully completed......................................
2023-06-03 14:53:58,301:INFO:SubProcess create_model() end ==================================
2023-06-03 14:53:58,302:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.2741
2023-06-03 14:53:58,302:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                     criterion='entropy', max_depth=5, max_features=1.0,
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0002, min_samples_leaf=5,
                     min_samples_split=10, min_weight_fraction_leaf=0.0,
                     n_estimators=150, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.2657
2023-06-03 14:53:58,302:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) is best model
2023-06-03 14:53:58,302:INFO:choose_better completed
2023-06-03 14:53:58,302:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-03 14:53:58,318:INFO:_master_model_container: 18
2023-06-03 14:53:58,319:INFO:_display_container: 4
2023-06-03 14:53:58,319:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 14:53:58,319:INFO:tune_model() successfully completed......................................
2023-06-03 14:53:58,467:INFO:Initializing tune_model()
2023-06-03 14:53:58,467:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>)
2023-06-03 14:53:58,467:INFO:Checking exceptions
2023-06-03 14:53:58,479:INFO:Copying training dataset
2023-06-03 14:53:58,482:INFO:Checking base model
2023-06-03 14:53:58,483:INFO:Base model : Light Gradient Boosting Machine
2023-06-03 14:53:58,485:INFO:Declaring metric variables
2023-06-03 14:53:58,488:INFO:Defining Hyperparameters
2023-06-03 14:53:58,599:INFO:Tuning with n_jobs=-1
2023-06-03 14:53:58,600:INFO:Initializing RandomizedSearchCV
2023-06-03 14:54:06,341:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-06-03 14:54:06,341:INFO:Hyperparameter search completed
2023-06-03 14:54:06,341:INFO:SubProcess create_model() called ==================================
2023-06-03 14:54:06,342:INFO:Initializing create_model()
2023-06-03 14:54:06,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b55580220>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-06-03 14:54:06,342:INFO:Checking exceptions
2023-06-03 14:54:06,342:INFO:Importing libraries
2023-06-03 14:54:06,342:INFO:Copying training dataset
2023-06-03 14:54:06,347:INFO:Defining folds
2023-06-03 14:54:06,347:INFO:Declaring metric variables
2023-06-03 14:54:06,350:INFO:Importing untrained model
2023-06-03 14:54:06,350:INFO:Declaring custom model
2023-06-03 14:54:06,353:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:54:06,358:INFO:Starting cross validation
2023-06-03 14:54:06,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:54:07,035:INFO:Calculating mean and std
2023-06-03 14:54:07,038:INFO:Creating metrics dataframe
2023-06-03 14:54:07,050:INFO:Finalizing model
2023-06-03 14:54:08,029:INFO:Uploading results into container
2023-06-03 14:54:08,030:INFO:Uploading model into container now
2023-06-03 14:54:08,030:INFO:_master_model_container: 19
2023-06-03 14:54:08,030:INFO:_display_container: 5
2023-06-03 14:54:08,030:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:54:08,031:INFO:create_model() successfully completed......................................
2023-06-03 14:54:08,141:INFO:SubProcess create_model() end ==================================
2023-06-03 14:54:08,141:INFO:choose_better activated
2023-06-03 14:54:08,145:INFO:SubProcess create_model() called ==================================
2023-06-03 14:54:08,146:INFO:Initializing create_model()
2023-06-03 14:54:08,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:54:08,146:INFO:Checking exceptions
2023-06-03 14:54:08,149:INFO:Importing libraries
2023-06-03 14:54:08,150:INFO:Copying training dataset
2023-06-03 14:54:08,158:INFO:Defining folds
2023-06-03 14:54:08,158:INFO:Declaring metric variables
2023-06-03 14:54:08,158:INFO:Importing untrained model
2023-06-03 14:54:08,158:INFO:Declaring custom model
2023-06-03 14:54:08,159:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 14:54:08,159:INFO:Starting cross validation
2023-06-03 14:54:08,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:54:08,794:INFO:Calculating mean and std
2023-06-03 14:54:08,794:INFO:Creating metrics dataframe
2023-06-03 14:54:08,798:INFO:Finalizing model
2023-06-03 14:54:08,992:INFO:Uploading results into container
2023-06-03 14:54:08,992:INFO:Uploading model into container now
2023-06-03 14:54:08,993:INFO:_master_model_container: 20
2023-06-03 14:54:08,993:INFO:_display_container: 6
2023-06-03 14:54:08,993:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:54:08,993:INFO:create_model() successfully completed......................................
2023-06-03 14:54:09,102:INFO:SubProcess create_model() end ==================================
2023-06-03 14:54:09,102:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.2704
2023-06-03 14:54:09,103:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.2767
2023-06-03 14:54:09,103:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-03 14:54:09,103:INFO:choose_better completed
2023-06-03 14:54:09,111:INFO:_master_model_container: 20
2023-06-03 14:54:09,111:INFO:_display_container: 5
2023-06-03 14:54:09,112:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 14:54:09,112:INFO:tune_model() successfully completed......................................
2023-06-03 14:54:09,279:INFO:Initializing tune_model()
2023-06-03 14:54:09,279:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>)
2023-06-03 14:54:09,279:INFO:Checking exceptions
2023-06-03 14:54:09,294:INFO:Copying training dataset
2023-06-03 14:54:09,296:INFO:Checking base model
2023-06-03 14:54:09,296:INFO:Base model : Gradient Boosting Classifier
2023-06-03 14:54:09,299:INFO:Declaring metric variables
2023-06-03 14:54:09,302:INFO:Defining Hyperparameters
2023-06-03 14:54:09,413:INFO:Tuning with n_jobs=-1
2023-06-03 14:54:09,413:INFO:Initializing RandomizedSearchCV
2023-06-03 14:54:25,305:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:32,967:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,026:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,046:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,053:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,086:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,225:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,291:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,346:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,478:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:33,573:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:40,843:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:40,857:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:40,959:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:41,038:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:41,315:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:41,466:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:41,474:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:41,660:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:41,721:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:41,845:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-03 14:54:48,264:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-06-03 14:54:48,264:INFO:Hyperparameter search completed
2023-06-03 14:54:48,265:INFO:SubProcess create_model() called ==================================
2023-06-03 14:54:48,265:INFO:Initializing create_model()
2023-06-03 14:54:48,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1ae5ab44c0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-06-03 14:54:48,265:INFO:Checking exceptions
2023-06-03 14:54:48,265:INFO:Importing libraries
2023-06-03 14:54:48,265:INFO:Copying training dataset
2023-06-03 14:54:48,270:INFO:Defining folds
2023-06-03 14:54:48,270:INFO:Declaring metric variables
2023-06-03 14:54:48,273:INFO:Importing untrained model
2023-06-03 14:54:48,273:INFO:Declaring custom model
2023-06-03 14:54:48,277:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:54:48,283:INFO:Starting cross validation
2023-06-03 14:54:48,284:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:54:49,215:INFO:Calculating mean and std
2023-06-03 14:54:49,218:INFO:Creating metrics dataframe
2023-06-03 14:54:49,229:INFO:Finalizing model
2023-06-03 14:54:52,431:INFO:Uploading results into container
2023-06-03 14:54:52,432:INFO:Uploading model into container now
2023-06-03 14:54:52,432:INFO:_master_model_container: 21
2023-06-03 14:54:52,432:INFO:_display_container: 6
2023-06-03 14:54:52,432:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:54:52,433:INFO:create_model() successfully completed......................................
2023-06-03 14:54:52,543:INFO:SubProcess create_model() end ==================================
2023-06-03 14:54:52,543:INFO:choose_better activated
2023-06-03 14:54:52,546:INFO:SubProcess create_model() called ==================================
2023-06-03 14:54:52,547:INFO:Initializing create_model()
2023-06-03 14:54:52,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:54:52,547:INFO:Checking exceptions
2023-06-03 14:54:52,548:INFO:Importing libraries
2023-06-03 14:54:52,548:INFO:Copying training dataset
2023-06-03 14:54:52,553:INFO:Defining folds
2023-06-03 14:54:52,553:INFO:Declaring metric variables
2023-06-03 14:54:52,553:INFO:Importing untrained model
2023-06-03 14:54:52,553:INFO:Declaring custom model
2023-06-03 14:54:52,554:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 14:54:52,554:INFO:Starting cross validation
2023-06-03 14:54:52,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:54:53,308:INFO:Calculating mean and std
2023-06-03 14:54:53,309:INFO:Creating metrics dataframe
2023-06-03 14:54:53,312:INFO:Finalizing model
2023-06-03 14:54:53,551:INFO:Uploading results into container
2023-06-03 14:54:53,551:INFO:Uploading model into container now
2023-06-03 14:54:53,552:INFO:_master_model_container: 22
2023-06-03 14:54:53,552:INFO:_display_container: 7
2023-06-03 14:54:53,552:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:54:53,552:INFO:create_model() successfully completed......................................
2023-06-03 14:54:53,662:INFO:SubProcess create_model() end ==================================
2023-06-03 14:54:53,663:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.2683
2023-06-03 14:54:53,663:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.276
2023-06-03 14:54:53,663:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-06-03 14:54:53,663:INFO:choose_better completed
2023-06-03 14:54:53,670:INFO:_master_model_container: 22
2023-06-03 14:54:53,670:INFO:_display_container: 6
2023-06-03 14:54:53,671:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 14:54:53,671:INFO:tune_model() successfully completed......................................
2023-06-03 14:54:53,824:INFO:Initializing tune_model()
2023-06-03 14:54:53,824:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>)
2023-06-03 14:54:53,824:INFO:Checking exceptions
2023-06-03 14:54:53,836:INFO:Copying training dataset
2023-06-03 14:54:53,839:INFO:Checking base model
2023-06-03 14:54:53,839:INFO:Base model : Logistic Regression
2023-06-03 14:54:53,842:INFO:Declaring metric variables
2023-06-03 14:54:53,847:INFO:Defining Hyperparameters
2023-06-03 14:54:53,967:INFO:Tuning with n_jobs=-1
2023-06-03 14:54:53,967:INFO:Initializing RandomizedSearchCV
2023-06-03 14:54:55,337:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,340:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,342:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,366:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,394:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,397:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,420:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,421:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,422:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,422:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,430:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,432:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,443:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,445:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,451:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,453:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,457:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,464:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:55,473:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,836:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,849:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,871:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,907:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,917:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,920:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,926:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,947:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,949:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,953:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:56,995:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,006:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,012:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,026:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,044:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,089:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,121:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,146:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,258:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:57,259:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,185:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,351:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,352:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,366:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,380:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,401:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,453:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,462:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,471:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,475:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,494:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,514:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,525:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,558:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,610:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,637:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,857:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:58,928:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,013:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,221:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,486:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,554:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,638:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,655:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,660:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,694:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,782:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,879:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:54:59,977:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,128:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,149:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,237:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,239:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,403:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,500:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,620:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,684:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,884:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:00,976:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,027:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,046:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,184:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,266:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,271:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,282:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,402:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,495:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,584:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,609:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,701:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:01,963:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,155:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,195:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,272:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,274:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,278:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,377:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,389:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,393:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:02,639:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:03,976:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 7.863}
2023-06-03 14:55:03,976:INFO:Hyperparameter search completed
2023-06-03 14:55:03,977:INFO:SubProcess create_model() called ==================================
2023-06-03 14:55:03,977:INFO:Initializing create_model()
2023-06-03 14:55:03,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1aed97f880>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 7.863})
2023-06-03 14:55:03,977:INFO:Checking exceptions
2023-06-03 14:55:03,977:INFO:Importing libraries
2023-06-03 14:55:03,977:INFO:Copying training dataset
2023-06-03 14:55:03,982:INFO:Defining folds
2023-06-03 14:55:03,982:INFO:Declaring metric variables
2023-06-03 14:55:03,984:INFO:Importing untrained model
2023-06-03 14:55:03,985:INFO:Declaring custom model
2023-06-03 14:55:03,987:INFO:Logistic Regression Imported successfully
2023-06-03 14:55:03,993:INFO:Starting cross validation
2023-06-03 14:55:03,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:55:04,617:INFO:Calculating mean and std
2023-06-03 14:55:04,620:INFO:Creating metrics dataframe
2023-06-03 14:55:04,625:INFO:Finalizing model
2023-06-03 14:55:05,459:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:05,527:INFO:Uploading results into container
2023-06-03 14:55:05,528:INFO:Uploading model into container now
2023-06-03 14:55:05,528:INFO:_master_model_container: 23
2023-06-03 14:55:05,529:INFO:_display_container: 7
2023-06-03 14:55:05,529:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:55:05,529:INFO:create_model() successfully completed......................................
2023-06-03 14:55:05,639:INFO:SubProcess create_model() end ==================================
2023-06-03 14:55:05,639:INFO:choose_better activated
2023-06-03 14:55:05,642:INFO:SubProcess create_model() called ==================================
2023-06-03 14:55:05,643:INFO:Initializing create_model()
2023-06-03 14:55:05,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:55:05,643:INFO:Checking exceptions
2023-06-03 14:55:05,644:INFO:Importing libraries
2023-06-03 14:55:05,645:INFO:Copying training dataset
2023-06-03 14:55:05,649:INFO:Defining folds
2023-06-03 14:55:05,649:INFO:Declaring metric variables
2023-06-03 14:55:05,649:INFO:Importing untrained model
2023-06-03 14:55:05,649:INFO:Declaring custom model
2023-06-03 14:55:05,650:INFO:Logistic Regression Imported successfully
2023-06-03 14:55:05,650:INFO:Starting cross validation
2023-06-03 14:55:05,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:55:06,204:INFO:Calculating mean and std
2023-06-03 14:55:06,205:INFO:Creating metrics dataframe
2023-06-03 14:55:06,210:INFO:Finalizing model
2023-06-03 14:55:06,422:INFO:Uploading results into container
2023-06-03 14:55:06,422:INFO:Uploading model into container now
2023-06-03 14:55:06,423:INFO:_master_model_container: 24
2023-06-03 14:55:06,423:INFO:_display_container: 8
2023-06-03 14:55:06,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:55:06,423:INFO:create_model() successfully completed......................................
2023-06-03 14:55:06,533:INFO:SubProcess create_model() end ==================================
2023-06-03 14:55:06,533:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.2627
2023-06-03 14:55:06,534:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.2637
2023-06-03 14:55:06,534:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-06-03 14:55:06,534:INFO:choose_better completed
2023-06-03 14:55:06,541:INFO:_master_model_container: 24
2023-06-03 14:55:06,541:INFO:_display_container: 7
2023-06-03 14:55:06,541:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 14:55:06,541:INFO:tune_model() successfully completed......................................
2023-06-03 14:55:06,744:INFO:Initializing blend_models()
2023-06-03 14:55:06,744:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator_list=[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=10, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-06-03 14:55:06,744:INFO:Checking exceptions
2023-06-03 14:55:06,773:INFO:Importing libraries
2023-06-03 14:55:06,773:INFO:Copying training dataset
2023-06-03 14:55:06,779:INFO:Getting model names
2023-06-03 14:55:06,788:INFO:SubProcess create_model() called ==================================
2023-06-03 14:55:06,802:INFO:Initializing create_model()
2023-06-03 14:55:06,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False...
                                                         warm_start=False)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1b206f4670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 14:55:06,802:INFO:Checking exceptions
2023-06-03 14:55:06,802:INFO:Importing libraries
2023-06-03 14:55:06,802:INFO:Copying training dataset
2023-06-03 14:55:06,809:INFO:Defining folds
2023-06-03 14:55:06,809:INFO:Declaring metric variables
2023-06-03 14:55:06,813:INFO:Importing untrained model
2023-06-03 14:55:06,813:INFO:Declaring custom model
2023-06-03 14:55:06,819:INFO:Voting Classifier Imported successfully
2023-06-03 14:55:06,825:INFO:Starting cross validation
2023-06-03 14:55:06,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 14:55:09,881:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:09,949:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:09,981:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:09,990:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:10,006:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:10,014:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:10,020:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:10,057:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:10,059:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:10,075:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:15,788:INFO:Calculating mean and std
2023-06-03 14:55:15,790:INFO:Creating metrics dataframe
2023-06-03 14:55:15,795:INFO:Finalizing model
2023-06-03 14:55:17,142:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:20,333:INFO:Uploading results into container
2023-06-03 14:55:20,335:INFO:Uploading model into container now
2023-06-03 14:55:20,336:INFO:_master_model_container: 25
2023-06-03 14:55:20,336:INFO:_display_container: 8
2023-06-03 14:55:20,349:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False...
                                                         warm_start=False)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-06-03 14:55:20,349:INFO:create_model() successfully completed......................................
2023-06-03 14:55:20,483:INFO:SubProcess create_model() end ==================================
2023-06-03 14:55:20,490:INFO:_master_model_container: 25
2023-06-03 14:55:20,490:INFO:_display_container: 8
2023-06-03 14:55:20,495:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False...
                                                         warm_start=False)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-06-03 14:55:20,495:INFO:blend_models() successfully completed......................................
2023-06-03 14:55:20,769:INFO:Initializing finalize_model()
2023-06-03 14:55:20,769:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False...
                                                         warm_start=False)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-03 14:55:20,778:INFO:Finalizing VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False...
                                                         warm_start=False)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-06-03 14:55:20,789:INFO:Initializing create_model()
2023-06-03 14:55:20,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1b20dc1970>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False...
                                                         warm_start=False)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-03 14:55:20,789:INFO:Checking exceptions
2023-06-03 14:55:20,791:INFO:Importing libraries
2023-06-03 14:55:20,791:INFO:Copying training dataset
2023-06-03 14:55:20,791:INFO:Defining folds
2023-06-03 14:55:20,791:INFO:Declaring metric variables
2023-06-03 14:55:20,791:INFO:Importing untrained model
2023-06-03 14:55:20,792:INFO:Declaring custom model
2023-06-03 14:55:20,793:INFO:Voting Classifier Imported successfully
2023-06-03 14:55:20,794:INFO:Cross validation set to False
2023-06-03 14:55:20,794:INFO:Fitting Model
2023-06-03 14:55:22,237:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 14:55:26,235:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                              ('Logistic Regression',
                                               LogisticRegression(C=1.0,
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-06-03 14:55:26,236:INFO:create_model() successfully completed......................................
2023-06-03 14:55:26,352:INFO:_master_model_container: 25
2023-06-03 14:55:26,352:INFO:_display_container: 8
2023-06-03 14:55:26,365:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'ocurcause',
                                             'rainamount', 'raindays',
                                             'tempavg', 'windavg', 'within_5km',
                                             'within_10km', 'within_30km',
                                             'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                              ('Logistic Regression',
                                               LogisticRegression(C=1.0,
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-06-03 14:55:26,365:INFO:finalize_model() successfully completed......................................
2023-06-03 18:10:18,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 18:10:18,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 18:10:18,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 18:10:18,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-03 18:10:18,902:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-03 18:10:19,026:INFO:PyCaret ClassificationExperiment
2023-06-03 18:10:19,026:INFO:Logging name: clf-default-name
2023-06-03 18:10:19,026:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 18:10:19,026:INFO:version 3.0.2
2023-06-03 18:10:19,026:INFO:Initializing setup()
2023-06-03 18:10:19,026:INFO:self.USI: 8132
2023-06-03 18:10:19,026:INFO:self._variable_keys: {'is_multiclass', 'data', 'exp_name_log', 'memory', 'target_param', 'USI', 'X', 'gpu_n_jobs_param', 'logging_param', 'pipeline', 'html_param', 'fold_generator', '_ml_usecase', 'y', 'fold_shuffle_param', 'n_jobs_param', 'log_plots_param', 'idx', 'fold_groups_param', 'y_test', 'X_test', 'seed', 'gpu_param', '_available_plots', 'exp_id', 'y_train', 'fix_imbalance', 'X_train'}
2023-06-03 18:10:19,026:INFO:Checking environment
2023-06-03 18:10:19,026:INFO:python_version: 3.8.16
2023-06-03 18:10:19,026:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 18:10:19,026:INFO:machine: x86_64
2023-06-03 18:10:19,026:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 18:10:19,026:INFO:Memory: svmem(total=134737395712, available=85925703680, percent=36.2, used=47239303168, free=7731302400, active=30360100864, inactive=87218204672, buffers=2417524736, cached=77349265408, shared=28499968, slab=4625522688)
2023-06-03 18:10:19,027:INFO:Physical Core: 10
2023-06-03 18:10:19,027:INFO:Logical Core: 20
2023-06-03 18:10:19,027:INFO:Checking libraries
2023-06-03 18:10:19,027:INFO:System:
2023-06-03 18:10:19,027:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 18:10:19,027:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 18:10:19,027:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 18:10:19,027:INFO:PyCaret required dependencies:
2023-06-03 18:10:19,027:INFO:                 pip: 23.0.1
2023-06-03 18:10:19,027:INFO:          setuptools: 67.8.0
2023-06-03 18:10:19,027:INFO:             pycaret: 3.0.2
2023-06-03 18:10:19,027:INFO:             IPython: 8.12.2
2023-06-03 18:10:19,027:INFO:          ipywidgets: 8.0.6
2023-06-03 18:10:19,027:INFO:                tqdm: 4.65.0
2023-06-03 18:10:19,028:INFO:               numpy: 1.23.5
2023-06-03 18:10:19,028:INFO:              pandas: 1.5.3
2023-06-03 18:10:19,028:INFO:              jinja2: 3.1.2
2023-06-03 18:10:19,028:INFO:               scipy: 1.10.1
2023-06-03 18:10:19,028:INFO:              joblib: 1.2.0
2023-06-03 18:10:19,028:INFO:             sklearn: 1.2.2
2023-06-03 18:10:19,028:INFO:                pyod: 1.0.9
2023-06-03 18:10:19,028:INFO:            imblearn: 0.10.1
2023-06-03 18:10:19,028:INFO:   category_encoders: 2.6.1
2023-06-03 18:10:19,028:INFO:            lightgbm: 3.3.5
2023-06-03 18:10:19,028:INFO:               numba: 0.57.0
2023-06-03 18:10:19,028:INFO:            requests: 2.31.0
2023-06-03 18:10:19,028:INFO:          matplotlib: 3.7.1
2023-06-03 18:10:19,028:INFO:          scikitplot: 0.3.7
2023-06-03 18:10:19,028:INFO:         yellowbrick: 1.5
2023-06-03 18:10:19,028:INFO:              plotly: 5.14.1
2023-06-03 18:10:19,028:INFO:             kaleido: 0.2.1
2023-06-03 18:10:19,028:INFO:         statsmodels: 0.14.0
2023-06-03 18:10:19,028:INFO:              sktime: 0.17.0
2023-06-03 18:10:19,028:INFO:               tbats: 1.1.3
2023-06-03 18:10:19,028:INFO:            pmdarima: 2.0.3
2023-06-03 18:10:19,028:INFO:              psutil: 5.9.5
2023-06-03 18:10:19,028:INFO:PyCaret optional dependencies:
2023-06-03 18:10:19,041:INFO:                shap: Not installed
2023-06-03 18:10:19,041:INFO:           interpret: Not installed
2023-06-03 18:10:19,042:INFO:                umap: Not installed
2023-06-03 18:10:19,042:INFO:    pandas_profiling: Not installed
2023-06-03 18:10:19,042:INFO:  explainerdashboard: Not installed
2023-06-03 18:10:19,042:INFO:             autoviz: Not installed
2023-06-03 18:10:19,042:INFO:           fairlearn: Not installed
2023-06-03 18:10:19,042:INFO:             xgboost: Not installed
2023-06-03 18:10:19,042:INFO:            catboost: Not installed
2023-06-03 18:10:19,042:INFO:              kmodes: Not installed
2023-06-03 18:10:19,042:INFO:             mlxtend: Not installed
2023-06-03 18:10:19,042:INFO:       statsforecast: Not installed
2023-06-03 18:10:19,042:INFO:        tune_sklearn: Not installed
2023-06-03 18:10:19,042:INFO:                 ray: Not installed
2023-06-03 18:10:19,042:INFO:            hyperopt: Not installed
2023-06-03 18:10:19,042:INFO:              optuna: Not installed
2023-06-03 18:10:19,042:INFO:               skopt: Not installed
2023-06-03 18:10:19,042:INFO:              mlflow: Not installed
2023-06-03 18:10:19,042:INFO:              gradio: Not installed
2023-06-03 18:10:19,043:INFO:             fastapi: Not installed
2023-06-03 18:10:19,043:INFO:             uvicorn: Not installed
2023-06-03 18:10:19,043:INFO:              m2cgen: Not installed
2023-06-03 18:10:19,043:INFO:           evidently: Not installed
2023-06-03 18:10:19,043:INFO:               fugue: Not installed
2023-06-03 18:10:19,043:INFO:           streamlit: Not installed
2023-06-03 18:10:19,043:INFO:             prophet: Not installed
2023-06-03 18:10:19,043:INFO:None
2023-06-03 18:10:19,043:INFO:Set up data.
2023-06-03 18:10:19,059:INFO:Set up train/test split.
2023-06-03 18:10:19,068:INFO:Set up index.
2023-06-03 18:10:19,069:INFO:Set up folding strategy.
2023-06-03 18:10:19,069:INFO:Assigning column types.
2023-06-03 18:10:19,073:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 18:10:19,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,109:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,176:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,197:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 18:10:19,230:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,282:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,302:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 18:10:19,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,406:INFO:Preparing preprocessing pipeline...
2023-06-03 18:10:19,407:INFO:Set up simple imputation.
2023-06-03 18:10:19,421:INFO:Finished creating preprocessing pipeline.
2023-06-03 18:10:19,424:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'rainamount',
                                             'raindays', 'tempavg', 'windavg',
                                             'within_5km', 'within_10km',
                                             'within_30km', 'within_5km_fact',
                                             'within_10km_fact',
                                             'within_30km_fact', 'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-03 18:10:19,424:INFO:Creating final display dataframe.
2023-06-03 18:10:19,473:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape        (8120, 14)
4        Transformed data shape        (8120, 14)
5   Transformed train set shape        (5684, 14)
6    Transformed test set shape        (2436, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              8132
2023-06-03 18:10:19,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,587:INFO:setup() successfully completed in 0.62s...............
2023-06-03 18:10:19,751:INFO:PyCaret ClassificationExperiment
2023-06-03 18:10:19,751:INFO:Logging name: clf-default-name
2023-06-03 18:10:19,751:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-03 18:10:19,751:INFO:version 3.0.2
2023-06-03 18:10:19,751:INFO:Initializing setup()
2023-06-03 18:10:19,751:INFO:self.USI: 335b
2023-06-03 18:10:19,751:INFO:self._variable_keys: {'is_multiclass', 'data', 'exp_name_log', 'memory', 'target_param', 'USI', 'X', 'gpu_n_jobs_param', 'logging_param', 'pipeline', 'html_param', 'fold_generator', '_ml_usecase', 'y', 'fold_shuffle_param', 'n_jobs_param', 'log_plots_param', 'idx', 'fold_groups_param', 'y_test', 'X_test', 'seed', 'gpu_param', '_available_plots', 'exp_id', 'y_train', 'fix_imbalance', 'X_train'}
2023-06-03 18:10:19,751:INFO:Checking environment
2023-06-03 18:10:19,751:INFO:python_version: 3.8.16
2023-06-03 18:10:19,751:INFO:python_build: ('default', 'Mar  2 2023 03:21:46')
2023-06-03 18:10:19,751:INFO:machine: x86_64
2023-06-03 18:10:19,751:INFO:platform: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 18:10:19,751:INFO:Memory: svmem(total=134737395712, available=85916315648, percent=36.2, used=47248699392, free=7721312256, active=30360735744, inactive=87227580416, buffers=2417528832, cached=77349855232, shared=28499968, slab=4625682432)
2023-06-03 18:10:19,752:INFO:Physical Core: 10
2023-06-03 18:10:19,752:INFO:Logical Core: 20
2023-06-03 18:10:19,752:INFO:Checking libraries
2023-06-03 18:10:19,752:INFO:System:
2023-06-03 18:10:19,752:INFO:    python: 3.8.16 (default, Mar  2 2023, 03:21:46)  [GCC 11.2.0]
2023-06-03 18:10:19,752:INFO:executable: /home/jaezic/anaconda3/envs/ml/bin/python
2023-06-03 18:10:19,752:INFO:   machine: Linux-5.15.0-67-generic-x86_64-with-glibc2.17
2023-06-03 18:10:19,752:INFO:PyCaret required dependencies:
2023-06-03 18:10:19,752:INFO:                 pip: 23.0.1
2023-06-03 18:10:19,752:INFO:          setuptools: 67.8.0
2023-06-03 18:10:19,752:INFO:             pycaret: 3.0.2
2023-06-03 18:10:19,752:INFO:             IPython: 8.12.2
2023-06-03 18:10:19,752:INFO:          ipywidgets: 8.0.6
2023-06-03 18:10:19,752:INFO:                tqdm: 4.65.0
2023-06-03 18:10:19,752:INFO:               numpy: 1.23.5
2023-06-03 18:10:19,752:INFO:              pandas: 1.5.3
2023-06-03 18:10:19,752:INFO:              jinja2: 3.1.2
2023-06-03 18:10:19,752:INFO:               scipy: 1.10.1
2023-06-03 18:10:19,752:INFO:              joblib: 1.2.0
2023-06-03 18:10:19,752:INFO:             sklearn: 1.2.2
2023-06-03 18:10:19,752:INFO:                pyod: 1.0.9
2023-06-03 18:10:19,752:INFO:            imblearn: 0.10.1
2023-06-03 18:10:19,752:INFO:   category_encoders: 2.6.1
2023-06-03 18:10:19,752:INFO:            lightgbm: 3.3.5
2023-06-03 18:10:19,752:INFO:               numba: 0.57.0
2023-06-03 18:10:19,752:INFO:            requests: 2.31.0
2023-06-03 18:10:19,752:INFO:          matplotlib: 3.7.1
2023-06-03 18:10:19,752:INFO:          scikitplot: 0.3.7
2023-06-03 18:10:19,752:INFO:         yellowbrick: 1.5
2023-06-03 18:10:19,752:INFO:              plotly: 5.14.1
2023-06-03 18:10:19,752:INFO:             kaleido: 0.2.1
2023-06-03 18:10:19,752:INFO:         statsmodels: 0.14.0
2023-06-03 18:10:19,752:INFO:              sktime: 0.17.0
2023-06-03 18:10:19,752:INFO:               tbats: 1.1.3
2023-06-03 18:10:19,752:INFO:            pmdarima: 2.0.3
2023-06-03 18:10:19,752:INFO:              psutil: 5.9.5
2023-06-03 18:10:19,752:INFO:PyCaret optional dependencies:
2023-06-03 18:10:19,752:INFO:                shap: Not installed
2023-06-03 18:10:19,752:INFO:           interpret: Not installed
2023-06-03 18:10:19,753:INFO:                umap: Not installed
2023-06-03 18:10:19,753:INFO:    pandas_profiling: Not installed
2023-06-03 18:10:19,753:INFO:  explainerdashboard: Not installed
2023-06-03 18:10:19,753:INFO:             autoviz: Not installed
2023-06-03 18:10:19,753:INFO:           fairlearn: Not installed
2023-06-03 18:10:19,753:INFO:             xgboost: Not installed
2023-06-03 18:10:19,753:INFO:            catboost: Not installed
2023-06-03 18:10:19,753:INFO:              kmodes: Not installed
2023-06-03 18:10:19,753:INFO:             mlxtend: Not installed
2023-06-03 18:10:19,753:INFO:       statsforecast: Not installed
2023-06-03 18:10:19,753:INFO:        tune_sklearn: Not installed
2023-06-03 18:10:19,753:INFO:                 ray: Not installed
2023-06-03 18:10:19,753:INFO:            hyperopt: Not installed
2023-06-03 18:10:19,753:INFO:              optuna: Not installed
2023-06-03 18:10:19,753:INFO:               skopt: Not installed
2023-06-03 18:10:19,753:INFO:              mlflow: Not installed
2023-06-03 18:10:19,753:INFO:              gradio: Not installed
2023-06-03 18:10:19,753:INFO:             fastapi: Not installed
2023-06-03 18:10:19,753:INFO:             uvicorn: Not installed
2023-06-03 18:10:19,753:INFO:              m2cgen: Not installed
2023-06-03 18:10:19,753:INFO:           evidently: Not installed
2023-06-03 18:10:19,753:INFO:               fugue: Not installed
2023-06-03 18:10:19,753:INFO:           streamlit: Not installed
2023-06-03 18:10:19,753:INFO:             prophet: Not installed
2023-06-03 18:10:19,753:INFO:None
2023-06-03 18:10:19,753:INFO:Set up data.
2023-06-03 18:10:19,760:INFO:Set up train/test split.
2023-06-03 18:10:19,765:INFO:Set up index.
2023-06-03 18:10:19,765:INFO:Set up folding strategy.
2023-06-03 18:10:19,765:INFO:Assigning column types.
2023-06-03 18:10:19,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-03 18:10:19,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,801:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,853:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,873:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-03 18:10:19,906:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,959:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-03 18:10:19,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:19,979:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-03 18:10:20,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,079:INFO:Preparing preprocessing pipeline...
2023-06-03 18:10:20,080:INFO:Set up simple imputation.
2023-06-03 18:10:20,080:INFO:Set up feature normalization.
2023-06-03 18:10:20,098:INFO:Finished creating preprocessing pipeline.
2023-06-03 18:10:20,101:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['diravg', 'humidrel', 'rainamount',
                                             'raindays', 'tempavg', 'windavg',
                                             'within_5km', 'within_10km',
                                             'within_30km', 'within_5km_fact',
                                             'within_10km_fact',
                                             'within_30km_fact', 'height'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-06-03 18:10:20,101:INFO:Creating final display dataframe.
2023-06-03 18:10:20,160:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      scale_damage
2                   Target type        Multiclass
3           Original data shape        (8120, 14)
4        Transformed data shape        (8120, 14)
5   Transformed train set shape        (5684, 14)
6    Transformed test set shape        (2436, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              335b
2023-06-03 18:10:20,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,299:INFO:setup() successfully completed in 0.62s...............
2023-06-03 18:10:20,333:INFO:gpu_param set to False
2023-06-03 18:10:20,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-03 18:10:20,478:INFO:Initializing compare_models()
2023-06-03 18:10:20,478:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-03 18:10:20,478:INFO:Checking exceptions
2023-06-03 18:10:20,485:INFO:Preparing display monitor
2023-06-03 18:10:20,522:INFO:Initializing Logistic Regression
2023-06-03 18:10:20,522:INFO:Total runtime is 5.145867665608724e-06 minutes
2023-06-03 18:10:20,529:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:20,530:INFO:Initializing create_model()
2023-06-03 18:10:20,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:20,530:INFO:Checking exceptions
2023-06-03 18:10:20,530:INFO:Importing libraries
2023-06-03 18:10:20,530:INFO:Copying training dataset
2023-06-03 18:10:20,539:INFO:Defining folds
2023-06-03 18:10:20,539:INFO:Declaring metric variables
2023-06-03 18:10:20,543:INFO:Importing untrained model
2023-06-03 18:10:20,548:INFO:Logistic Regression Imported successfully
2023-06-03 18:10:20,555:INFO:Starting cross validation
2023-06-03 18:10:20,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:22,404:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,410:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,411:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,430:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,435:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,448:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,449:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,489:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,506:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:22,518:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-06-03 18:10:23,025:INFO:Calculating mean and std
2023-06-03 18:10:23,027:INFO:Creating metrics dataframe
2023-06-03 18:10:23,259:INFO:Uploading results into container
2023-06-03 18:10:23,260:INFO:Uploading model into container now
2023-06-03 18:10:23,260:INFO:_master_model_container: 1
2023-06-03 18:10:23,261:INFO:_display_container: 2
2023-06-03 18:10:23,261:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-03 18:10:23,261:INFO:create_model() successfully completed......................................
2023-06-03 18:10:23,360:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:23,360:INFO:Creating metrics dataframe
2023-06-03 18:10:23,369:INFO:Initializing K Neighbors Classifier
2023-06-03 18:10:23,369:INFO:Total runtime is 0.04745736519495646 minutes
2023-06-03 18:10:23,373:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:23,373:INFO:Initializing create_model()
2023-06-03 18:10:23,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:23,373:INFO:Checking exceptions
2023-06-03 18:10:23,373:INFO:Importing libraries
2023-06-03 18:10:23,373:INFO:Copying training dataset
2023-06-03 18:10:23,378:INFO:Defining folds
2023-06-03 18:10:23,378:INFO:Declaring metric variables
2023-06-03 18:10:23,382:INFO:Importing untrained model
2023-06-03 18:10:23,386:INFO:K Neighbors Classifier Imported successfully
2023-06-03 18:10:23,393:INFO:Starting cross validation
2023-06-03 18:10:23,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:24,891:INFO:Calculating mean and std
2023-06-03 18:10:24,894:INFO:Creating metrics dataframe
2023-06-03 18:10:25,123:INFO:Uploading results into container
2023-06-03 18:10:25,124:INFO:Uploading model into container now
2023-06-03 18:10:25,124:INFO:_master_model_container: 2
2023-06-03 18:10:25,125:INFO:_display_container: 2
2023-06-03 18:10:25,125:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-03 18:10:25,125:INFO:create_model() successfully completed......................................
2023-06-03 18:10:25,200:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:25,200:INFO:Creating metrics dataframe
2023-06-03 18:10:25,219:INFO:Initializing Naive Bayes
2023-06-03 18:10:25,219:INFO:Total runtime is 0.07828470468521118 minutes
2023-06-03 18:10:25,224:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:25,224:INFO:Initializing create_model()
2023-06-03 18:10:25,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:25,224:INFO:Checking exceptions
2023-06-03 18:10:25,224:INFO:Importing libraries
2023-06-03 18:10:25,224:INFO:Copying training dataset
2023-06-03 18:10:25,230:INFO:Defining folds
2023-06-03 18:10:25,231:INFO:Declaring metric variables
2023-06-03 18:10:25,234:INFO:Importing untrained model
2023-06-03 18:10:25,237:INFO:Naive Bayes Imported successfully
2023-06-03 18:10:25,242:INFO:Starting cross validation
2023-06-03 18:10:25,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:25,870:INFO:Calculating mean and std
2023-06-03 18:10:25,872:INFO:Creating metrics dataframe
2023-06-03 18:10:26,085:INFO:Uploading results into container
2023-06-03 18:10:26,086:INFO:Uploading model into container now
2023-06-03 18:10:26,086:INFO:_master_model_container: 3
2023-06-03 18:10:26,086:INFO:_display_container: 2
2023-06-03 18:10:26,086:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-03 18:10:26,086:INFO:create_model() successfully completed......................................
2023-06-03 18:10:26,166:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:26,166:INFO:Creating metrics dataframe
2023-06-03 18:10:26,174:INFO:Initializing Decision Tree Classifier
2023-06-03 18:10:26,175:INFO:Total runtime is 0.09420929749806721 minutes
2023-06-03 18:10:26,177:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:26,177:INFO:Initializing create_model()
2023-06-03 18:10:26,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:26,177:INFO:Checking exceptions
2023-06-03 18:10:26,177:INFO:Importing libraries
2023-06-03 18:10:26,177:INFO:Copying training dataset
2023-06-03 18:10:26,181:INFO:Defining folds
2023-06-03 18:10:26,182:INFO:Declaring metric variables
2023-06-03 18:10:26,184:INFO:Importing untrained model
2023-06-03 18:10:26,191:INFO:Decision Tree Classifier Imported successfully
2023-06-03 18:10:26,202:INFO:Starting cross validation
2023-06-03 18:10:26,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:26,812:INFO:Calculating mean and std
2023-06-03 18:10:26,815:INFO:Creating metrics dataframe
2023-06-03 18:10:27,057:INFO:Uploading results into container
2023-06-03 18:10:27,057:INFO:Uploading model into container now
2023-06-03 18:10:27,058:INFO:_master_model_container: 4
2023-06-03 18:10:27,058:INFO:_display_container: 2
2023-06-03 18:10:27,058:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-06-03 18:10:27,058:INFO:create_model() successfully completed......................................
2023-06-03 18:10:27,131:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:27,132:INFO:Creating metrics dataframe
2023-06-03 18:10:27,141:INFO:Initializing SVM - Linear Kernel
2023-06-03 18:10:27,141:INFO:Total runtime is 0.11031327247619628 minutes
2023-06-03 18:10:27,148:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:27,149:INFO:Initializing create_model()
2023-06-03 18:10:27,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:27,149:INFO:Checking exceptions
2023-06-03 18:10:27,150:INFO:Importing libraries
2023-06-03 18:10:27,150:INFO:Copying training dataset
2023-06-03 18:10:27,160:INFO:Defining folds
2023-06-03 18:10:27,160:INFO:Declaring metric variables
2023-06-03 18:10:27,164:INFO:Importing untrained model
2023-06-03 18:10:27,168:INFO:SVM - Linear Kernel Imported successfully
2023-06-03 18:10:27,175:INFO:Starting cross validation
2023-06-03 18:10:27,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:27,323:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,327:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:27,371:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,374:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:27,377:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,378:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,381:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,393:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,398:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,456:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,464:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,492:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-03 18:10:27,892:INFO:Calculating mean and std
2023-06-03 18:10:27,895:INFO:Creating metrics dataframe
2023-06-03 18:10:28,119:INFO:Uploading results into container
2023-06-03 18:10:28,120:INFO:Uploading model into container now
2023-06-03 18:10:28,120:INFO:_master_model_container: 5
2023-06-03 18:10:28,120:INFO:_display_container: 2
2023-06-03 18:10:28,121:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-03 18:10:28,121:INFO:create_model() successfully completed......................................
2023-06-03 18:10:28,201:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:28,201:INFO:Creating metrics dataframe
2023-06-03 18:10:28,210:INFO:Initializing Ridge Classifier
2023-06-03 18:10:28,210:INFO:Total runtime is 0.12813499768575032 minutes
2023-06-03 18:10:28,213:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:28,213:INFO:Initializing create_model()
2023-06-03 18:10:28,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:28,213:INFO:Checking exceptions
2023-06-03 18:10:28,213:INFO:Importing libraries
2023-06-03 18:10:28,213:INFO:Copying training dataset
2023-06-03 18:10:28,217:INFO:Defining folds
2023-06-03 18:10:28,217:INFO:Declaring metric variables
2023-06-03 18:10:28,220:INFO:Importing untrained model
2023-06-03 18:10:28,227:INFO:Ridge Classifier Imported successfully
2023-06-03 18:10:28,239:INFO:Starting cross validation
2023-06-03 18:10:28,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:28,320:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,325:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,326:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,327:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,328:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,332:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,341:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,344:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,350:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,354:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-03 18:10:28,790:INFO:Calculating mean and std
2023-06-03 18:10:28,793:INFO:Creating metrics dataframe
2023-06-03 18:10:29,006:INFO:Uploading results into container
2023-06-03 18:10:29,007:INFO:Uploading model into container now
2023-06-03 18:10:29,007:INFO:_master_model_container: 6
2023-06-03 18:10:29,007:INFO:_display_container: 2
2023-06-03 18:10:29,007:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-06-03 18:10:29,007:INFO:create_model() successfully completed......................................
2023-06-03 18:10:29,082:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:29,083:INFO:Creating metrics dataframe
2023-06-03 18:10:29,091:INFO:Initializing Random Forest Classifier
2023-06-03 18:10:29,092:INFO:Total runtime is 0.14282666047414144 minutes
2023-06-03 18:10:29,094:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:29,095:INFO:Initializing create_model()
2023-06-03 18:10:29,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:29,095:INFO:Checking exceptions
2023-06-03 18:10:29,095:INFO:Importing libraries
2023-06-03 18:10:29,095:INFO:Copying training dataset
2023-06-03 18:10:29,099:INFO:Defining folds
2023-06-03 18:10:29,099:INFO:Declaring metric variables
2023-06-03 18:10:29,101:INFO:Importing untrained model
2023-06-03 18:10:29,104:INFO:Random Forest Classifier Imported successfully
2023-06-03 18:10:29,109:INFO:Starting cross validation
2023-06-03 18:10:29,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:30,942:INFO:Calculating mean and std
2023-06-03 18:10:30,944:INFO:Creating metrics dataframe
2023-06-03 18:10:31,169:INFO:Uploading results into container
2023-06-03 18:10:31,170:INFO:Uploading model into container now
2023-06-03 18:10:31,170:INFO:_master_model_container: 7
2023-06-03 18:10:31,170:INFO:_display_container: 2
2023-06-03 18:10:31,171:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 18:10:31,171:INFO:create_model() successfully completed......................................
2023-06-03 18:10:31,253:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:31,254:INFO:Creating metrics dataframe
2023-06-03 18:10:31,263:INFO:Initializing Quadratic Discriminant Analysis
2023-06-03 18:10:31,263:INFO:Total runtime is 0.17901349067687988 minutes
2023-06-03 18:10:31,265:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:31,266:INFO:Initializing create_model()
2023-06-03 18:10:31,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:31,266:INFO:Checking exceptions
2023-06-03 18:10:31,266:INFO:Importing libraries
2023-06-03 18:10:31,266:INFO:Copying training dataset
2023-06-03 18:10:31,270:INFO:Defining folds
2023-06-03 18:10:31,270:INFO:Declaring metric variables
2023-06-03 18:10:31,273:INFO:Importing untrained model
2023-06-03 18:10:31,276:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-03 18:10:31,281:INFO:Starting cross validation
2023-06-03 18:10:31,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:31,899:INFO:Calculating mean and std
2023-06-03 18:10:31,900:INFO:Creating metrics dataframe
2023-06-03 18:10:32,140:INFO:Uploading results into container
2023-06-03 18:10:32,141:INFO:Uploading model into container now
2023-06-03 18:10:32,142:INFO:_master_model_container: 8
2023-06-03 18:10:32,142:INFO:_display_container: 2
2023-06-03 18:10:32,142:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-03 18:10:32,142:INFO:create_model() successfully completed......................................
2023-06-03 18:10:32,219:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:32,219:INFO:Creating metrics dataframe
2023-06-03 18:10:32,229:INFO:Initializing Ada Boost Classifier
2023-06-03 18:10:32,229:INFO:Total runtime is 0.19511437813440957 minutes
2023-06-03 18:10:32,232:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:32,232:INFO:Initializing create_model()
2023-06-03 18:10:32,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:32,232:INFO:Checking exceptions
2023-06-03 18:10:32,232:INFO:Importing libraries
2023-06-03 18:10:32,232:INFO:Copying training dataset
2023-06-03 18:10:32,236:INFO:Defining folds
2023-06-03 18:10:32,236:INFO:Declaring metric variables
2023-06-03 18:10:32,239:INFO:Importing untrained model
2023-06-03 18:10:32,241:INFO:Ada Boost Classifier Imported successfully
2023-06-03 18:10:32,247:INFO:Starting cross validation
2023-06-03 18:10:32,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:33,135:INFO:Calculating mean and std
2023-06-03 18:10:33,137:INFO:Creating metrics dataframe
2023-06-03 18:10:33,349:INFO:Uploading results into container
2023-06-03 18:10:33,350:INFO:Uploading model into container now
2023-06-03 18:10:33,350:INFO:_master_model_container: 9
2023-06-03 18:10:33,350:INFO:_display_container: 2
2023-06-03 18:10:33,351:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 18:10:33,351:INFO:create_model() successfully completed......................................
2023-06-03 18:10:33,424:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:33,424:INFO:Creating metrics dataframe
2023-06-03 18:10:33,433:INFO:Initializing Gradient Boosting Classifier
2023-06-03 18:10:33,433:INFO:Total runtime is 0.21518515348434447 minutes
2023-06-03 18:10:33,436:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:33,436:INFO:Initializing create_model()
2023-06-03 18:10:33,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:33,436:INFO:Checking exceptions
2023-06-03 18:10:33,436:INFO:Importing libraries
2023-06-03 18:10:33,436:INFO:Copying training dataset
2023-06-03 18:10:33,440:INFO:Defining folds
2023-06-03 18:10:33,440:INFO:Declaring metric variables
2023-06-03 18:10:33,443:INFO:Importing untrained model
2023-06-03 18:10:33,445:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 18:10:33,450:INFO:Starting cross validation
2023-06-03 18:10:33,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:36,452:INFO:Calculating mean and std
2023-06-03 18:10:36,456:INFO:Creating metrics dataframe
2023-06-03 18:10:36,695:INFO:Uploading results into container
2023-06-03 18:10:36,696:INFO:Uploading model into container now
2023-06-03 18:10:36,696:INFO:_master_model_container: 10
2023-06-03 18:10:36,696:INFO:_display_container: 2
2023-06-03 18:10:36,697:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 18:10:36,697:INFO:create_model() successfully completed......................................
2023-06-03 18:10:36,779:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:36,780:INFO:Creating metrics dataframe
2023-06-03 18:10:36,791:INFO:Initializing Linear Discriminant Analysis
2023-06-03 18:10:36,791:INFO:Total runtime is 0.27114613850911456 minutes
2023-06-03 18:10:36,794:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:36,794:INFO:Initializing create_model()
2023-06-03 18:10:36,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:36,795:INFO:Checking exceptions
2023-06-03 18:10:36,795:INFO:Importing libraries
2023-06-03 18:10:36,795:INFO:Copying training dataset
2023-06-03 18:10:36,799:INFO:Defining folds
2023-06-03 18:10:36,800:INFO:Declaring metric variables
2023-06-03 18:10:36,803:INFO:Importing untrained model
2023-06-03 18:10:36,806:INFO:Linear Discriminant Analysis Imported successfully
2023-06-03 18:10:36,812:INFO:Starting cross validation
2023-06-03 18:10:36,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:37,431:INFO:Calculating mean and std
2023-06-03 18:10:37,434:INFO:Creating metrics dataframe
2023-06-03 18:10:37,670:INFO:Uploading results into container
2023-06-03 18:10:37,670:INFO:Uploading model into container now
2023-06-03 18:10:37,671:INFO:_master_model_container: 11
2023-06-03 18:10:37,671:INFO:_display_container: 2
2023-06-03 18:10:37,671:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-03 18:10:37,671:INFO:create_model() successfully completed......................................
2023-06-03 18:10:37,756:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:37,756:INFO:Creating metrics dataframe
2023-06-03 18:10:37,766:INFO:Initializing Extra Trees Classifier
2023-06-03 18:10:37,766:INFO:Total runtime is 0.28740668296813965 minutes
2023-06-03 18:10:37,769:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:37,769:INFO:Initializing create_model()
2023-06-03 18:10:37,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:37,769:INFO:Checking exceptions
2023-06-03 18:10:37,769:INFO:Importing libraries
2023-06-03 18:10:37,769:INFO:Copying training dataset
2023-06-03 18:10:37,774:INFO:Defining folds
2023-06-03 18:10:37,774:INFO:Declaring metric variables
2023-06-03 18:10:37,777:INFO:Importing untrained model
2023-06-03 18:10:37,780:INFO:Extra Trees Classifier Imported successfully
2023-06-03 18:10:37,785:INFO:Starting cross validation
2023-06-03 18:10:37,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:39,331:INFO:Calculating mean and std
2023-06-03 18:10:39,334:INFO:Creating metrics dataframe
2023-06-03 18:10:39,566:INFO:Uploading results into container
2023-06-03 18:10:39,567:INFO:Uploading model into container now
2023-06-03 18:10:39,567:INFO:_master_model_container: 12
2023-06-03 18:10:39,568:INFO:_display_container: 2
2023-06-03 18:10:39,568:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 18:10:39,568:INFO:create_model() successfully completed......................................
2023-06-03 18:10:39,644:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:39,644:INFO:Creating metrics dataframe
2023-06-03 18:10:39,655:INFO:Initializing Light Gradient Boosting Machine
2023-06-03 18:10:39,655:INFO:Total runtime is 0.3188857714335124 minutes
2023-06-03 18:10:39,658:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:39,659:INFO:Initializing create_model()
2023-06-03 18:10:39,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:39,659:INFO:Checking exceptions
2023-06-03 18:10:39,659:INFO:Importing libraries
2023-06-03 18:10:39,659:INFO:Copying training dataset
2023-06-03 18:10:39,663:INFO:Defining folds
2023-06-03 18:10:39,663:INFO:Declaring metric variables
2023-06-03 18:10:39,666:INFO:Importing untrained model
2023-06-03 18:10:39,669:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 18:10:39,678:INFO:Starting cross validation
2023-06-03 18:10:39,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:40,657:INFO:Calculating mean and std
2023-06-03 18:10:40,660:INFO:Creating metrics dataframe
2023-06-03 18:10:40,887:INFO:Uploading results into container
2023-06-03 18:10:40,887:INFO:Uploading model into container now
2023-06-03 18:10:40,888:INFO:_master_model_container: 13
2023-06-03 18:10:40,888:INFO:_display_container: 2
2023-06-03 18:10:40,888:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 18:10:40,888:INFO:create_model() successfully completed......................................
2023-06-03 18:10:40,969:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:40,970:INFO:Creating metrics dataframe
2023-06-03 18:10:40,980:INFO:Initializing Dummy Classifier
2023-06-03 18:10:40,980:INFO:Total runtime is 0.3409718592961629 minutes
2023-06-03 18:10:40,986:INFO:SubProcess create_model() called ==================================
2023-06-03 18:10:40,986:INFO:Initializing create_model()
2023-06-03 18:10:40,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f6cb7ce1670>, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:40,987:INFO:Checking exceptions
2023-06-03 18:10:40,987:INFO:Importing libraries
2023-06-03 18:10:40,987:INFO:Copying training dataset
2023-06-03 18:10:40,996:INFO:Defining folds
2023-06-03 18:10:40,996:INFO:Declaring metric variables
2023-06-03 18:10:41,000:INFO:Importing untrained model
2023-06-03 18:10:41,004:INFO:Dummy Classifier Imported successfully
2023-06-03 18:10:41,009:INFO:Starting cross validation
2023-06-03 18:10:41,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-03 18:10:41,073:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,081:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,088:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,088:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,095:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,108:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,112:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,118:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,120:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,157:WARNING:/home/jaezic/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-03 18:10:41,590:INFO:Calculating mean and std
2023-06-03 18:10:41,592:INFO:Creating metrics dataframe
2023-06-03 18:10:41,831:INFO:Uploading results into container
2023-06-03 18:10:41,832:INFO:Uploading model into container now
2023-06-03 18:10:41,832:INFO:_master_model_container: 14
2023-06-03 18:10:41,832:INFO:_display_container: 2
2023-06-03 18:10:41,833:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-06-03 18:10:41,833:INFO:create_model() successfully completed......................................
2023-06-03 18:10:41,910:INFO:SubProcess create_model() end ==================================
2023-06-03 18:10:41,911:INFO:Creating metrics dataframe
2023-06-03 18:10:41,927:INFO:Initializing create_model()
2023-06-03 18:10:41,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:41,928:INFO:Checking exceptions
2023-06-03 18:10:41,932:INFO:Importing libraries
2023-06-03 18:10:41,932:INFO:Copying training dataset
2023-06-03 18:10:41,941:INFO:Defining folds
2023-06-03 18:10:41,941:INFO:Declaring metric variables
2023-06-03 18:10:41,941:INFO:Importing untrained model
2023-06-03 18:10:41,941:INFO:Declaring custom model
2023-06-03 18:10:41,942:INFO:Gradient Boosting Classifier Imported successfully
2023-06-03 18:10:41,943:INFO:Cross validation set to False
2023-06-03 18:10:41,943:INFO:Fitting Model
2023-06-03 18:10:44,341:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-03 18:10:44,341:INFO:create_model() successfully completed......................................
2023-06-03 18:10:44,419:INFO:Initializing create_model()
2023-06-03 18:10:44,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:44,419:INFO:Checking exceptions
2023-06-03 18:10:44,420:INFO:Importing libraries
2023-06-03 18:10:44,420:INFO:Copying training dataset
2023-06-03 18:10:44,424:INFO:Defining folds
2023-06-03 18:10:44,425:INFO:Declaring metric variables
2023-06-03 18:10:44,425:INFO:Importing untrained model
2023-06-03 18:10:44,425:INFO:Declaring custom model
2023-06-03 18:10:44,425:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-03 18:10:44,426:INFO:Cross validation set to False
2023-06-03 18:10:44,426:INFO:Fitting Model
2023-06-03 18:10:44,781:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-03 18:10:44,781:INFO:create_model() successfully completed......................................
2023-06-03 18:10:44,859:INFO:Initializing create_model()
2023-06-03 18:10:44,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:44,859:INFO:Checking exceptions
2023-06-03 18:10:44,860:INFO:Importing libraries
2023-06-03 18:10:44,860:INFO:Copying training dataset
2023-06-03 18:10:44,864:INFO:Defining folds
2023-06-03 18:10:44,864:INFO:Declaring metric variables
2023-06-03 18:10:44,864:INFO:Importing untrained model
2023-06-03 18:10:44,864:INFO:Declaring custom model
2023-06-03 18:10:44,865:INFO:Random Forest Classifier Imported successfully
2023-06-03 18:10:44,865:INFO:Cross validation set to False
2023-06-03 18:10:44,865:INFO:Fitting Model
2023-06-03 18:10:45,511:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-06-03 18:10:45,511:INFO:create_model() successfully completed......................................
2023-06-03 18:10:45,589:INFO:Initializing create_model()
2023-06-03 18:10:45,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:45,589:INFO:Checking exceptions
2023-06-03 18:10:45,590:INFO:Importing libraries
2023-06-03 18:10:45,590:INFO:Copying training dataset
2023-06-03 18:10:45,599:INFO:Defining folds
2023-06-03 18:10:45,600:INFO:Declaring metric variables
2023-06-03 18:10:45,600:INFO:Importing untrained model
2023-06-03 18:10:45,600:INFO:Declaring custom model
2023-06-03 18:10:45,601:INFO:Ada Boost Classifier Imported successfully
2023-06-03 18:10:45,602:INFO:Cross validation set to False
2023-06-03 18:10:45,602:INFO:Fitting Model
2023-06-03 18:10:45,944:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-06-03 18:10:45,944:INFO:create_model() successfully completed......................................
2023-06-03 18:10:46,022:INFO:Initializing create_model()
2023-06-03 18:10:46,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-03 18:10:46,022:INFO:Checking exceptions
2023-06-03 18:10:46,023:INFO:Importing libraries
2023-06-03 18:10:46,023:INFO:Copying training dataset
2023-06-03 18:10:46,027:INFO:Defining folds
2023-06-03 18:10:46,027:INFO:Declaring metric variables
2023-06-03 18:10:46,027:INFO:Importing untrained model
2023-06-03 18:10:46,027:INFO:Declaring custom model
2023-06-03 18:10:46,028:INFO:Extra Trees Classifier Imported successfully
2023-06-03 18:10:46,028:INFO:Cross validation set to False
2023-06-03 18:10:46,028:INFO:Fitting Model
2023-06-03 18:10:46,537:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-06-03 18:10:46,537:INFO:create_model() successfully completed......................................
2023-06-03 18:10:46,631:INFO:_master_model_container: 14
2023-06-03 18:10:46,631:INFO:_display_container: 2
2023-06-03 18:10:46,632:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)]
2023-06-03 18:10:46,632:INFO:compare_models() successfully completed......................................
2023-06-03 18:10:46,982:INFO:Initializing tune_model()
2023-06-03 18:10:46,982:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f6d486ceb80>)
2023-06-03 18:10:46,982:INFO:Checking exceptions
2023-06-03 18:10:47,017:INFO:Copying training dataset
2023-06-03 18:10:47,024:INFO:Checking base model
2023-06-03 18:10:47,025:INFO:Base model : Gradient Boosting Classifier
2023-06-03 18:10:47,030:INFO:Declaring metric variables
2023-06-03 18:10:47,036:INFO:Defining Hyperparameters
2023-06-03 18:10:47,133:INFO:Tuning with n_jobs=-1
2023-06-03 18:10:47,133:INFO:Initializing RandomizedSearchCV
